{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Q2klSSy9ECD"
   },
   "source": [
    "# Análisis de datos de actividad cerebral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjf2AY81oB3b"
   },
   "source": [
    "Equipo:\n",
    "*   Alejandra Velasco Zárate A01635453\n",
    "*   Laura Merarí Valdivia Frausto A01641790\n",
    "*   Francisco Javier Ochoa Chávez A01641644"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zA0vgIPDADLm"
   },
   "outputs": [],
   "source": [
    "#Librerías\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut, RepeatedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, SequentialFeatureSelector, RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJC2BJHY9Mqr"
   },
   "source": [
    "## Evaluación de algoritmos de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "reNj-YPgCuV7"
   },
   "outputs": [],
   "source": [
    "# Funciones de clasificadores\n",
    "# k-fold SVM cross-validation\n",
    "def SVM_cross_validation(x,y,n,tipo,a, c):\n",
    "  n_folds = n\n",
    "  kf = StratifiedKFold(n_splits=n_folds, shuffle = True)\n",
    "\n",
    "  acc = 0\n",
    "  recall = np.array([0., 0., 0.])\n",
    "  precision = np.array([0., 0., 0.])\n",
    "\n",
    "  cv_y_test = []\n",
    "  cv_y_pred = []\n",
    "\n",
    "  for train_index, test_index in kf.split(x, y):\n",
    "\n",
    "      # Training phase\n",
    "      x_train = x[train_index, :]\n",
    "      y_train = y[train_index]\n",
    "\n",
    "      clf_cv = SVC(C = c, kernel = tipo)\n",
    "      clf_cv.fit(x_train, y_train)\n",
    "\n",
    "      # Test phase\n",
    "      x_test = x[test_index, :]\n",
    "      y_test = y[test_index]\n",
    "      y_pred = clf_cv.predict(x_test)\n",
    "\n",
    "      # Concatenate results of evaluation\n",
    "      cv_y_test.append(y_test)\n",
    "      cv_y_pred.append(y_pred)\n",
    "\n",
    "      # Model performance\n",
    "      if a == True:\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "  # Model performance\n",
    "  print(\"Resultados del clasificador:\\n\\n\")\n",
    "  # Crea la tabla\n",
    "  report = classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred), output_dict=True)\n",
    "  accuracy = report['accuracy']\n",
    "  table = PrettyTable()\n",
    "  table.field_names = ['Clase', 'Precisión', 'Recall', 'Puntaje F1', 'Soporte']\n",
    "\n",
    "  # Agrega las filas a la tabla\n",
    "  for class_label, metrics in report.items():\n",
    "      if class_label != 'accuracy':\n",
    "          precision = metrics['precision']\n",
    "          recall = metrics['recall']\n",
    "          f1_score = metrics['f1-score']\n",
    "          support = metrics['support']\n",
    "          table.add_row([class_label, precision, recall, f1_score, support])\n",
    "\n",
    "  # Imprime el resultado\n",
    "  print(table)\n",
    "  print(\"\\nAccuracy = \", accuracy)\n",
    "\n",
    "  # k-fold KNN cross-validation\n",
    "def KNN_cross_validation(x,y,n,k, a):\n",
    "  n_folds = n\n",
    "  kf = StratifiedKFold(n_splits=n_folds, shuffle = True)\n",
    "\n",
    "  acc = 0\n",
    "  recall = np.array([0., 0., 0.])\n",
    "  precision = np.array([0., 0., 0.])\n",
    "\n",
    "  knn_y_test = []\n",
    "  knn_y_pred = []\n",
    "\n",
    "  for train_index, test_index in kf.split(x, y):\n",
    "\n",
    "      # Training phase\n",
    "      x_train = x[train_index, :]\n",
    "      y_train = y[train_index]\n",
    "\n",
    "      knn = KNeighborsClassifier(n_neighbors = int(k))\n",
    "      knn.fit(x_train, y_train)\n",
    "\n",
    "      # Test phase\n",
    "      x_test = x[test_index, :]\n",
    "      y_test = y[test_index]\n",
    "      y_pred = knn.predict(x_test)\n",
    "\n",
    "      # Concatenate results of evaluation\n",
    "      knn_y_test.append(y_test)\n",
    "      knn_y_pred.append(y_pred)\n",
    "\n",
    "      # Model performance\n",
    "      if a==True:\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "  # Model performance\n",
    "  print(\"Resultados del clasificador:\\n\\n\")\n",
    "  # Crea la tabla\n",
    "  report = classification_report(np.concatenate(knn_y_test), np.concatenate(knn_y_pred), output_dict=True)\n",
    "  accuracy = report['accuracy']\n",
    "  table = PrettyTable()\n",
    "  table.field_names = ['Clase', 'Precisión', 'Recall', 'Puntaje F1', 'Soporte']\n",
    "\n",
    "  # Agrega las filas a la tabla\n",
    "  for class_label, metrics in report.items():\n",
    "      if class_label != 'accuracy':\n",
    "          precision = metrics['precision']\n",
    "          recall = metrics['recall']\n",
    "          f1_score = metrics['f1-score']\n",
    "          support = metrics['support']\n",
    "          table.add_row([class_label, precision, recall, f1_score, support])\n",
    "\n",
    "  # Imprime el resultado\n",
    "  print(table)\n",
    "  print(\"\\nAccuracy = \", accuracy)\n",
    "\n",
    "#MLP\n",
    "def perceptron(x , y, capas):\n",
    "\n",
    "  clf = MLPClassifier(hidden_layer_sizes=capas, max_iter=10000)  # hidden_layer_sizes controls the number of neurons of each hidden layer.\n",
    "  clf.fit(x, y)\n",
    "\n",
    "\n",
    "  # 5-fold cross-validation\n",
    "  kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "\n",
    "  cv_y_test = []\n",
    "  cv_y_pred = []\n",
    "\n",
    "  for train_index, test_index in kf.split(x, y):\n",
    "\n",
    "      # Training phase\n",
    "      x_train = x[train_index, :]\n",
    "      y_train = y[train_index]\n",
    "\n",
    "      clf_i = MLPClassifier(hidden_layer_sizes=capas, max_iter=10000)\n",
    "      clf_i.fit(x_train, y_train)\n",
    "\n",
    "      # Test phase\n",
    "      x_test = x[test_index, :]\n",
    "      y_test = y[test_index]\n",
    "      y_pred = clf_i.predict(x_test)\n",
    "\n",
    "      cv_y_test.append(y_test)\n",
    "      cv_y_pred.append(y_pred)\n",
    "\n",
    "      print(classification_report(y_test, y_pred))\n",
    "\n",
    "  # Model performance\n",
    "  print(\"Resultados del clasificador:\\n\\n\")\n",
    "  # Crea la tabla\n",
    "  report = classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred), output_dict=True)\n",
    "  accuracy = accuracy_score(np.concatenate(cv_y_test), np.concatenate(cv_y_pred))\n",
    "\n",
    "  # Crea la tabla\n",
    "  table = PrettyTable()\n",
    "  table.field_names = ['Clase', 'Precisión', 'Recall', 'Puntaje F1', 'Soporte']\n",
    "\n",
    "  # Agrega las filas a la tabla\n",
    "  for class_label, metrics in report.items():\n",
    "      if class_label != 'accuracy':\n",
    "          precision = metrics['precision']\n",
    "          recall = metrics['recall']\n",
    "          f1_score = metrics['f1-score']\n",
    "          support = metrics['support']\n",
    "          table.add_row([class_label, precision, recall, f1_score, support])\n",
    "\n",
    "  # Agrega la fila de accuracy a la tabla\n",
    "  table.add_row(['Accuracy', '', '', accuracy, ''])\n",
    "\n",
    "  # Imprime el resultado\n",
    "  print(table)\n",
    "\n",
    "# k-fold Decisión Tree cross-validation\n",
    "def dtc_cross_validation(x,y,n,a, criterio):\n",
    "  n_folds = n\n",
    "  kf = StratifiedKFold(n_splits=n_folds, shuffle = True)\n",
    "\n",
    "  acc = 0\n",
    "  recall = np.array([0., 0., 0.])\n",
    "  precision = np.array([0., 0., 0.])\n",
    "\n",
    "  dtc_y_test = []\n",
    "  dtc_y_pred = []\n",
    "\n",
    "  for train_index, test_index in kf.split(x, y):\n",
    "\n",
    "      # Training phase\n",
    "      x_train = x[train_index, :]\n",
    "      y_train = y[train_index]\n",
    "\n",
    "      dtc = DecisionTreeClassifier(criterion=criterio)\n",
    "      dtc.fit(x_train, y_train)\n",
    "\n",
    "      # Test phase\n",
    "      x_test = x[test_index, :]\n",
    "      y_test = y[test_index]\n",
    "      y_pred = dtc.predict(x_test)\n",
    "\n",
    "      # Concatenate results of evaluation\n",
    "      dtc_y_test.append(y_test)\n",
    "      dtc_y_pred.append(y_pred)\n",
    "\n",
    "      # Model performance\n",
    "      if a == True:\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "  # Model performance\n",
    "  print(\"Resultados del clasificador:\\n\\n\")\n",
    "  # Crea la tabla\n",
    "  report = classification_report(np.concatenate(dtc_y_test), np.concatenate(dtc_y_pred), output_dict=True)\n",
    "  accuracy = report['accuracy']\n",
    "  table = PrettyTable()\n",
    "  table.field_names = ['Clase', 'Precisión', 'Recall', 'Puntaje F1', 'Soporte']\n",
    "\n",
    "  # Agrega las filas a la tabla\n",
    "  for class_label, metrics in report.items():\n",
    "      if class_label != 'accuracy':\n",
    "          precision = metrics['precision']\n",
    "          recall = metrics['recall']\n",
    "          f1_score = metrics['f1-score']\n",
    "          support = metrics['support']\n",
    "          table.add_row([class_label, precision, recall, f1_score, support])\n",
    "\n",
    "\n",
    "  # Imprime el resultado\n",
    "  print(table)\n",
    "  print(\"\\nAccuracy = \", accuracy)\n",
    "\n",
    "# k-fold XGB cross-validation\n",
    "def XGB_cross_validation(x,y,n, a, boost):\n",
    "  n_folds = n\n",
    "  kf = StratifiedKFold(n_splits=n_folds, shuffle = True)\n",
    "\n",
    "  acc = 0\n",
    "  recall = np.array([0., 0., 0.])\n",
    "  precision = np.array([0., 0., 0.])\n",
    "\n",
    "  xgb_y_test = []\n",
    "  xgb_y_pred = []\n",
    "\n",
    "  for train_index, test_index in kf.split(x, y):\n",
    "\n",
    "      # Training phase\n",
    "      x_train = x[train_index, :]\n",
    "      y_train = y[train_index] - 1\n",
    "\n",
    "      xgb = XGBClassifier(booster = boost)\n",
    "      xgb.fit(x_train,y_train)\n",
    "\n",
    "      # Test phase\n",
    "      x_test = x[test_index, :]\n",
    "      y_test = y[test_index]\n",
    "      y_pred = xgb.predict(x_test) + 1\n",
    "\n",
    "      # Concatenate results of evaluation\n",
    "      xgb_y_test.append(y_test)\n",
    "      xgb_y_pred.append(y_pred)\n",
    "\n",
    "      # Model performance\n",
    "      if a == True:\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "  # Model performance\n",
    "  print(\"Resultados del clasificador:\\n\\n\")\n",
    "  # Crea la tabla\n",
    "  report = classification_report(np.concatenate(xgb_y_test), np.concatenate(xgb_y_pred), output_dict=True)\n",
    "  accuracy = report['accuracy']\n",
    "  table = PrettyTable()\n",
    "  table.field_names = ['Clase', 'Precisión', 'Recall', 'Puntaje F1', 'Soporte']\n",
    "\n",
    "  # Agrega las filas a la tabla\n",
    "  for class_label, metrics in report.items():\n",
    "      if class_label != 'accuracy':\n",
    "          precision = metrics['precision']\n",
    "          recall = metrics['recall']\n",
    "          f1_score = metrics['f1-score']\n",
    "          support = metrics['support']\n",
    "          table.add_row([class_label, precision, recall, f1_score, support])\n",
    "\n",
    "  # Imprime el resultado\n",
    "  print(table)\n",
    "  print(\"\\nAccuracy = \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qH_R9Aa9cPy"
   },
   "source": [
    "### P300: Datos Laura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1umeSMN9ZQW"
   },
   "source": [
    "1. Evalúe el rendimiento de los modelos de clasificación SVM, K-NN, y MLP (de al menos 2 capas). Calcule tanto la exactitud, la precisión por clase y el recall por clase para cada uno de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "APKqqyb89L_M",
    "outputId": "c50d55f5-18ec-4f9c-fe63-35a4a11305f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9de94233-09dd-436f-b553-2b048d0bb842\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.094699</td>\n",
       "      <td>2.686294</td>\n",
       "      <td>2.116933</td>\n",
       "      <td>1.681730</td>\n",
       "      <td>1.428804</td>\n",
       "      <td>1.146389</td>\n",
       "      <td>0.697691</td>\n",
       "      <td>0.163320</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.390041</td>\n",
       "      <td>-1.289870</td>\n",
       "      <td>-1.585485</td>\n",
       "      <td>-0.967814</td>\n",
       "      <td>-0.326333</td>\n",
       "      <td>-0.394560</td>\n",
       "      <td>-0.848664</td>\n",
       "      <td>-1.019911</td>\n",
       "      <td>-0.902654</td>\n",
       "      <td>-0.982901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.647285</td>\n",
       "      <td>-1.337426</td>\n",
       "      <td>-0.399274</td>\n",
       "      <td>0.617037</td>\n",
       "      <td>1.403505</td>\n",
       "      <td>1.960633</td>\n",
       "      <td>2.237125</td>\n",
       "      <td>2.095777</td>\n",
       "      <td>...</td>\n",
       "      <td>1.075409</td>\n",
       "      <td>1.152623</td>\n",
       "      <td>0.494895</td>\n",
       "      <td>-0.655006</td>\n",
       "      <td>-1.339643</td>\n",
       "      <td>-1.267109</td>\n",
       "      <td>-1.180082</td>\n",
       "      <td>-1.703452</td>\n",
       "      <td>-2.400101</td>\n",
       "      <td>-2.382245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.897142</td>\n",
       "      <td>-0.418778</td>\n",
       "      <td>0.313001</td>\n",
       "      <td>0.458591</td>\n",
       "      <td>0.068793</td>\n",
       "      <td>-0.079836</td>\n",
       "      <td>0.346122</td>\n",
       "      <td>0.826408</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.924741</td>\n",
       "      <td>-0.738733</td>\n",
       "      <td>-0.511247</td>\n",
       "      <td>-0.246012</td>\n",
       "      <td>-0.063970</td>\n",
       "      <td>-0.031393</td>\n",
       "      <td>0.016903</td>\n",
       "      <td>0.278268</td>\n",
       "      <td>0.691305</td>\n",
       "      <td>1.000935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.342521</td>\n",
       "      <td>0.344052</td>\n",
       "      <td>0.433977</td>\n",
       "      <td>0.741706</td>\n",
       "      <td>1.032663</td>\n",
       "      <td>1.004040</td>\n",
       "      <td>0.807921</td>\n",
       "      <td>0.958655</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096683</td>\n",
       "      <td>-0.061644</td>\n",
       "      <td>-0.097367</td>\n",
       "      <td>-0.062478</td>\n",
       "      <td>0.083558</td>\n",
       "      <td>0.223636</td>\n",
       "      <td>0.260519</td>\n",
       "      <td>0.283433</td>\n",
       "      <td>0.427372</td>\n",
       "      <td>0.567981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.266527</td>\n",
       "      <td>0.976373</td>\n",
       "      <td>0.392510</td>\n",
       "      <td>-0.398334</td>\n",
       "      <td>-0.912957</td>\n",
       "      <td>-0.836680</td>\n",
       "      <td>-0.621592</td>\n",
       "      <td>-0.958110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.483651</td>\n",
       "      <td>-0.102319</td>\n",
       "      <td>0.579976</td>\n",
       "      <td>0.821032</td>\n",
       "      <td>0.434634</td>\n",
       "      <td>0.054592</td>\n",
       "      <td>0.211030</td>\n",
       "      <td>0.627942</td>\n",
       "      <td>0.709177</td>\n",
       "      <td>0.276425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 155 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9de94233-09dd-436f-b553-2b048d0bb842')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9de94233-09dd-436f-b553-2b048d0bb842 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9de94233-09dd-436f-b553-2b048d0bb842');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   0    1         2         3         4         5         6         7    \\\n",
       "0    1    1  3.094699  2.686294  2.116933  1.681730  1.428804  1.146389   \n",
       "1    1    1 -1.647285 -1.337426 -0.399274  0.617037  1.403505  1.960633   \n",
       "2    1    1 -0.897142 -0.418778  0.313001  0.458591  0.068793 -0.079836   \n",
       "3    1    1  0.342521  0.344052  0.433977  0.741706  1.032663  1.004040   \n",
       "4    1    1  1.266527  0.976373  0.392510 -0.398334 -0.912957 -0.836680   \n",
       "\n",
       "        8         9    ...       145       146       147       148       149  \\\n",
       "0  0.697691  0.163320  ... -0.390041 -1.289870 -1.585485 -0.967814 -0.326333   \n",
       "1  2.237125  2.095777  ...  1.075409  1.152623  0.494895 -0.655006 -1.339643   \n",
       "2  0.346122  0.826408  ... -0.924741 -0.738733 -0.511247 -0.246012 -0.063970   \n",
       "3  0.807921  0.958655  ... -0.096683 -0.061644 -0.097367 -0.062478  0.083558   \n",
       "4 -0.621592 -0.958110  ... -0.483651 -0.102319  0.579976  0.821032  0.434634   \n",
       "\n",
       "        150       151       152       153       154  \n",
       "0 -0.394560 -0.848664 -1.019911 -0.902654 -0.982901  \n",
       "1 -1.267109 -1.180082 -1.703452 -2.400101 -2.382245  \n",
       "2 -0.031393  0.016903  0.278268  0.691305  1.000935  \n",
       "3  0.223636  0.260519  0.283433  0.427372  0.567981  \n",
       "4  0.054592  0.211030  0.627942  0.709177  0.276425  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lauraP300 = pd.read_csv(\"/Features_Laura_P300.txt\", header=None, delimiter=\"\\t\")\n",
    "lauraP300 = lauraP300.drop([155], axis=1)\n",
    "lauraP300 = lauraP300[lauraP300[1] != 0]\n",
    "lauraP300.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abfGjKRrJsI9",
    "outputId": "b3f44ec1-61bc-4bc6-cec4-0f38054f190b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "La clase 1 tiene 262 observaciones\n",
      "\n",
      "La clase 2 tiene 1042 observaciones\n"
     ]
    }
   ],
   "source": [
    "x = lauraP300.iloc[:, 2:].values\n",
    "y = lauraP300.iloc[:, 0].values\n",
    "\n",
    "clase2=0\n",
    "clase3=0\n",
    "\n",
    "for i in y:\n",
    "  if i==1:\n",
    "    clase2+=1\n",
    "  elif i == 2:\n",
    "    clase3+=1\n",
    "\n",
    "print(f\"\\nLa clase 1 tiene {clase2} observaciones\")\n",
    "print(f\"\\nLa clase 2 tiene {clase3} observaciones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwe4odfPJwwz"
   },
   "source": [
    "Al realizar un análisis exploratorio de los datos se puede observar que hay un desbalance entre las clases 1 y 2, ya que la clase 2 tiene casi 4 veces más observaciones que la clase uno. Si no balanceamos los datos, el recall, precisión y F1-Score de la clase 1 será muy bajo, mientras que la clase 2 tendrá valores aceptables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J801w64hOz2x"
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy=\"majority\")\n",
    "xL, yL = rus.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WFkcU4sUOofP",
    "outputId": "37410eba-5498-4899-ebb9-186daecce724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "La clase 1 tiene 262 observaciones\n",
      "\n",
      "La clase 2 tiene 262 observaciones\n"
     ]
    }
   ],
   "source": [
    "clase2=0\n",
    "clase3=0\n",
    "\n",
    "for i in yL:\n",
    "  if i==1:\n",
    "    clase2+=1\n",
    "  elif i == 2:\n",
    "    clase3+=1\n",
    "\n",
    "print(f\"\\nLa clase 1 tiene {clase2} observaciones\")\n",
    "print(f\"\\nLa clase 2 tiene {clase3} observaciones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzF_-5kbKlgL"
   },
   "source": [
    "Al balancear los datos, podemos sacrificar un poco el accuracy de los modelos de clasificación ya que se hace una disminución en las observaciones, pero mejora los evaluadores de la clase 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlCE31luC15L"
   },
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HKuyx-TW6L4W",
    "outputId": "9476e921-9219-48f6-84af-bc8f13c92c66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.83      0.81        53\n",
      "           2       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.81       105\n",
      "   macro avg       0.81      0.81      0.81       105\n",
      "weighted avg       0.81      0.81      0.81       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.85      0.88        53\n",
      "           2       0.86      0.92      0.89        52\n",
      "\n",
      "    accuracy                           0.89       105\n",
      "   macro avg       0.89      0.89      0.89       105\n",
      "weighted avg       0.89      0.89      0.89       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.71      0.73        52\n",
      "           2       0.73      0.75      0.74        53\n",
      "\n",
      "    accuracy                           0.73       105\n",
      "   macro avg       0.73      0.73      0.73       105\n",
      "weighted avg       0.73      0.73      0.73       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.79      0.80        52\n",
      "           2       0.80      0.81      0.80        53\n",
      "\n",
      "    accuracy                           0.80       105\n",
      "   macro avg       0.80      0.80      0.80       105\n",
      "weighted avg       0.80      0.80      0.80       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.79      0.76        52\n",
      "           2       0.77      0.71      0.74        52\n",
      "\n",
      "    accuracy                           0.75       104\n",
      "   macro avg       0.75      0.75      0.75       104\n",
      "weighted avg       0.75      0.75      0.75       104\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7969348659003831 | 0.7938931297709924 | 0.7954110898661567 |   262   |\n",
      "|      2       | 0.7946768060836502 | 0.7977099236641222 | 0.7961904761904763 |   262   |\n",
      "|  macro avg   | 0.7958058359920166 | 0.7958015267175573 | 0.7958007830283165 |   524   |\n",
      "| weighted avg | 0.7958058359920166 | 0.7958015267175572 | 0.7958007830283165 |   524   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7958015267175572\n"
     ]
    }
   ],
   "source": [
    "SVM_cross_validation(xL,yL,5,\"rbf\",True, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVN0Vn9NMqAC"
   },
   "source": [
    "KNN\n",
    "\n",
    "k = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUGjEV_wMpam",
    "outputId": "52dd105f-3a21-448e-e0f8-a34ce6d5a37d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.70      0.73        53\n",
      "           2       0.71      0.77      0.74        52\n",
      "\n",
      "    accuracy                           0.73       105\n",
      "   macro avg       0.73      0.73      0.73       105\n",
      "weighted avg       0.73      0.73      0.73       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.72      0.76        53\n",
      "           2       0.74      0.83      0.78        52\n",
      "\n",
      "    accuracy                           0.77       105\n",
      "   macro avg       0.77      0.77      0.77       105\n",
      "weighted avg       0.78      0.77      0.77       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.67      0.70        52\n",
      "           2       0.70      0.75      0.73        53\n",
      "\n",
      "    accuracy                           0.71       105\n",
      "   macro avg       0.72      0.71      0.71       105\n",
      "weighted avg       0.72      0.71      0.71       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.77      0.74        52\n",
      "           2       0.76      0.70      0.73        53\n",
      "\n",
      "    accuracy                           0.73       105\n",
      "   macro avg       0.73      0.73      0.73       105\n",
      "weighted avg       0.73      0.73      0.73       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.67      0.65        52\n",
      "           2       0.65      0.62      0.63        52\n",
      "\n",
      "    accuracy                           0.64       104\n",
      "   macro avg       0.64      0.64      0.64       104\n",
      "weighted avg       0.64      0.64      0.64       104\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7254901960784313 | 0.7061068702290076 | 0.7156673114119922 |   262   |\n",
      "|      2       | 0.7137546468401487 | 0.732824427480916  | 0.7231638418079096 |   262   |\n",
      "|  macro avg   |  0.71962242145929  | 0.7194656488549618 | 0.7194155766099509 |   524   |\n",
      "| weighted avg | 0.7196224214592899 | 0.7194656488549618 | 0.7194155766099509 |   524   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7194656488549618\n"
     ]
    }
   ],
   "source": [
    "KNN_cross_validation(xL,yL,5,13,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bUSfEs1Ncqx"
   },
   "source": [
    "MLP\n",
    "5 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZtHD0SUNqYF",
    "outputId": "a3d105e0-cce1-496c-a79e-190d092a2f28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.79      0.79        53\n",
      "           2       0.78      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.78       105\n",
      "   macro avg       0.78      0.78      0.78       105\n",
      "weighted avg       0.78      0.78      0.78       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.60      0.68        53\n",
      "           2       0.67      0.83      0.74        52\n",
      "\n",
      "    accuracy                           0.71       105\n",
      "   macro avg       0.73      0.72      0.71       105\n",
      "weighted avg       0.73      0.71      0.71       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.73      0.68        52\n",
      "           2       0.70      0.60      0.65        53\n",
      "\n",
      "    accuracy                           0.67       105\n",
      "   macro avg       0.67      0.67      0.67       105\n",
      "weighted avg       0.67      0.67      0.67       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.69      0.70        52\n",
      "           2       0.70      0.72      0.71        53\n",
      "\n",
      "    accuracy                           0.70       105\n",
      "   macro avg       0.70      0.70      0.70       105\n",
      "weighted avg       0.70      0.70      0.70       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.71      0.74        52\n",
      "           2       0.73      0.79      0.76        52\n",
      "\n",
      "    accuracy                           0.75       104\n",
      "   macro avg       0.75      0.75      0.75       104\n",
      "weighted avg       0.75      0.75      0.75       104\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7312252964426877 | 0.7061068702290076 | 0.7184466019417476 |   262   |\n",
      "|      2       | 0.7158671586715867 | 0.7404580152671756 | 0.7279549718574109 |   262   |\n",
      "|  macro avg   | 0.7235462275571372 | 0.7232824427480916 | 0.7232007868995792 |   524   |\n",
      "| weighted avg | 0.7235462275571372 | 0.7232824427480916 | 0.7232007868995792 |   524   |\n",
      "|   Accuracy   |                    |                    | 0.7232824427480916 |         |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "perceptron(xL,yL,(5,5,5,5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wvl-FB58uxGL"
   },
   "source": [
    "El mejor clasificador es SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UkZAe8DQkf1"
   },
   "source": [
    "2. Seleccione dos modelos de clasificación no vistos en clase, y evalúelos con sus conjuntos de datos. Calcule tanto la exactitud, la precisión por clase y el recall por clase para cada uno de los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZwFIpnqIilL"
   },
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NvHnrEy0IiOP",
    "outputId": "4417aaba-5645-47d4-c459-3c8cc57b31cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.62      0.63        53\n",
      "           2       0.62      0.63      0.63        52\n",
      "\n",
      "    accuracy                           0.63       105\n",
      "   macro avg       0.63      0.63      0.63       105\n",
      "weighted avg       0.63      0.63      0.63       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.62      0.62        53\n",
      "           2       0.62      0.62      0.62        52\n",
      "\n",
      "    accuracy                           0.62       105\n",
      "   macro avg       0.62      0.62      0.62       105\n",
      "weighted avg       0.62      0.62      0.62       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.65      0.66        52\n",
      "           2       0.67      0.68      0.67        53\n",
      "\n",
      "    accuracy                           0.67       105\n",
      "   macro avg       0.67      0.67      0.67       105\n",
      "weighted avg       0.67      0.67      0.67       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.62      0.59        52\n",
      "           2       0.59      0.55      0.57        53\n",
      "\n",
      "    accuracy                           0.58       105\n",
      "   macro avg       0.58      0.58      0.58       105\n",
      "weighted avg       0.58      0.58      0.58       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.54      0.55        52\n",
      "           2       0.56      0.60      0.58        52\n",
      "\n",
      "    accuracy                           0.57       104\n",
      "   macro avg       0.57      0.57      0.57       104\n",
      "weighted avg       0.57      0.57      0.57       104\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.6130268199233716 | 0.6106870229007634 | 0.6118546845124283 |   262   |\n",
      "|      2       | 0.6121673003802282 | 0.6145038167938931 | 0.6133333333333334 |   262   |\n",
      "|  macro avg   | 0.6125970601517998 | 0.6125954198473282 | 0.6125940089228809 |   524   |\n",
      "| weighted avg | 0.6125970601517999 | 0.6125954198473282 | 0.6125940089228809 |   524   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.6125954198473282\n"
     ]
    }
   ],
   "source": [
    "dtc_cross_validation(xL,yL,5, True, 'gini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cC-4pQcROOtb"
   },
   "source": [
    "XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-LpUxhnOOb9",
    "outputId": "b63ad5d7-de58-4d3d-d22e-2ff23d98c080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.79      0.78        53\n",
      "           2       0.78      0.75      0.76        52\n",
      "\n",
      "    accuracy                           0.77       105\n",
      "   macro avg       0.77      0.77      0.77       105\n",
      "weighted avg       0.77      0.77      0.77       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.72      0.74        53\n",
      "           2       0.73      0.77      0.75        52\n",
      "\n",
      "    accuracy                           0.74       105\n",
      "   macro avg       0.74      0.74      0.74       105\n",
      "weighted avg       0.74      0.74      0.74       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.75      0.75        52\n",
      "           2       0.75      0.75      0.75        53\n",
      "\n",
      "    accuracy                           0.75       105\n",
      "   macro avg       0.75      0.75      0.75       105\n",
      "weighted avg       0.75      0.75      0.75       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.79      0.77        52\n",
      "           2       0.78      0.75      0.77        53\n",
      "\n",
      "    accuracy                           0.77       105\n",
      "   macro avg       0.77      0.77      0.77       105\n",
      "weighted avg       0.77      0.77      0.77       105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.77      0.75        52\n",
      "           2       0.76      0.73      0.75        52\n",
      "\n",
      "    accuracy                           0.75       104\n",
      "   macro avg       0.75      0.75      0.75       104\n",
      "weighted avg       0.75      0.75      0.75       104\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7547169811320755 | 0.7633587786259542 | 0.7590132827324477 |   262   |\n",
      "|      2       | 0.7606177606177607 | 0.7519083969465649 | 0.7562380038387716 |   262   |\n",
      "|  macro avg   | 0.7576673708749181 | 0.7576335877862596 | 0.7576256432856097 |   524   |\n",
      "| weighted avg | 0.7576673708749181 | 0.7576335877862596 | 0.7576256432856097 |   524   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7576335877862596\n"
     ]
    }
   ],
   "source": [
    "XGB_cross_validation(xL,yL,5, True, 'gbtree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84AdwInXAkGs"
   },
   "source": [
    "Mejor modelo:SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cg0g1R80Qq0-"
   },
   "source": [
    "3. Indique qué modelos de clasificación de los que evaluó anteriormente tienen hiperparámetros y cuáles son éstos en cada caso. Seleccione uno de estos clasificadores, y determine sus hiperparámetros óptimos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVwDqgwBsVjy"
   },
   "source": [
    "1.   ***SVM***\n",
    "  *   **C**: Es el parámetro que controla la relación el tamaño del margen (valor grande de 𝐶 ocasiona un margen pequeño, y un valor grande de 𝐶 conduce a un margen grande).\n",
    "2.   ***KNN***\n",
    "  *   **k**: Representa el número de vecinos más cercanos que se utilizan para la clasificación. Seleccionar un valor adecuado para k es importante, ya que un valor bajo puede llevar a un modelo demasiado sensible al ruido y un valor alto puede llevar a un modelo demasiado generalizado.\n",
    "3.   ***MLP***\n",
    "  *   **hidden_layer_sizes**: Especifica la arquitectura de la red neuronal, es decir, el número de neuronas en cada capa oculta.\n",
    "4.   ***Decision Tree Classifier***\n",
    "  *   **max_depth**: Determina la profundidad máxima del árbol de decisión.\n",
    "  *   **criterion**: Es el encargado de medir la uniformidad de los nodos, uniformidad quiere decir que las cosas que son similares deben estar juntas y las que son diferentes deben separarse y distinguirse claramente unas de otras. se puede elegir el mse/mae/friedman_mse para regresión y gini/entropy para clasificación.\n",
    "  *   **min_samples_split**: el número mínimo de datos requeridos por un nodo para realizar una división.\n",
    "5.   ***XGBoost Classifier***\n",
    "  *   **n_estimators**: Representa el número de árboles que se utilizarán en el modelo. Cuanto mayor sea este valor, más complejo será el modelo y más tiempo requerirá el entrenamiento. Sin embargo, un número demasiado alto puede llevar a un sobreajuste.\n",
    "  *   **booster**: El tipo de modelo de clasificación usado, por defecto gbtree.\n",
    "  *   **max_depth**: “Profundidad” o número de nodos de bifurcación de los árboles de decisión usados en el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6PXXcmuNrX8"
   },
   "source": [
    "Hiperparámetro KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g2o3WqTJ9yOx",
    "outputId": "7b990b64-6351-41a5-c735-35b818491189"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Para k = 10 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.6529968454258676 | 0.7900763358778626 | 0.7150259067357513 |   262   |\n",
      "|      2       | 0.7342995169082126 | 0.5801526717557252 | 0.6481876332622601 |   262   |\n",
      "|  macro avg   | 0.6936481811670401 | 0.6851145038167938 | 0.6816067699990057 |   524   |\n",
      "| weighted avg | 0.6936481811670401 | 0.6851145038167938 | 0.6816067699990056 |   524   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.6851145038167938\n",
      "\n",
      "Para k = 11 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7272727272727273 | 0.732824427480916  | 0.7300380228136881 |   262   |\n",
      "|      2       | 0.7307692307692307 | 0.7251908396946565 | 0.7279693486590039 |   262   |\n",
      "|  macro avg   | 0.729020979020979  | 0.7290076335877862 | 0.729003685736346  |   524   |\n",
      "| weighted avg | 0.7290209790209791 | 0.7290076335877863 | 0.729003685736346  |   524   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7290076335877863\n",
      "\n",
      "Para k = 12 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.6889632107023411 | 0.7862595419847328 | 0.7344028520499108 |   262   |\n",
      "|      2       | 0.7511111111111111 | 0.6450381679389313 | 0.6940451745379876 |   262   |\n",
      "|  macro avg   | 0.7200371609067261 | 0.7156488549618321 | 0.7142240132939492 |   524   |\n",
      "| weighted avg | 0.7200371609067261 | 0.7156488549618321 | 0.7142240132939492 |   524   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7156488549618321\n",
      "\n",
      "Para k = 13 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7529411764705882 | 0.732824427480916  | 0.7427466150870407 |   262   |\n",
      "|      2       | 0.7397769516728625 | 0.7595419847328244 | 0.7495291902071564 |   262   |\n",
      "|  macro avg   | 0.7463590640717254 | 0.7461832061068703 | 0.7461379026470984 |   524   |\n",
      "| weighted avg | 0.7463590640717254 | 0.7461832061068703 | 0.7461379026470986 |   524   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7461832061068703\n",
      "\n",
      "Para k = 14 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.6976744186046512 | 0.8015267175572519 | 0.7460035523978685 |   262   |\n",
      "|      2       | 0.7668161434977578 | 0.6526717557251909 | 0.7051546391752577 |   262   |\n",
      "|  macro avg   | 0.7322452810512046 | 0.7270992366412214 | 0.7255790957865631 |   524   |\n",
      "| weighted avg | 0.7322452810512045 | 0.7270992366412213 | 0.7255790957865631 |   524   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7270992366412213\n",
      "\n",
      "Para k = 15 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7232472324723247 | 0.7480916030534351 | 0.7354596622889306 |   262   |\n",
      "|      2       | 0.7391304347826086 | 0.7137404580152672 | 0.7262135922330097 |   262   |\n",
      "|  macro avg   | 0.7311888336274667 | 0.7309160305343512 | 0.7308366272609701 |   524   |\n",
      "| weighted avg | 0.7311888336274667 | 0.7309160305343512 | 0.7308366272609701 |   524   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7309160305343512\n",
      "\n",
      "Para k = 16 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7248322147651006 | 0.8244274809160306 | 0.7714285714285715 |   262   |\n",
      "|      2       | 0.7964601769911505 | 0.6870229007633588 | 0.7377049180327869 |   262   |\n",
      "|  macro avg   | 0.7606461958781255 | 0.7557251908396947 | 0.7545667447306792 |   524   |\n",
      "| weighted avg | 0.7606461958781255 | 0.7557251908396947 | 0.7545667447306792 |   524   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7557251908396947\n",
      "\n",
      "Para k = 17 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7272727272727273 | 0.732824427480916  | 0.7300380228136881 |   262   |\n",
      "|      2       | 0.7307692307692307 | 0.7251908396946565 | 0.7279693486590039 |   262   |\n",
      "|  macro avg   | 0.729020979020979  | 0.7290076335877862 | 0.729003685736346  |   524   |\n",
      "| weighted avg | 0.7290209790209791 | 0.7290076335877863 | 0.729003685736346  |   524   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7290076335877863\n",
      "\n",
      "Para k = 18 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7132867132867133 | 0.7786259541984732 | 0.7445255474452556 |   262   |\n",
      "|      2       | 0.7563025210084033 | 0.6870229007633588 |        0.72        |   262   |\n",
      "|  macro avg   | 0.7347946171475583 | 0.732824427480916  | 0.7322627737226277 |   524   |\n",
      "| weighted avg | 0.7347946171475583 | 0.732824427480916  | 0.7322627737226277 |   524   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.732824427480916\n",
      "\n",
      "Para k = 19 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7490494296577946 | 0.7519083969465649 | 0.7504761904761905 |   262   |\n",
      "|      2       | 0.7509578544061303 | 0.7480916030534351 | 0.7495219885277247 |   262   |\n",
      "|  macro avg   | 0.7500036420319625 |        0.75        | 0.7499990895019576 |   524   |\n",
      "| weighted avg | 0.7500036420319625 |        0.75        | 0.7499990895019576 |   524   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.75\n"
     ]
    }
   ],
   "source": [
    "for k in range(10, 20):\n",
    "  print(f'\\nPara k = {k} los resultados son: ')\n",
    "  KNN_cross_validation(xL,yL,5,k,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rc4CnjoSu2WY"
   },
   "source": [
    "Mejor k=16 para mayor exactitud, recall y precisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lA9GBA5QuTP"
   },
   "source": [
    "4. Para uno de los modelos de clasificación, aplique un método de selección de características. Indique cuantas características son suficientes para obtener buenos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 837
    },
    "id": "IwLtxbpC3I3E",
    "outputId": "a1aea54f-8ca2-4ccb-8c0c-cd7beebb6f86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Wrapper feature selection, k = 1\n",
      "ACC:  0.6412213740458015 Recall:  [0.60305344 0.67938931] Precision:  [0.65289256 0.63120567]\n",
      "--------------- Wrapper feature selection, k = 2\n",
      "ACC:  0.6984732824427481 Recall:  [0.69083969 0.70610687] Precision:  [0.70155039 0.69548872]\n",
      "--------------- Wrapper feature selection, k = 3\n",
      "ACC:  0.7080152671755725 Recall:  [0.70610687 0.70992366] Precision:  [0.70881226 0.70722433]\n",
      "--------------- Wrapper feature selection, k = 4\n",
      "ACC:  0.7041984732824428 Recall:  [0.70229008 0.70610687] Precision:  [0.70498084 0.70342205]\n",
      "--------------- Wrapper feature selection, k = 5\n",
      "ACC:  0.6736641221374046 Recall:  [0.66030534 0.6870229 ] Precision:  [0.67843137 0.66914498]\n",
      "--------------- Wrapper feature selection, k = 6\n",
      "ACC:  0.7137404580152672 Recall:  [0.6870229  0.74045802] Precision:  [0.72580645 0.70289855]\n",
      "--------------- Wrapper feature selection, k = 7\n",
      "ACC:  0.7232824427480916 Recall:  [0.7519084  0.69465649] Precision:  [0.71119134 0.73684211]\n",
      "--------------- Wrapper feature selection, k = 8\n",
      "ACC:  0.7557251908396947 Recall:  [0.77480916 0.73664122] Precision:  [0.74632353 0.76587302]\n",
      "--------------- Wrapper feature selection, k = 9\n",
      "ACC:  0.7347328244274809 Recall:  [0.7519084  0.71755725] Precision:  [0.72693727 0.743083  ]\n",
      "--------------- Wrapper feature selection, k = 10\n",
      "ACC:  0.7290076335877863 Recall:  [0.72519084 0.73282443] Precision:  [0.73076923 0.72727273]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the wrapper approach for feature selection\n",
    "ks = np.arange(1, 11, 1)\n",
    "accs = []\n",
    "clf = SVC(kernel = 'rbf')\n",
    "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "\n",
    "\n",
    "for k in ks:\n",
    "    print('--------------- Wrapper feature selection, k =', k)\n",
    "\n",
    "    cv_y_test = []\n",
    "    cv_y_pred = []\n",
    "\n",
    "    for train_index, test_index in kf.split(xL, yL):\n",
    "\n",
    "       # Training phase\n",
    "        x_train = xL[train_index, :]\n",
    "        y_train = yL[train_index]\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "        ffs = SequentialFeatureSelector(knn, n_features_to_select=k)\n",
    "        ffs.fit(x_train, y_train)\n",
    "        x_train = ffs.transform(x_train)\n",
    "\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        # Test phase\n",
    "        x_test = ffs.transform(xL[test_index, :])\n",
    "        y_test = yL[test_index]\n",
    "        y_pred = clf.predict(x_test)\n",
    "\n",
    "        cv_y_test.append(y_test)\n",
    "        cv_y_pred.append(y_pred)\n",
    "\n",
    "    acc = accuracy_score(np.concatenate(cv_y_test), np.concatenate(cv_y_pred))\n",
    "    rec = recall_score(np.concatenate(cv_y_test), np.concatenate(cv_y_pred), average = None)\n",
    "    pre = precision_score(np.concatenate(cv_y_test), np.concatenate(cv_y_pred), average = None)\n",
    "\n",
    "    print('ACC: ', acc, 'Recall: ', rec, 'Precision: ', pre)\n",
    "    accs.append(acc)\n",
    "\n",
    "plt.plot(ks, accs)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Univariate Wrapper for feature selection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71o5-CDXP9in"
   },
   "source": [
    "Se puede observar que con 8 características se tiene un mejor accuracy y una mejor precicisón y recall por clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4gRYTURPeGh"
   },
   "source": [
    "### P300: Datos Frank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIphjp9ORE8a"
   },
   "source": [
    "1. Evalúe el rendimiento de los modelos de clasificación SVM, K-NN, y MLP (de al menos 2 capas). Calcule tanto la exactitud, la precisión por clase y el recall por clase para cada uno de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "ixH-1dJYR_Cv",
    "outputId": "51390f86-3cb0-428d-e009-4962ed940cd7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6233aef4-a1fb-4ca8-bca1-90e679b9b477\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.650851</td>\n",
       "      <td>-1.103353</td>\n",
       "      <td>-1.011505</td>\n",
       "      <td>-0.806631</td>\n",
       "      <td>-0.929389</td>\n",
       "      <td>-1.399728</td>\n",
       "      <td>-1.890547</td>\n",
       "      <td>-2.008128</td>\n",
       "      <td>...</td>\n",
       "      <td>1.019730</td>\n",
       "      <td>0.925757</td>\n",
       "      <td>0.178875</td>\n",
       "      <td>-0.613055</td>\n",
       "      <td>-0.695333</td>\n",
       "      <td>-0.185439</td>\n",
       "      <td>0.051071</td>\n",
       "      <td>-0.407607</td>\n",
       "      <td>-0.971513</td>\n",
       "      <td>-0.900166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.430508</td>\n",
       "      <td>-0.367755</td>\n",
       "      <td>-0.438024</td>\n",
       "      <td>-0.058692</td>\n",
       "      <td>-0.151503</td>\n",
       "      <td>-0.875360</td>\n",
       "      <td>-1.326114</td>\n",
       "      <td>-0.877437</td>\n",
       "      <td>...</td>\n",
       "      <td>1.154726</td>\n",
       "      <td>0.584666</td>\n",
       "      <td>0.327648</td>\n",
       "      <td>0.666186</td>\n",
       "      <td>1.234882</td>\n",
       "      <td>1.276373</td>\n",
       "      <td>0.534872</td>\n",
       "      <td>-0.241118</td>\n",
       "      <td>-0.090552</td>\n",
       "      <td>0.922864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.764953</td>\n",
       "      <td>-0.304019</td>\n",
       "      <td>0.290725</td>\n",
       "      <td>0.773008</td>\n",
       "      <td>1.368661</td>\n",
       "      <td>1.910477</td>\n",
       "      <td>1.791856</td>\n",
       "      <td>0.970698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.666665</td>\n",
       "      <td>-1.050586</td>\n",
       "      <td>-1.035848</td>\n",
       "      <td>-0.656030</td>\n",
       "      <td>-0.560080</td>\n",
       "      <td>-0.955270</td>\n",
       "      <td>-1.206095</td>\n",
       "      <td>-0.794955</td>\n",
       "      <td>-0.076633</td>\n",
       "      <td>0.337063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.320071</td>\n",
       "      <td>-0.561524</td>\n",
       "      <td>-0.814992</td>\n",
       "      <td>-1.033411</td>\n",
       "      <td>-1.067577</td>\n",
       "      <td>-0.813750</td>\n",
       "      <td>-0.399316</td>\n",
       "      <td>-0.123247</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.242755</td>\n",
       "      <td>-0.985276</td>\n",
       "      <td>-1.595225</td>\n",
       "      <td>-2.324547</td>\n",
       "      <td>-2.021589</td>\n",
       "      <td>-0.901173</td>\n",
       "      <td>-0.299647</td>\n",
       "      <td>-0.759278</td>\n",
       "      <td>-1.319188</td>\n",
       "      <td>-1.036059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.239852</td>\n",
       "      <td>0.406552</td>\n",
       "      <td>2.006212</td>\n",
       "      <td>3.284820</td>\n",
       "      <td>3.240865</td>\n",
       "      <td>2.238398</td>\n",
       "      <td>1.273309</td>\n",
       "      <td>0.675379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858562</td>\n",
       "      <td>1.203783</td>\n",
       "      <td>0.967443</td>\n",
       "      <td>0.884985</td>\n",
       "      <td>1.165211</td>\n",
       "      <td>1.160697</td>\n",
       "      <td>0.576841</td>\n",
       "      <td>0.084106</td>\n",
       "      <td>0.197770</td>\n",
       "      <td>0.367902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 152 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6233aef4-a1fb-4ca8-bca1-90e679b9b477')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6233aef4-a1fb-4ca8-bca1-90e679b9b477 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6233aef4-a1fb-4ca8-bca1-90e679b9b477');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   0    1         2         3         4         5         6         7    \\\n",
       "0    1    1 -0.650851 -1.103353 -1.011505 -0.806631 -0.929389 -1.399728   \n",
       "1    1    1  0.430508 -0.367755 -0.438024 -0.058692 -0.151503 -0.875360   \n",
       "2    1    1 -0.764953 -0.304019  0.290725  0.773008  1.368661  1.910477   \n",
       "3    1    1 -0.320071 -0.561524 -0.814992 -1.033411 -1.067577 -0.813750   \n",
       "4    1    1 -0.239852  0.406552  2.006212  3.284820  3.240865  2.238398   \n",
       "\n",
       "        8         9    ...       142       143       144       145       146  \\\n",
       "0 -1.890547 -2.008128  ...  1.019730  0.925757  0.178875 -0.613055 -0.695333   \n",
       "1 -1.326114 -0.877437  ...  1.154726  0.584666  0.327648  0.666186  1.234882   \n",
       "2  1.791856  0.970698  ... -0.666665 -1.050586 -1.035848 -0.656030 -0.560080   \n",
       "3 -0.399316 -0.123247  ... -1.242755 -0.985276 -1.595225 -2.324547 -2.021589   \n",
       "4  1.273309  0.675379  ...  0.858562  1.203783  0.967443  0.884985  1.165211   \n",
       "\n",
       "        147       148       149       150       151  \n",
       "0 -0.185439  0.051071 -0.407607 -0.971513 -0.900166  \n",
       "1  1.276373  0.534872 -0.241118 -0.090552  0.922864  \n",
       "2 -0.955270 -1.206095 -0.794955 -0.076633  0.337063  \n",
       "3 -0.901173 -0.299647 -0.759278 -1.319188 -1.036059  \n",
       "4  1.160697  0.576841  0.084106  0.197770  0.367902  \n",
       "\n",
       "[5 rows x 152 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frankP300 = pd.read_csv(\"/content/drive/Shareddrives/Proyecto_AprendizajeAI/Features_Frank_P300_2.txt\", header=None, delimiter=\"\\t\")\n",
    "frankP300 = frankP300.drop([152], axis=1)\n",
    "frankP300 = frankP300[frankP300[1] != 0]\n",
    "frankP300.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IojXrRuzIvNq",
    "outputId": "ab43c247-66b5-4723-dd1e-2b66f2649a70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "La clase 1 tiene 277 observaciones\n",
      "\n",
      "La clase 2 tiene 1116 observaciones\n"
     ]
    }
   ],
   "source": [
    "xF = frankP300.iloc[:, 1:].values\n",
    "yF = frankP300.iloc[:, 0].values\n",
    "\n",
    "clase2=0\n",
    "clase3=0\n",
    "\n",
    "for i in yF:\n",
    "  if i==1:\n",
    "    clase2+=1\n",
    "  elif i == 2:\n",
    "    clase3+=1\n",
    "\n",
    "print(f\"\\nLa clase 1 tiene {clase2} observaciones\")\n",
    "print(f\"\\nLa clase 2 tiene {clase3} observaciones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JlvpGkULVR2"
   },
   "source": [
    "En este caso se tiene el mismo problema que en la base de datos anterior, razón por la cual se balancearon los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eUqO3uJ1SUxf"
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy=\"majority\")\n",
    "xF, yF = rus.fit_resample(xF, yF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WxrSO2pkPenv",
    "outputId": "988bf37c-d761-4f42-d9d3-53fe8ecebc96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "La clase 1 tiene 277 observaciones\n",
      "\n",
      "La clase 2 tiene 277 observaciones\n"
     ]
    }
   ],
   "source": [
    "clase2=0\n",
    "clase3=0\n",
    "\n",
    "for i in yF:\n",
    "  if i==1:\n",
    "    clase2+=1\n",
    "  elif i == 2:\n",
    "    clase3+=1\n",
    "\n",
    "print(f\"\\nLa clase 1 tiene {clase2} observaciones\")\n",
    "print(f\"\\nLa clase 2 tiene {clase3} observaciones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhmM1DcxLggN"
   },
   "source": [
    "Al final reducimos los datos de la clase 2, de 1116 a 277."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e29OX4r4T6xK"
   },
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yiJ7M0x_UIlt",
    "outputId": "9228ba7f-5d2b-46f7-992e-db52095ae87a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.79      0.79        56\n",
      "           2       0.78      0.78      0.78        55\n",
      "\n",
      "    accuracy                           0.78       111\n",
      "   macro avg       0.78      0.78      0.78       111\n",
      "weighted avg       0.78      0.78      0.78       111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.77      0.77        56\n",
      "           2       0.77      0.78      0.77        55\n",
      "\n",
      "    accuracy                           0.77       111\n",
      "   macro avg       0.77      0.77      0.77       111\n",
      "weighted avg       0.77      0.77      0.77       111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.75      0.75        55\n",
      "           2       0.75      0.77      0.76        56\n",
      "\n",
      "    accuracy                           0.76       111\n",
      "   macro avg       0.76      0.76      0.76       111\n",
      "weighted avg       0.76      0.76      0.76       111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.73      0.72        55\n",
      "           2       0.73      0.71      0.72        56\n",
      "\n",
      "    accuracy                           0.72       111\n",
      "   macro avg       0.72      0.72      0.72       111\n",
      "weighted avg       0.72      0.72      0.72       111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.75      0.77        55\n",
      "           2       0.76      0.82      0.79        55\n",
      "\n",
      "    accuracy                           0.78       110\n",
      "   macro avg       0.78      0.78      0.78       110\n",
      "weighted avg       0.78      0.78      0.78       110\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7683823529411765 | 0.7545126353790613 | 0.761384335154827  |   277   |\n",
      "|      2       | 0.7588652482269503 | 0.7725631768953068 | 0.7656529516994633 |   277   |\n",
      "|  macro avg   | 0.7636238005840634 | 0.7635379061371841 | 0.7635186434271451 |   554   |\n",
      "| weighted avg | 0.7636238005840634 | 0.7635379061371841 | 0.7635186434271451 |   554   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7635379061371841\n"
     ]
    }
   ],
   "source": [
    "SVM_cross_validation(xF,yF,5,\"rbf\", True, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMw5X_4XT73r"
   },
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nDUCagKSUK9p",
    "outputId": "5b38215b-837e-45b0-8088-3c0483d2685a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.82      0.77        56\n",
      "           2       0.79      0.69      0.74        55\n",
      "\n",
      "    accuracy                           0.76       111\n",
      "   macro avg       0.76      0.76      0.76       111\n",
      "weighted avg       0.76      0.76      0.76       111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.77      0.69        56\n",
      "           2       0.70      0.55      0.61        55\n",
      "\n",
      "    accuracy                           0.66       111\n",
      "   macro avg       0.67      0.66      0.65       111\n",
      "weighted avg       0.66      0.66      0.65       111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.67      0.69        55\n",
      "           2       0.69      0.71      0.70        56\n",
      "\n",
      "    accuracy                           0.69       111\n",
      "   macro avg       0.69      0.69      0.69       111\n",
      "weighted avg       0.69      0.69      0.69       111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.87      0.74        55\n",
      "           2       0.81      0.54      0.65        56\n",
      "\n",
      "    accuracy                           0.70       111\n",
      "   macro avg       0.73      0.70      0.69       111\n",
      "weighted avg       0.73      0.70      0.69       111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.80      0.75        55\n",
      "           2       0.77      0.67      0.72        55\n",
      "\n",
      "    accuracy                           0.74       110\n",
      "   macro avg       0.74      0.74      0.74       110\n",
      "weighted avg       0.74      0.74      0.74       110\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       |      0.68125       | 0.7870036101083032 | 0.7303182579564489 |   277   |\n",
      "|      2       | 0.7478632478632479 | 0.631768953068592  | 0.684931506849315  |   277   |\n",
      "|  macro avg   | 0.7145566239316239 | 0.7093862815884476 | 0.7076248824028819 |   554   |\n",
      "| weighted avg | 0.714556623931624  | 0.7093862815884476 | 0.7076248824028819 |   554   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7093862815884476\n"
     ]
    }
   ],
   "source": [
    "KNN_cross_validation(xF,yF,5,13,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IoEp9xsZT8lO"
   },
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jccGtqxAUQYC",
    "outputId": "50fcd1ed-e43f-4fd5-9f60-fbb94fd4a3f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.79      0.76        56\n",
      "           2       0.76      0.71      0.74        55\n",
      "\n",
      "    accuracy                           0.75       111\n",
      "   macro avg       0.75      0.75      0.75       111\n",
      "weighted avg       0.75      0.75      0.75       111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.62      0.68        56\n",
      "           2       0.67      0.78      0.72        55\n",
      "\n",
      "    accuracy                           0.70       111\n",
      "   macro avg       0.71      0.70      0.70       111\n",
      "weighted avg       0.71      0.70      0.70       111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.85      0.75        55\n",
      "           2       0.80      0.57      0.67        56\n",
      "\n",
      "    accuracy                           0.71       111\n",
      "   macro avg       0.73      0.71      0.71       111\n",
      "weighted avg       0.73      0.71      0.71       111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.75      0.77        55\n",
      "           2       0.76      0.80      0.78        56\n",
      "\n",
      "    accuracy                           0.77       111\n",
      "   macro avg       0.78      0.77      0.77       111\n",
      "weighted avg       0.78      0.77      0.77       111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.67      0.68        55\n",
      "           2       0.68      0.69      0.68        55\n",
      "\n",
      "    accuracy                           0.68       110\n",
      "   macro avg       0.68      0.68      0.68       110\n",
      "weighted avg       0.68      0.68      0.68       110\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7183098591549296 | 0.7364620938628159 | 0.7272727272727273 |   277   |\n",
      "|      2       | 0.7296296296296296 | 0.7111913357400722 | 0.720292504570384  |   277   |\n",
      "|  macro avg   | 0.7239697443922797 | 0.7238267148014441 | 0.7237826159215557 |   554   |\n",
      "| weighted avg | 0.7239697443922797 | 0.723826714801444  | 0.7237826159215557 |   554   |\n",
      "|   Accuracy   |                    |                    | 0.723826714801444  |         |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "perceptron(xF,yF,(5,5,5,5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eq2yYN85RIw7"
   },
   "source": [
    "2. Seleccione dos modelos de clasificación no vistos en clase, y evalúelos con sus conjuntos de datos. Calcule tanto la exactitud, la precisión por clase y el recall por clase para cada uno de los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4Y2QxeET_JE"
   },
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38C_ZqLEUWfV",
    "outputId": "d5cfd40b-37e5-41ab-98c1-1ccd8cc23784"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.70      0.64        56\n",
      "           2       0.62      0.51      0.56        55\n",
      "\n",
      "    accuracy                           0.60       111\n",
      "   macro avg       0.61      0.60      0.60       111\n",
      "weighted avg       0.61      0.60      0.60       111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.61      0.62        56\n",
      "           2       0.62      0.65      0.64        55\n",
      "\n",
      "    accuracy                           0.63       111\n",
      "   macro avg       0.63      0.63      0.63       111\n",
      "weighted avg       0.63      0.63      0.63       111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.60      0.63        55\n",
      "           2       0.64      0.70      0.67        56\n",
      "\n",
      "    accuracy                           0.65       111\n",
      "   macro avg       0.65      0.65      0.65       111\n",
      "weighted avg       0.65      0.65      0.65       111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.67      0.67        55\n",
      "           2       0.67      0.66      0.67        56\n",
      "\n",
      "    accuracy                           0.67       111\n",
      "   macro avg       0.67      0.67      0.67       111\n",
      "weighted avg       0.67      0.67      0.67       111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.58      0.62        55\n",
      "           2       0.62      0.69      0.66        55\n",
      "\n",
      "    accuracy                           0.64       110\n",
      "   macro avg       0.64      0.64      0.64       110\n",
      "weighted avg       0.64      0.64      0.64       110\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.6386861313868614 | 0.631768953068592  | 0.6352087114337568 |   277   |\n",
      "|      2       | 0.6357142857142857 | 0.6425992779783394 | 0.6391382405745063 |   277   |\n",
      "|  macro avg   | 0.6372002085505735 | 0.6371841155234657 | 0.6371734760041315 |   554   |\n",
      "| weighted avg | 0.6372002085505736 | 0.6371841155234657 | 0.6371734760041315 |   554   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.6371841155234657\n"
     ]
    }
   ],
   "source": [
    "dtc_cross_validation(xF,yF,5, True, 'gini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-Ua3vjdUDDR"
   },
   "source": [
    "XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bY0TGM5ZUe-P",
    "outputId": "a054e840-f044-409e-f80f-8c66e42b91d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.73      0.73        56\n",
      "           2       0.72      0.71      0.72        55\n",
      "\n",
      "    accuracy                           0.72       111\n",
      "   macro avg       0.72      0.72      0.72       111\n",
      "weighted avg       0.72      0.72      0.72       111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.77      0.74        56\n",
      "           2       0.74      0.67      0.70        55\n",
      "\n",
      "    accuracy                           0.72       111\n",
      "   macro avg       0.72      0.72      0.72       111\n",
      "weighted avg       0.72      0.72      0.72       111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.73      0.75        55\n",
      "           2       0.75      0.79      0.77        56\n",
      "\n",
      "    accuracy                           0.76       111\n",
      "   macro avg       0.76      0.76      0.76       111\n",
      "weighted avg       0.76      0.76      0.76       111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.82      0.79        55\n",
      "           2       0.81      0.75      0.78        56\n",
      "\n",
      "    accuracy                           0.78       111\n",
      "   macro avg       0.79      0.78      0.78       111\n",
      "weighted avg       0.79      0.78      0.78       111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.76      0.74        55\n",
      "           2       0.75      0.71      0.73        55\n",
      "\n",
      "    accuracy                           0.74       110\n",
      "   macro avg       0.74      0.74      0.74       110\n",
      "weighted avg       0.74      0.74      0.74       110\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.735191637630662  | 0.7617328519855595 |  0.74822695035461  |   277   |\n",
      "|      2       | 0.7528089887640449 | 0.7256317689530686 | 0.7389705882352942 |   277   |\n",
      "|  macro avg   | 0.7440003131973534 | 0.743682310469314  | 0.7435987692949521 |   554   |\n",
      "| weighted avg | 0.7440003131973534 | 0.7436823104693141 | 0.7435987692949521 |   554   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7436823104693141\n"
     ]
    }
   ],
   "source": [
    "XGB_cross_validation(xF,yF,5, True, 'gbtree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RccIV-84vCUx"
   },
   "source": [
    "El mejor clasificador de los 5 evaluados fue SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGBSW4VGRMRE"
   },
   "source": [
    "3. Indique qué modelos de clasificación de los que evaluó anteriormente tienen hiperparámetros y cuáles son éstos en cada caso. Seleccione uno de estos clasificadores, y determine sus hiperparámetros óptimos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyJNYqh4DCmp"
   },
   "source": [
    "1.   ***SVM***\n",
    "  *   **C**: Es el parámetro que controla la relación el tamaño del margen (valor grande de 𝐶 ocasiona un margen pequeño, y un valor grande de 𝐶 conduce a un margen grande).\n",
    "2.   ***KNN***\n",
    "  *   **k**: Representa el número de vecinos más cercanos que se utilizan para la clasificación. Seleccionar un valor adecuado para k es importante, ya que un valor bajo puede llevar a un modelo demasiado sensible al ruido y un valor alto puede llevar a un modelo demasiado generalizado.\n",
    "3.   ***MLP***\n",
    "  *   **hidden_layer_sizes**: Especifica la arquitectura de la red neuronal, es decir, el número de neuronas en cada capa oculta.\n",
    "4.   ***Decision Tree Classifier***\n",
    "  *   **max_depth**: Determina la profundidad máxima del árbol de decisión.\n",
    "  *   **criterion**: Es el encargado de medir la uniformidad de los nodos, uniformidad quiere decir que las cosas que son similares deben estar juntas y las que son diferentes deben separarse y distinguirse claramente unas de otras. se puede elegir el mse/mae/friedman_mse para regresión y gini/entropy para clasificación.\n",
    "  *   **min_samples_split**: el número mínimo de datos requeridos por un nodo para realizar una división.\n",
    "5.   ***XGBoost Classifier***\n",
    "  *   **n_estimators**: Representa el número de árboles que se utilizarán en el modelo. Cuanto mayor sea este valor, más complejo será el modelo y más tiempo requerirá el entrenamiento. Sin embargo, un número demasiado alto puede llevar a un sobreajuste.\n",
    "  *   **booster**: El tipo de modelo de clasificación usado, por defecto gbtree.\n",
    "  *   **max_depth**: “Profundidad” o número de nodos de bifurcación de los árboles de decisión usados en el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1ebgOhYPQV5"
   },
   "source": [
    "Hiperparámetro Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wq0OLGMVN2px",
    "outputId": "d1e8f9c3-af08-4d47-a48d-daf96fc36f45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Para criterion: gini:\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.629757785467128  | 0.6570397111913358 | 0.6431095406360424 |   277   |\n",
      "|      2       | 0.6415094339622641 | 0.6137184115523465 | 0.6273062730627307 |   277   |\n",
      "|  macro avg   | 0.6356336097146961 | 0.6353790613718411 | 0.6352079068493865 |   554   |\n",
      "| weighted avg | 0.6356336097146961 | 0.6353790613718412 | 0.6352079068493865 |   554   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.6353790613718412\n",
      "\n",
      "Para criterion: entropy:\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.6305970149253731 | 0.6101083032490975 | 0.6201834862385321 |   277   |\n",
      "|      2       | 0.6223776223776224 | 0.6425992779783394 | 0.6323268206039078 |   277   |\n",
      "|  macro avg   | 0.6264873186514978 | 0.6263537906137184 |  0.62625515342122  |   554   |\n",
      "| weighted avg | 0.6264873186514979 | 0.6263537906137184 |  0.62625515342122  |   554   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.6263537906137184\n",
      "\n",
      "Para criterion: log_loss:\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.6068965517241379 | 0.6353790613718412 | 0.6208112874779541 |   277   |\n",
      "|      2       | 0.6174242424242424 | 0.5884476534296029 | 0.6025878003696857 |   277   |\n",
      "|  macro avg   | 0.6121603970741902 | 0.6119133574007221 |  0.61169954392382  |   554   |\n",
      "| weighted avg | 0.6121603970741902 | 0.6119133574007221 | 0.6116995439238199 |   554   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.6119133574007221\n"
     ]
    }
   ],
   "source": [
    "criterio = ['gini', 'entropy', 'log_loss']\n",
    "\n",
    "for i in criterio:\n",
    "  print(f\"\\nPara criterion: {i}:\")\n",
    "  dtc_cross_validation(xF,yF,5, False, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjxmwUAjvGds"
   },
   "source": [
    "El mejor hiperparámetro del clasificador de Árbol de decisión criterio es 'log_loss'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7BHasVdRQx7"
   },
   "source": [
    "4. Para uno de los modelos de clasificación, aplique un método de selección de características. Indique cuantas características son suficientes para obtener buenos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ePOqYVjGP7Vz",
    "outputId": "eb6999a7-8156-4ed6-ec21-f86704a01b6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Wrapper feature selection, k = 1\n",
      "ACC:  0.631768953068592 Recall:  [0.68231047 0.58122744] Precision:  [0.61967213 0.64658635]\n",
      "--------------- Wrapper feature selection, k = 2\n",
      "ACC:  0.6263537906137184 Recall:  [0.67509025 0.57761733] Precision:  [0.61513158 0.64      ]\n",
      "--------------- Wrapper feature selection, k = 3\n",
      "ACC:  0.6913357400722022 Recall:  [0.67509025 0.70758123] Precision:  [0.69776119 0.68531469]\n",
      "--------------- Wrapper feature selection, k = 4\n",
      "ACC:  0.6841155234657039 Recall:  [0.70036101 0.66787004] Precision:  [0.67832168 0.69029851]\n",
      "--------------- Wrapper feature selection, k = 5\n"
     ]
    }
   ],
   "source": [
    "# Use the wrapper approach for feature selection\n",
    "ks = np.arange(1, 11, 1)\n",
    "accs = []\n",
    "clf = SVC(kernel = 'rbf')\n",
    "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "\n",
    "\n",
    "for k in ks:\n",
    "    print('--------------- Wrapper feature selection, k =', k)\n",
    "\n",
    "    cv_y_test = []\n",
    "    cv_y_pred = []\n",
    "\n",
    "    for train_index, test_index in kf.split(xF, yF):\n",
    "\n",
    "       # Training phase\n",
    "        x_train = xF[train_index, :]\n",
    "        y_train = yF[train_index]\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "        ffs = SequentialFeatureSelector(knn, n_features_to_select=k)\n",
    "        ffs.fit(x_train, y_train)\n",
    "        x_train = ffs.transform(x_train)\n",
    "\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        # Test phase\n",
    "        x_test = ffs.transform(xF[test_index, :])\n",
    "        y_test = yF[test_index]\n",
    "        y_pred = clf.predict(x_test)\n",
    "\n",
    "        cv_y_test.append(y_test)\n",
    "        cv_y_pred.append(y_pred)\n",
    "\n",
    "    acc = accuracy_score(np.concatenate(cv_y_test), np.concatenate(cv_y_pred))\n",
    "    rec = recall_score(np.concatenate(cv_y_test), np.concatenate(cv_y_pred), average = None)\n",
    "    pre = precision_score(np.concatenate(cv_y_test), np.concatenate(cv_y_pred), average = None)\n",
    "\n",
    "    print('ACC: ', acc, 'Recall: ', rec, 'Precision: ', pre)\n",
    "    accs.append(acc)\n",
    "\n",
    "plt.plot(ks, accs)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Univariate Wrapper for feature selection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkkTAOX5vR5h"
   },
   "source": [
    "El rendimiento óptimo del modelo se consigue con 9 características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ouy838ZZRlaB"
   },
   "source": [
    "### Cognitivo Frank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlvv7FRe4OU4"
   },
   "source": [
    "**Clasificación de tareas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "9NIfmkeIyOTO",
    "outputId": "e0d97692-719f-466a-8198-db3ff7d3909d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-a9dca053-8cb6-4b34-a990-cd6ddebf7ca4\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2332</th>\n",
       "      <th>2333</th>\n",
       "      <th>2334</th>\n",
       "      <th>2335</th>\n",
       "      <th>2336</th>\n",
       "      <th>2337</th>\n",
       "      <th>2338</th>\n",
       "      <th>2339</th>\n",
       "      <th>2340</th>\n",
       "      <th>2341</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.316079</td>\n",
       "      <td>-0.569181</td>\n",
       "      <td>-0.840397</td>\n",
       "      <td>-2.263029</td>\n",
       "      <td>-0.477150</td>\n",
       "      <td>-0.473358</td>\n",
       "      <td>-1.639392</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.089592</td>\n",
       "      <td>-1.521619</td>\n",
       "      <td>-0.756561</td>\n",
       "      <td>-1.132632</td>\n",
       "      <td>-1.944529</td>\n",
       "      <td>-1.126415</td>\n",
       "      <td>-1.040056</td>\n",
       "      <td>-1.276589</td>\n",
       "      <td>-1.252492</td>\n",
       "      <td>-1.276102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.092858</td>\n",
       "      <td>-0.509809</td>\n",
       "      <td>-0.208803</td>\n",
       "      <td>0.182265</td>\n",
       "      <td>-1.280907</td>\n",
       "      <td>-0.332009</td>\n",
       "      <td>0.088508</td>\n",
       "      <td>-0.322166</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.129138</td>\n",
       "      <td>-1.549519</td>\n",
       "      <td>-1.534214</td>\n",
       "      <td>-0.629425</td>\n",
       "      <td>-1.352853</td>\n",
       "      <td>-0.975112</td>\n",
       "      <td>-1.168972</td>\n",
       "      <td>-2.116018</td>\n",
       "      <td>-1.773718</td>\n",
       "      <td>-1.474069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.924355</td>\n",
       "      <td>-1.020561</td>\n",
       "      <td>-0.608800</td>\n",
       "      <td>-1.923035</td>\n",
       "      <td>-1.002875</td>\n",
       "      <td>-0.927044</td>\n",
       "      <td>-0.946278</td>\n",
       "      <td>-0.433741</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.051609</td>\n",
       "      <td>-1.223329</td>\n",
       "      <td>-1.384643</td>\n",
       "      <td>-0.561653</td>\n",
       "      <td>-0.666955</td>\n",
       "      <td>-1.012405</td>\n",
       "      <td>-0.713106</td>\n",
       "      <td>-1.353017</td>\n",
       "      <td>-1.530745</td>\n",
       "      <td>-0.481837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.269049</td>\n",
       "      <td>-0.495929</td>\n",
       "      <td>-0.515496</td>\n",
       "      <td>-0.309277</td>\n",
       "      <td>-0.425367</td>\n",
       "      <td>-0.968869</td>\n",
       "      <td>-0.364516</td>\n",
       "      <td>-1.179716</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.825389</td>\n",
       "      <td>-0.510917</td>\n",
       "      <td>-0.676058</td>\n",
       "      <td>-0.091499</td>\n",
       "      <td>-0.740510</td>\n",
       "      <td>-0.497735</td>\n",
       "      <td>-0.659177</td>\n",
       "      <td>-1.753575</td>\n",
       "      <td>-0.644050</td>\n",
       "      <td>-0.541565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.174988</td>\n",
       "      <td>-0.915864</td>\n",
       "      <td>0.160994</td>\n",
       "      <td>-2.238067</td>\n",
       "      <td>-0.740315</td>\n",
       "      <td>-0.548436</td>\n",
       "      <td>0.227631</td>\n",
       "      <td>-0.112852</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.375743</td>\n",
       "      <td>-1.633402</td>\n",
       "      <td>-1.146866</td>\n",
       "      <td>-0.800723</td>\n",
       "      <td>-0.698990</td>\n",
       "      <td>-0.311886</td>\n",
       "      <td>-1.488918</td>\n",
       "      <td>-1.371906</td>\n",
       "      <td>-1.615953</td>\n",
       "      <td>-0.688520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2342 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9dca053-8cb6-4b34-a990-cd6ddebf7ca4')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-a9dca053-8cb6-4b34-a990-cd6ddebf7ca4 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-a9dca053-8cb6-4b34-a990-cd6ddebf7ca4');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   0     1         2         3         4         5         6         7     \\\n",
       "0     1     1 -1.316079 -0.569181 -0.840397 -2.263029 -0.477150 -0.473358   \n",
       "1     1     1 -0.092858 -0.509809 -0.208803  0.182265 -1.280907 -0.332009   \n",
       "2     1     1 -0.924355 -1.020561 -0.608800 -1.923035 -1.002875 -0.927044   \n",
       "3     1     1 -0.269049 -0.495929 -0.515496 -0.309277 -0.425367 -0.968869   \n",
       "4     1     1  0.174988 -0.915864  0.160994 -2.238067 -0.740315 -0.548436   \n",
       "\n",
       "       8         9     ...      2332      2333      2334      2335      2336  \\\n",
       "0 -1.639392 -0.018691  ... -1.089592 -1.521619 -0.756561 -1.132632 -1.944529   \n",
       "1  0.088508 -0.322166  ... -1.129138 -1.549519 -1.534214 -0.629425 -1.352853   \n",
       "2 -0.946278 -0.433741  ... -1.051609 -1.223329 -1.384643 -0.561653 -0.666955   \n",
       "3 -0.364516 -1.179716  ... -0.825389 -0.510917 -0.676058 -0.091499 -0.740510   \n",
       "4  0.227631 -0.112852  ... -0.375743 -1.633402 -1.146866 -0.800723 -0.698990   \n",
       "\n",
       "       2337      2338      2339      2340      2341  \n",
       "0 -1.126415 -1.040056 -1.276589 -1.252492 -1.276102  \n",
       "1 -0.975112 -1.168972 -2.116018 -1.773718 -1.474069  \n",
       "2 -1.012405 -0.713106 -1.353017 -1.530745 -0.481837  \n",
       "3 -0.497735 -0.659177 -1.753575 -0.644050 -0.541565  \n",
       "4 -0.311886 -1.488918 -1.371906 -1.615953 -0.688520  \n",
       "\n",
       "[5 rows x 2342 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frank_cog= pd.read_csv(\"/Features_Frank_Cognitivo.txt\" , header=None, delimiter= \"\\t\")\n",
    "frank_cog = frank_cog.dropna(axis=1)\n",
    "frank_cog = frank_cog[frank_cog[1] != 0]\n",
    "frank_cog = frank_cog[frank_cog[0] != 13]\n",
    "frank_cog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "b2Pp0GQezRLp"
   },
   "outputs": [],
   "source": [
    "transformacion = lambda x: 1 if 1 <= x <= 4 else 2 if 5 <= x <= 8 else 3 if 9 <= x <= 12 else 4\n",
    "frank_cog[0] = frank_cog[0].map(transformacion)\n",
    "xFC= frank_cog.iloc[:, 2:].values\n",
    "yFC = frank_cog.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqRBp23P1zdd"
   },
   "source": [
    "1. Evalúe el rendimiento de los modelos de clasificación SVM, K-NN, y MLP (de al menos 2 capas). Calcule tanto la exactitud, la precisión por clase y el recall por clase para cada uno de los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkUbXrYK0r9S"
   },
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "_IrRRZeqzfr_",
    "outputId": "de78de9b-1fdb-403f-b821-3c04d21bcd26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.64      0.74        11\n",
      "           2       0.91      1.00      0.95        10\n",
      "           3       0.77      0.91      0.83        11\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.85      0.85      0.84        32\n",
      "weighted avg       0.85      0.84      0.84        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.82      0.90        11\n",
      "           2       0.91      1.00      0.95        10\n",
      "           3       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.94        31\n",
      "   macro avg       0.94      0.94      0.93        31\n",
      "weighted avg       0.94      0.94      0.93        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.60      0.67        10\n",
      "           2       0.83      0.91      0.87        11\n",
      "           3       0.73      0.80      0.76        10\n",
      "\n",
      "    accuracy                           0.77        31\n",
      "   macro avg       0.77      0.77      0.77        31\n",
      "weighted avg       0.77      0.77      0.77        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.80      0.84        10\n",
      "           2       1.00      1.00      1.00        11\n",
      "           3       0.82      0.90      0.86        10\n",
      "\n",
      "    accuracy                           0.90        31\n",
      "   macro avg       0.90      0.90      0.90        31\n",
      "weighted avg       0.91      0.90      0.90        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.70      0.78        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "           3       0.77      0.91      0.83        11\n",
      "\n",
      "    accuracy                           0.87        31\n",
      "   macro avg       0.88      0.87      0.87        31\n",
      "weighted avg       0.88      0.87      0.87        31\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8809523809523809 | 0.7115384615384616 | 0.7872340425531914 |    52   |\n",
      "|      2       | 0.9272727272727272 | 0.9807692307692307 | 0.9532710280373831 |    52   |\n",
      "|      3       | 0.7966101694915254 | 0.9038461538461539 | 0.8468468468468469 |    52   |\n",
      "|  macro avg   | 0.8682784259055446 | 0.8653846153846154 | 0.862450639145807  |   156   |\n",
      "| weighted avg | 0.8682784259055446 | 0.8653846153846154 | 0.862450639145807  |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8653846153846154\n"
     ]
    }
   ],
   "source": [
    "SVM_cross_validation(xFC,yFC,5,\"rbf\",True, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUnhnBlL1Bj9"
   },
   "source": [
    "KNN\n",
    "\n",
    "k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RVdbAfGF1A3y",
    "outputId": "2b64813e-6649-436c-e264-a0aeae914beb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.73      0.80        11\n",
      "           2       0.83      1.00      0.91        10\n",
      "           3       0.82      0.82      0.82        11\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.85      0.85      0.84        32\n",
      "weighted avg       0.85      0.84      0.84        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.55      0.71        11\n",
      "           2       0.91      1.00      0.95        10\n",
      "           3       0.71      1.00      0.83        10\n",
      "\n",
      "    accuracy                           0.84        31\n",
      "   macro avg       0.87      0.85      0.83        31\n",
      "weighted avg       0.88      0.84      0.83        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.70      0.78        10\n",
      "           2       1.00      0.91      0.95        11\n",
      "           3       0.77      1.00      0.87        10\n",
      "\n",
      "    accuracy                           0.87        31\n",
      "   macro avg       0.88      0.87      0.87        31\n",
      "weighted avg       0.89      0.87      0.87        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.60      0.60        10\n",
      "           2       0.92      1.00      0.96        11\n",
      "           3       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.74        31\n",
      "   macro avg       0.73      0.73      0.73        31\n",
      "weighted avg       0.73      0.74      0.74        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.60      0.60        10\n",
      "           2       0.91      1.00      0.95        10\n",
      "           3       0.70      0.64      0.67        11\n",
      "\n",
      "    accuracy                           0.74        31\n",
      "   macro avg       0.74      0.75      0.74        31\n",
      "weighted avg       0.74      0.74      0.74        31\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7674418604651163 | 0.6346153846153846 | 0.6947368421052632 |    52   |\n",
      "|      2       | 0.9107142857142857 | 0.9807692307692307 | 0.9444444444444444 |    52   |\n",
      "|      3       | 0.7368421052631579 | 0.8076923076923077 | 0.7706422018348624 |    52   |\n",
      "|  macro avg   |  0.80499941714752  | 0.8076923076923078 | 0.8032744961281901 |   156   |\n",
      "| weighted avg | 0.8049994171475199 | 0.8076923076923077 |  0.80327449612819  |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8076923076923077\n"
     ]
    }
   ],
   "source": [
    "KNN_cross_validation(xFC,yFC,5,5,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsys3-JH1cnf"
   },
   "source": [
    "MLP 5 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CvTVF_Mi1gGn",
    "outputId": "53a8aa19-f020-405a-b684-3ad720f8df16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.64      0.67        11\n",
      "           2       0.91      1.00      0.95        10\n",
      "           3       0.73      0.73      0.73        11\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.78      0.79      0.78        32\n",
      "weighted avg       0.77      0.78      0.78        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.73      0.80        11\n",
      "           2       1.00      1.00      1.00        10\n",
      "           3       0.75      0.90      0.82        10\n",
      "\n",
      "    accuracy                           0.87        31\n",
      "   macro avg       0.88      0.88      0.87        31\n",
      "weighted avg       0.88      0.87      0.87        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.70      0.64        10\n",
      "           2       1.00      0.91      0.95        11\n",
      "           3       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.71        31\n",
      "   macro avg       0.71      0.70      0.71        31\n",
      "weighted avg       0.72      0.71      0.71        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.60      0.57        10\n",
      "           2       0.91      0.91      0.91        11\n",
      "           3       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.68        31\n",
      "   macro avg       0.67      0.67      0.67        31\n",
      "weighted avg       0.68      0.68      0.68        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.60      0.75        10\n",
      "           2       1.00      0.90      0.95        10\n",
      "           3       0.69      1.00      0.81        11\n",
      "\n",
      "    accuracy                           0.84        31\n",
      "   macro avg       0.90      0.83      0.84        31\n",
      "weighted avg       0.89      0.84      0.84        31\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7083333333333334 | 0.6538461538461539 |        0.68        |    52   |\n",
      "|      2       | 0.9607843137254902 | 0.9423076923076923 | 0.9514563106796117 |    52   |\n",
      "|      3       | 0.6666666666666666 | 0.7307692307692307 | 0.6972477064220183 |    52   |\n",
      "|  macro avg   | 0.7785947712418301 | 0.7756410256410257 |  0.77623467236721  |   156   |\n",
      "| weighted avg | 0.7785947712418301 | 0.7756410256410257 |  0.77623467236721  |   156   |\n",
      "|   Accuracy   |                    |                    | 0.7756410256410257 |         |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "perceptron(xFC,yFC,(5,5,5,5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLSdGx5jR15q"
   },
   "source": [
    "2. Seleccione dos modelos de clasificación no vistos en clase, y evalúelos con sus conjuntos de datos. Calcule tanto la exactitud, la precisión por clase y el recall por clase para cada uno de los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbCeeJ3D2As_"
   },
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tEuMpxAj2CFH",
    "outputId": "1d6f4408-297d-4085-ed95-f63f2949ab07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.73      0.67        11\n",
      "           2       0.89      0.80      0.84        10\n",
      "           3       0.70      0.64      0.67        11\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.73      0.72      0.73        32\n",
      "weighted avg       0.73      0.72      0.72        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.27      0.37        11\n",
      "           2       0.82      0.90      0.86        10\n",
      "           3       0.53      0.80      0.64        10\n",
      "\n",
      "    accuracy                           0.65        31\n",
      "   macro avg       0.65      0.66      0.62        31\n",
      "weighted avg       0.65      0.65      0.62        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.50      0.50        10\n",
      "           2       0.80      0.73      0.76        11\n",
      "           3       0.73      0.80      0.76        10\n",
      "\n",
      "    accuracy                           0.68        31\n",
      "   macro avg       0.68      0.68      0.67        31\n",
      "weighted avg       0.68      0.68      0.68        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.60      0.67        10\n",
      "           2       0.80      0.73      0.76        11\n",
      "           3       0.69      0.90      0.78        10\n",
      "\n",
      "    accuracy                           0.74        31\n",
      "   macro avg       0.75      0.74      0.74        31\n",
      "weighted avg       0.75      0.74      0.74        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.60      0.60        10\n",
      "           2       0.82      0.90      0.86        10\n",
      "           3       0.70      0.64      0.67        11\n",
      "\n",
      "    accuracy                           0.71        31\n",
      "   macro avg       0.71      0.71      0.71        31\n",
      "weighted avg       0.71      0.71      0.71        31\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.6086956521739131 | 0.5384615384615384 | 0.5714285714285715 |    52   |\n",
      "|      2       | 0.8235294117647058 | 0.8076923076923077 | 0.8155339805825242 |    52   |\n",
      "|      3       | 0.6610169491525424 |        0.75        | 0.7027027027027027 |    52   |\n",
      "|  macro avg   | 0.6977473376970537 | 0.6987179487179488 | 0.6965550849045995 |   156   |\n",
      "| weighted avg | 0.6977473376970538 | 0.6987179487179487 | 0.6965550849045994 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.6987179487179487\n"
     ]
    }
   ],
   "source": [
    "dtc_cross_validation(xFC,yFC,5, True, 'gini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TADlDcb02Ks1"
   },
   "source": [
    "XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wdY71STt2KHH",
    "outputId": "c595fa1f-11a7-47ac-ebde-665b74e996d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.64      0.78        11\n",
      "           2       1.00      1.00      1.00        10\n",
      "           3       0.73      1.00      0.85        11\n",
      "\n",
      "    accuracy                           0.88        32\n",
      "   macro avg       0.91      0.88      0.87        32\n",
      "weighted avg       0.91      0.88      0.87        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.82      0.78        11\n",
      "           2       1.00      1.00      1.00        10\n",
      "           3       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.84        31\n",
      "   macro avg       0.84      0.84      0.84        31\n",
      "weighted avg       0.84      0.84      0.84        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.70      0.78        10\n",
      "           2       0.91      0.91      0.91        11\n",
      "           3       0.75      0.90      0.82        10\n",
      "\n",
      "    accuracy                           0.84        31\n",
      "   macro avg       0.84      0.84      0.84        31\n",
      "weighted avg       0.85      0.84      0.84        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.80      0.76        10\n",
      "           2       1.00      0.82      0.90        11\n",
      "           3       0.73      0.80      0.76        10\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.82      0.81      0.81        31\n",
      "weighted avg       0.82      0.81      0.81        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.70      0.78        10\n",
      "           2       0.82      0.90      0.86        10\n",
      "           3       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.84        31\n",
      "   macro avg       0.84      0.84      0.83        31\n",
      "weighted avg       0.84      0.84      0.84        31\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8260869565217391 | 0.7307692307692307 | 0.7755102040816326 |    52   |\n",
      "|      2       | 0.9411764705882353 | 0.9230769230769231 | 0.9320388349514563 |    52   |\n",
      "|      3       | 0.7627118644067796 | 0.8653846153846154 | 0.8108108108108109 |    52   |\n",
      "|  macro avg   | 0.8433250971722513 | 0.8397435897435898 |  0.8394532832813   |   156   |\n",
      "| weighted avg | 0.8433250971722515 | 0.8397435897435898 | 0.8394532832812999 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8397435897435898\n"
     ]
    }
   ],
   "source": [
    "XGB_cross_validation(xFC,yFC,5, True, 'gbtree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmI-eywOBH4-"
   },
   "source": [
    "El mejor modelo de clasificación para este grupo de datos es SVM base radial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8pjDconvRzKU"
   },
   "source": [
    "3. Indique qué modelos de clasificación de los que evaluó anteriormente tienen hiperparámetros y cuáles son éstos en cada caso. Seleccione uno de estos clasificadores, y determine sus hiperparámetros óptimos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOr0x7ifDGug"
   },
   "source": [
    "1.   ***SVM***\n",
    "  *   **C**: Es el parámetro que controla la relación el tamaño del margen (valor grande de 𝐶 ocasiona un margen pequeño, y un valor grande de 𝐶 conduce a un margen grande).\n",
    "2.   ***KNN***\n",
    "  *   **k**: Representa el número de vecinos más cercanos que se utilizan para la clasificación. Seleccionar un valor adecuado para k es importante, ya que un valor bajo puede llevar a un modelo demasiado sensible al ruido y un valor alto puede llevar a un modelo demasiado generalizado.\n",
    "3.   ***MLP***\n",
    "  *   **hidden_layer_sizes**: Especifica la arquitectura de la red neuronal, es decir, el número de neuronas en cada capa oculta.\n",
    "4.   ***Decision Tree Classifier***\n",
    "  *   **max_depth**: Determina la profundidad máxima del árbol de decisión.\n",
    "  *   **criterion**: Es el encargado de medir la uniformidad de los nodos, uniformidad quiere decir que las cosas que son similares deben estar juntas y las que son diferentes deben separarse y distinguirse claramente unas de otras. se puede elegir el mse/mae/friedman_mse para regresión y gini/entropy para clasificación.\n",
    "  *   **min_samples_split**: el número mínimo de datos requeridos por un nodo para realizar una división.\n",
    "5.   ***XGBoost Classifier***\n",
    "  *   **n_estimators**: Representa el número de árboles que se utilizarán en el modelo. Cuanto mayor sea este valor, más complejo será el modelo y más tiempo requerirá el entrenamiento. Sin embargo, un número demasiado alto puede llevar a un sobreajuste.\n",
    "  *   **booster**: El tipo de modelo de clasificación usado, por defecto gbtree.\n",
    "  *   **max_depth**: “Profundidad” o número de nodos de bifurcación de los árboles de decisión usados en el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yy15BTAI3UST"
   },
   "source": [
    "Hiperparámetro SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B3aVBVuZ3PmP",
    "outputId": "41cf0b78-aa96-44a1-9a1e-3177490ed19d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C =  0.01\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+---------------------+---------------------+---------+\n",
      "|    Clase     |     Precisión      |        Recall       |      Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+---------------------+---------------------+---------+\n",
      "|      1       | 0.4666666666666667 | 0.40384615384615385 | 0.43298969072164945 |    52   |\n",
      "|      2       |      0.46875       |  0.5769230769230769 |  0.5172413793103449 |    52   |\n",
      "|      3       | 0.5957446808510638 |  0.5384615384615384 |  0.5656565656565657 |    52   |\n",
      "|  macro avg   | 0.5103871158392436 |  0.5064102564102564 |  0.5052958785628533 |   156   |\n",
      "| weighted avg | 0.5103871158392435 |  0.5064102564102564 |  0.5052958785628533 |   156   |\n",
      "+--------------+--------------------+---------------------+---------------------+---------+\n",
      "\n",
      "Accuracy =  0.5064102564102564\n",
      "\n",
      "C =  0.03\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+---------------------+---------------------+---------+\n",
      "|    Clase     |     Precisión      |        Recall       |      Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+---------------------+---------------------+---------+\n",
      "|      1       | 0.4444444444444444 | 0.38461538461538464 |  0.4123711340206186 |    52   |\n",
      "|      2       | 0.4838709677419355 |  0.5769230769230769 |  0.5263157894736842 |    52   |\n",
      "|      3       | 0.5306122448979592 |         0.5         |  0.5148514851485149 |    52   |\n",
      "|  macro avg   | 0.486309219028113  | 0.48717948717948717 |  0.4845128028809392 |   156   |\n",
      "| weighted avg | 0.4863092190281131 | 0.48717948717948717 | 0.48451280288093923 |   156   |\n",
      "+--------------+--------------------+---------------------+---------------------+---------+\n",
      "\n",
      "Accuracy =  0.48717948717948717\n",
      "\n",
      "C =  0.05\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+---------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |        Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+---------------------+--------------------+---------+\n",
      "|      1       | 0.5581395348837209 | 0.46153846153846156 | 0.5052631578947369 |    52   |\n",
      "|      2       | 0.5357142857142857 |  0.5769230769230769 | 0.5555555555555555 |    52   |\n",
      "|      3       | 0.5263157894736842 |  0.5769230769230769 | 0.5504587155963302 |    52   |\n",
      "|  macro avg   | 0.5400565366905635 |  0.5384615384615384 | 0.5370924763488741 |   156   |\n",
      "| weighted avg | 0.5400565366905636 |  0.5384615384615384 | 0.5370924763488741 |   156   |\n",
      "+--------------+--------------------+---------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.5384615384615384\n",
      "\n",
      "C =  0.07\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+---------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |        Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+---------------------+--------------------+---------+\n",
      "|      1       | 0.5217391304347826 | 0.46153846153846156 | 0.4897959183673469 |    52   |\n",
      "|      2       | 0.5370370370370371 |  0.5576923076923077 | 0.5471698113207548 |    52   |\n",
      "|      3       |        0.5         |  0.5384615384615384 | 0.5185185185185186 |    52   |\n",
      "|  macro avg   | 0.5195920558239399 |  0.5192307692307692 | 0.5184947494022069 |   156   |\n",
      "| weighted avg | 0.5195920558239399 |  0.5192307692307693 | 0.5184947494022069 |   156   |\n",
      "+--------------+--------------------+---------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.5192307692307693\n",
      "\n",
      "C =  0.09\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+---------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |      Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+---------------------+--------------------+--------------------+---------+\n",
      "|      1       |  0.5652173913043478 |        0.5         | 0.5306122448979592 |    52   |\n",
      "|      2       |  0.5084745762711864 | 0.5769230769230769 | 0.5405405405405405 |    52   |\n",
      "|      3       | 0.49019607843137253 | 0.4807692307692308 | 0.4854368932038835 |    52   |\n",
      "|  macro avg   |  0.5212960153356355 | 0.5192307692307693 | 0.5188632262141277 |   156   |\n",
      "| weighted avg |  0.5212960153356355 | 0.5192307692307693 | 0.5188632262141277 |   156   |\n",
      "+--------------+---------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.5192307692307693\n",
      "\n",
      "C =  0.11\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.5416666666666666 |        0.5         |        0.52        |    52   |\n",
      "|      2       | 0.6530612244897959 | 0.6153846153846154 | 0.6336633663366337 |    52   |\n",
      "|      3       | 0.576271186440678  | 0.6538461538461539 | 0.6126126126126126 |    52   |\n",
      "|  macro avg   | 0.5903330258657135 | 0.5897435897435898 | 0.5887586596497488 |   156   |\n",
      "| weighted avg | 0.5903330258657135 | 0.5897435897435898 | 0.5887586596497487 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.5897435897435898\n",
      "\n",
      "C =  0.13\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.6666666666666666 | 0.5384615384615384 | 0.5957446808510638 |    52   |\n",
      "|      2       | 0.7868852459016393 | 0.9230769230769231 | 0.8495575221238939 |    52   |\n",
      "|      3       | 0.6792452830188679 | 0.6923076923076923 | 0.6857142857142857 |    52   |\n",
      "|  macro avg   | 0.7109323985290579 | 0.7179487179487181 | 0.7103388295630811 |   156   |\n",
      "| weighted avg | 0.7109323985290579 | 0.717948717948718  | 0.7103388295630811 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.717948717948718\n",
      "\n",
      "C =  0.15\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.6888888888888889 | 0.5961538461538461 | 0.6391752577319588 |    52   |\n",
      "|      2       | 0.8909090909090909 | 0.9423076923076923 | 0.9158878504672897 |    52   |\n",
      "|      3       | 0.6964285714285714 |        0.75        | 0.7222222222222223 |    52   |\n",
      "|  macro avg   | 0.7587421837421836 | 0.7628205128205128 | 0.7590951101404902 |   156   |\n",
      "| weighted avg | 0.7587421837421837 | 0.7628205128205128 | 0.7590951101404902 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7628205128205128\n",
      "\n",
      "C =  0.17\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7857142857142857 | 0.6346153846153846 | 0.7021276595744681 |    52   |\n",
      "|      2       | 0.8928571428571429 | 0.9615384615384616 | 0.9259259259259259 |    52   |\n",
      "|      3       | 0.7413793103448276 | 0.8269230769230769 | 0.7818181818181817 |    52   |\n",
      "|  macro avg   | 0.8066502463054187 | 0.8076923076923078 | 0.8032905891061919 |   156   |\n",
      "| weighted avg | 0.8066502463054187 | 0.8076923076923077 | 0.8032905891061919 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8076923076923077\n",
      "\n",
      "C =  0.19\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       |       0.825        | 0.6346153846153846 | 0.717391304347826  |    52   |\n",
      "|      2       | 0.8793103448275862 | 0.9807692307692307 | 0.9272727272727272 |    52   |\n",
      "|      3       | 0.7413793103448276 | 0.8269230769230769 | 0.7818181818181817 |    52   |\n",
      "|  macro avg   | 0.8152298850574713 | 0.8141025641025642 | 0.8088274044795783 |   156   |\n",
      "| weighted avg | 0.8152298850574713 | 0.8141025641025641 | 0.8088274044795783 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8141025641025641\n",
      "\n",
      "C =  0.21\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8421052631578947 | 0.6153846153846154 | 0.7111111111111111 |    52   |\n",
      "|      2       | 0.8947368421052632 | 0.9807692307692307 | 0.9357798165137614 |    52   |\n",
      "|      3       | 0.7377049180327869 | 0.8653846153846154 | 0.7964601769911505 |    52   |\n",
      "|  macro avg   | 0.824849007765315  | 0.8205128205128206 | 0.8144503682053409 |   156   |\n",
      "| weighted avg | 0.824849007765315  | 0.8205128205128205 | 0.8144503682053411 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8205128205128205\n",
      "\n",
      "C =  0.23\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8157894736842105 | 0.5961538461538461 | 0.6888888888888889 |    52   |\n",
      "|      2       | 0.8928571428571429 | 0.9615384615384616 | 0.9259259259259259 |    52   |\n",
      "|      3       | 0.7258064516129032 | 0.8653846153846154 | 0.7894736842105263 |    52   |\n",
      "|  macro avg   | 0.811484356051419  | 0.8076923076923078 | 0.8014294996751138 |   156   |\n",
      "| weighted avg | 0.8114843560514189 | 0.8076923076923077 | 0.8014294996751138 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8076923076923077\n",
      "\n",
      "C =  0.25\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8333333333333334 | 0.6730769230769231 |  0.74468085106383  |    52   |\n",
      "|      2       | 0.8620689655172413 | 0.9615384615384616 | 0.9090909090909091 |    52   |\n",
      "|      3       | 0.7678571428571429 | 0.8269230769230769 | 0.7962962962962962 |    52   |\n",
      "|  macro avg   | 0.8210864805692392 | 0.8205128205128206 | 0.8166893521503451 |   156   |\n",
      "| weighted avg | 0.8210864805692393 | 0.8205128205128205 | 0.8166893521503451 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8205128205128205\n",
      "\n",
      "C =  0.27\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       |       0.825        | 0.6346153846153846 | 0.717391304347826  |    52   |\n",
      "|      2       | 0.8771929824561403 | 0.9615384615384616 | 0.9174311926605504 |    52   |\n",
      "|      3       | 0.7457627118644068 | 0.8461538461538461 | 0.7927927927927929 |    52   |\n",
      "|  macro avg   | 0.8159852314401824 | 0.8141025641025642 | 0.8092050966003898 |   156   |\n",
      "| weighted avg | 0.8159852314401823 | 0.8141025641025641 | 0.8092050966003898 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8141025641025641\n",
      "\n",
      "C =  0.29\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8292682926829268 | 0.6538461538461539 | 0.7311827956989247 |    52   |\n",
      "|      2       | 0.9107142857142857 | 0.9807692307692307 | 0.9444444444444444 |    52   |\n",
      "|      3       | 0.7627118644067796 | 0.8653846153846154 | 0.8108108108108109 |    52   |\n",
      "|  macro avg   | 0.834231480934664  | 0.8333333333333334 | 0.8288126836513934 |   156   |\n",
      "| weighted avg | 0.834231480934664  | 0.8333333333333334 | 0.8288126836513933 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8333333333333334\n",
      "\n",
      "C =  0.31\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       |       0.825        | 0.6346153846153846 | 0.717391304347826  |    52   |\n",
      "|      2       | 0.9107142857142857 | 0.9807692307692307 | 0.9444444444444444 |    52   |\n",
      "|      3       |        0.75        | 0.8653846153846154 | 0.8035714285714286 |    52   |\n",
      "|  macro avg   | 0.8285714285714286 | 0.826923076923077  | 0.8218023924545662 |   156   |\n",
      "| weighted avg | 0.8285714285714286 | 0.8269230769230769 | 0.8218023924545662 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8269230769230769\n",
      "\n",
      "C =  0.33\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       |       0.825        | 0.6346153846153846 | 0.717391304347826  |    52   |\n",
      "|      2       | 0.8928571428571429 | 0.9615384615384616 | 0.9259259259259259 |    52   |\n",
      "|      3       |        0.75        | 0.8653846153846154 | 0.8035714285714286 |    52   |\n",
      "|  macro avg   | 0.8226190476190477 | 0.8205128205128206 | 0.8156295529483936 |   156   |\n",
      "| weighted avg | 0.8226190476190476 | 0.8205128205128205 | 0.8156295529483933 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8205128205128205\n",
      "\n",
      "C =  0.35\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8536585365853658 | 0.6730769230769231 | 0.7526881720430108 |    52   |\n",
      "|      2       | 0.9272727272727272 | 0.9807692307692307 | 0.9532710280373831 |    52   |\n",
      "|      3       |        0.75        | 0.8653846153846154 | 0.8035714285714286 |    52   |\n",
      "|  macro avg   | 0.8436437546193644 | 0.8397435897435898 | 0.8365102095506075 |   156   |\n",
      "| weighted avg | 0.8436437546193645 | 0.8397435897435898 | 0.8365102095506074 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8397435897435898\n",
      "\n",
      "C =  0.37\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8333333333333334 | 0.6730769230769231 |  0.74468085106383  |    52   |\n",
      "|      2       | 0.9090909090909091 | 0.9615384615384616 | 0.9345794392523366 |    52   |\n",
      "|      3       | 0.7627118644067796 | 0.8653846153846154 | 0.8108108108108109 |    52   |\n",
      "|  macro avg   | 0.835045368943674  | 0.8333333333333334 | 0.8300237003756591 |   156   |\n",
      "| weighted avg | 0.835045368943674  | 0.8333333333333334 | 0.8300237003756592 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8333333333333334\n",
      "\n",
      "C =  0.39\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8461538461538461 | 0.6346153846153846 | 0.7252747252747251 |    52   |\n",
      "|      2       | 0.896551724137931  |        1.0         | 0.9454545454545454 |    52   |\n",
      "|      3       | 0.7627118644067796 | 0.8653846153846154 | 0.8108108108108109 |    52   |\n",
      "|  macro avg   | 0.8351391448995189 | 0.8333333333333334 | 0.8271800271800273 |   156   |\n",
      "| weighted avg | 0.8351391448995188 | 0.8333333333333334 | 0.8271800271800271 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8333333333333334\n",
      "\n",
      "C =  0.41\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8292682926829268 | 0.6538461538461539 | 0.7311827956989247 |    52   |\n",
      "|      2       | 0.9090909090909091 | 0.9615384615384616 | 0.9345794392523366 |    52   |\n",
      "|      3       |        0.75        | 0.8653846153846154 | 0.8035714285714286 |    52   |\n",
      "|  macro avg   | 0.8294530672579453 | 0.826923076923077  |  0.82311122117423  |   156   |\n",
      "| weighted avg | 0.8294530672579452 | 0.8269230769230769 |  0.82311122117423  |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8269230769230769\n",
      "\n",
      "C =  0.43\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       |       0.825        | 0.6346153846153846 | 0.717391304347826  |    52   |\n",
      "|      2       | 0.8928571428571429 | 0.9615384615384616 | 0.9259259259259259 |    52   |\n",
      "|      3       |        0.75        | 0.8653846153846154 | 0.8035714285714286 |    52   |\n",
      "|  macro avg   | 0.8226190476190477 | 0.8205128205128206 | 0.8156295529483936 |   156   |\n",
      "| weighted avg | 0.8226190476190476 | 0.8205128205128205 | 0.8156295529483933 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8205128205128205\n",
      "\n",
      "C =  0.45\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8536585365853658 | 0.6730769230769231 | 0.7526881720430108 |    52   |\n",
      "|      2       | 0.9285714285714286 |        1.0         | 0.962962962962963  |    52   |\n",
      "|      3       | 0.7627118644067796 | 0.8653846153846154 | 0.8108108108108109 |    52   |\n",
      "|  macro avg   | 0.848313943187858  | 0.8461538461538461 | 0.8421539819389282 |   156   |\n",
      "| weighted avg | 0.8483139431878579 | 0.8461538461538461 | 0.8421539819389283 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8461538461538461\n",
      "\n",
      "C =  0.47\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8333333333333334 | 0.6730769230769231 |  0.74468085106383  |    52   |\n",
      "|      2       | 0.9259259259259259 | 0.9615384615384616 | 0.9433962264150944 |    52   |\n",
      "|      3       |        0.75        | 0.8653846153846154 | 0.8035714285714286 |    52   |\n",
      "|  macro avg   | 0.8364197530864198 | 0.8333333333333334 | 0.8305495020167845 |   156   |\n",
      "| weighted avg | 0.8364197530864197 | 0.8333333333333334 | 0.8305495020167842 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8333333333333334\n",
      "\n",
      "C =  0.49\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8292682926829268 | 0.6538461538461539 | 0.7311827956989247 |    52   |\n",
      "|      2       | 0.9090909090909091 | 0.9615384615384616 | 0.9345794392523366 |    52   |\n",
      "|      3       | 0.7666666666666667 | 0.8846153846153846 | 0.8214285714285715 |    52   |\n",
      "|  macro avg   | 0.8350086228135009 | 0.8333333333333334 | 0.8290636021266109 |   156   |\n",
      "| weighted avg | 0.8350086228135007 | 0.8333333333333334 | 0.829063602126611  |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8333333333333334\n",
      "\n",
      "C =  0.51\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8333333333333334 | 0.6730769230769231 |  0.74468085106383  |    52   |\n",
      "|      2       | 0.9090909090909091 | 0.9615384615384616 | 0.9345794392523366 |    52   |\n",
      "|      3       | 0.7627118644067796 | 0.8653846153846154 | 0.8108108108108109 |    52   |\n",
      "|  macro avg   | 0.835045368943674  | 0.8333333333333334 | 0.8300237003756591 |   156   |\n",
      "| weighted avg | 0.835045368943674  | 0.8333333333333334 | 0.8300237003756592 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8333333333333334\n",
      "\n",
      "C =  0.53\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       |        0.85        | 0.6538461538461539 | 0.7391304347826088 |    52   |\n",
      "|      2       | 0.9272727272727272 | 0.9807692307692307 | 0.9532710280373831 |    52   |\n",
      "|      3       | 0.7540983606557377 | 0.8846153846153846 | 0.8141592920353982 |    52   |\n",
      "|  macro avg   | 0.8437903626428217 | 0.8397435897435898 | 0.8355202516184633 |   156   |\n",
      "| weighted avg | 0.8437903626428217 | 0.8397435897435898 | 0.8355202516184633 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8397435897435898\n",
      "\n",
      "C =  0.55\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8571428571428571 | 0.6923076923076923 | 0.7659574468085107 |    52   |\n",
      "|      2       | 0.9272727272727272 | 0.9807692307692307 | 0.9532710280373831 |    52   |\n",
      "|      3       | 0.7627118644067796 | 0.8653846153846154 | 0.8108108108108109 |    52   |\n",
      "|  macro avg   | 0.849042482940788  | 0.8461538461538461 | 0.843346428552235  |   156   |\n",
      "| weighted avg | 0.849042482940788  | 0.8461538461538461 | 0.8433464285522349 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8461538461538461\n",
      "\n",
      "C =  0.57\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8292682926829268 | 0.6538461538461539 | 0.7311827956989247 |    52   |\n",
      "|      2       | 0.9090909090909091 | 0.9615384615384616 | 0.9345794392523366 |    52   |\n",
      "|      3       |        0.75        | 0.8653846153846154 | 0.8035714285714286 |    52   |\n",
      "|  macro avg   | 0.8294530672579453 | 0.826923076923077  |  0.82311122117423  |   156   |\n",
      "| weighted avg | 0.8294530672579452 | 0.8269230769230769 |  0.82311122117423  |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8269230769230769\n",
      "\n",
      "C =  0.59\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8372093023255814 | 0.6923076923076923 | 0.7578947368421053 |    52   |\n",
      "|      2       | 0.9433962264150944 | 0.9615384615384616 | 0.9523809523809524 |    52   |\n",
      "|      3       | 0.7666666666666667 | 0.8846153846153846 | 0.8214285714285715 |    52   |\n",
      "|  macro avg   | 0.8490907318024474 | 0.8461538461538461 | 0.8439014202172097 |   156   |\n",
      "| weighted avg | 0.8490907318024474 | 0.8461538461538461 | 0.8439014202172097 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8461538461538461\n",
      "\n",
      "C =  0.61\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8333333333333334 | 0.6730769230769231 |  0.74468085106383  |    52   |\n",
      "|      2       | 0.9259259259259259 | 0.9615384615384616 | 0.9433962264150944 |    52   |\n",
      "|      3       | 0.7666666666666667 | 0.8846153846153846 | 0.8214285714285715 |    52   |\n",
      "|  macro avg   | 0.8419753086419753 | 0.8397435897435898 | 0.8365018829691654 |   156   |\n",
      "| weighted avg | 0.8419753086419752 | 0.8397435897435898 | 0.8365018829691653 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8397435897435898\n",
      "\n",
      "C =  0.63\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8571428571428571 | 0.6923076923076923 | 0.7659574468085107 |    52   |\n",
      "|      2       | 0.9444444444444444 | 0.9807692307692307 | 0.9622641509433962 |    52   |\n",
      "|      3       | 0.7666666666666667 | 0.8846153846153846 | 0.8214285714285715 |    52   |\n",
      "|  macro avg   | 0.856084656084656  | 0.8525641025641025 | 0.8498833897268262 |   156   |\n",
      "| weighted avg | 0.856084656084656  | 0.8525641025641025 | 0.8498833897268261 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8525641025641025\n",
      "\n",
      "C =  0.65\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8571428571428571 | 0.6923076923076923 | 0.7659574468085107 |    52   |\n",
      "|      2       | 0.9444444444444444 | 0.9807692307692307 | 0.9622641509433962 |    52   |\n",
      "|      3       | 0.7666666666666667 | 0.8846153846153846 | 0.8214285714285715 |    52   |\n",
      "|  macro avg   | 0.856084656084656  | 0.8525641025641025 | 0.8498833897268262 |   156   |\n",
      "| weighted avg | 0.856084656084656  | 0.8525641025641025 | 0.8498833897268261 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8525641025641025\n",
      "\n",
      "C =  0.67\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8372093023255814 | 0.6923076923076923 | 0.7578947368421053 |    52   |\n",
      "|      2       | 0.9090909090909091 | 0.9615384615384616 | 0.9345794392523366 |    52   |\n",
      "|      3       | 0.7758620689655172 | 0.8653846153846154 | 0.8181818181818181 |    52   |\n",
      "|  macro avg   | 0.8407207601273359 | 0.8397435897435898 | 0.8368853314254201 |   156   |\n",
      "| weighted avg | 0.8407207601273359 | 0.8397435897435898 | 0.8368853314254199 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8397435897435898\n",
      "\n",
      "C =  0.69\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8372093023255814 | 0.6923076923076923 | 0.7578947368421053 |    52   |\n",
      "|      2       | 0.9433962264150944 | 0.9615384615384616 | 0.9523809523809524 |    52   |\n",
      "|      3       | 0.7666666666666667 | 0.8846153846153846 | 0.8214285714285715 |    52   |\n",
      "|  macro avg   | 0.8490907318024474 | 0.8461538461538461 | 0.8439014202172097 |   156   |\n",
      "| weighted avg | 0.8490907318024474 | 0.8461538461538461 | 0.8439014202172097 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8461538461538461\n",
      "\n",
      "C =  0.71\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8571428571428571 | 0.6923076923076923 | 0.7659574468085107 |    52   |\n",
      "|      2       | 0.9444444444444444 | 0.9807692307692307 | 0.9622641509433962 |    52   |\n",
      "|      3       | 0.7666666666666667 | 0.8846153846153846 | 0.8214285714285715 |    52   |\n",
      "|  macro avg   | 0.856084656084656  | 0.8525641025641025 | 0.8498833897268262 |   156   |\n",
      "| weighted avg | 0.856084656084656  | 0.8525641025641025 | 0.8498833897268261 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8525641025641025\n",
      "\n",
      "C =  0.73\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8571428571428571 | 0.6923076923076923 | 0.7659574468085107 |    52   |\n",
      "|      2       | 0.9272727272727272 | 0.9807692307692307 | 0.9532710280373831 |    52   |\n",
      "|      3       | 0.7796610169491526 | 0.8846153846153846 | 0.8288288288288288 |    52   |\n",
      "|  macro avg   | 0.8546922004549123 | 0.8525641025641025 | 0.8493524345582409 |   156   |\n",
      "| weighted avg | 0.8546922004549122 | 0.8525641025641025 | 0.8493524345582409 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8525641025641025\n",
      "\n",
      "C =  0.75\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8604651162790697 | 0.7115384615384616 | 0.7789473684210527 |    52   |\n",
      "|      2       | 0.9272727272727272 | 0.9807692307692307 | 0.9532710280373831 |    52   |\n",
      "|      3       | 0.7758620689655172 | 0.8653846153846154 | 0.8181818181818181 |    52   |\n",
      "|  macro avg   | 0.854533304172438  | 0.8525641025641025 | 0.8501334048800846 |   156   |\n",
      "| weighted avg | 0.8545333041724381 | 0.8525641025641025 | 0.8501334048800846 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8525641025641025\n",
      "\n",
      "C =  0.77\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8571428571428571 | 0.6923076923076923 | 0.7659574468085107 |    52   |\n",
      "|      2       | 0.9272727272727272 | 0.9807692307692307 | 0.9532710280373831 |    52   |\n",
      "|      3       | 0.7796610169491526 | 0.8846153846153846 | 0.8288288288288288 |    52   |\n",
      "|  macro avg   | 0.8546922004549123 | 0.8525641025641025 | 0.8493524345582409 |   156   |\n",
      "| weighted avg | 0.8546922004549122 | 0.8525641025641025 | 0.8493524345582409 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8525641025641025\n",
      "\n",
      "C =  0.79\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8409090909090909 | 0.7115384615384616 | 0.7708333333333333 |    52   |\n",
      "|      2       | 0.9444444444444444 | 0.9807692307692307 | 0.9622641509433962 |    52   |\n",
      "|      3       | 0.7931034482758621 | 0.8846153846153846 | 0.8363636363636363 |    52   |\n",
      "|  macro avg   | 0.8594856612097992 | 0.8589743589743589 | 0.8564870402134552 |   156   |\n",
      "| weighted avg | 0.8594856612097991 | 0.8589743589743589 | 0.8564870402134553 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8589743589743589\n",
      "\n",
      "C =  0.81\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8809523809523809 | 0.7115384615384616 | 0.7872340425531914 |    52   |\n",
      "|      2       | 0.9444444444444444 | 0.9807692307692307 | 0.9622641509433962 |    52   |\n",
      "|      3       | 0.7833333333333333 | 0.9038461538461539 | 0.8392857142857143 |    52   |\n",
      "|  macro avg   | 0.8695767195767196 | 0.8653846153846154 | 0.8629279692607673 |   156   |\n",
      "| weighted avg | 0.8695767195767194 | 0.8653846153846154 | 0.8629279692607673 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8653846153846154\n",
      "\n",
      "C =  0.83\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8636363636363636 | 0.7307692307692307 | 0.7916666666666666 |    52   |\n",
      "|      2       | 0.9444444444444444 | 0.9807692307692307 | 0.9622641509433962 |    52   |\n",
      "|      3       | 0.8103448275862069 | 0.9038461538461539 | 0.8545454545454546 |    52   |\n",
      "|  macro avg   | 0.8728085452223383 | 0.8717948717948718 | 0.8694920907185058 |   156   |\n",
      "| weighted avg | 0.8728085452223383 | 0.8717948717948718 | 0.8694920907185059 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8717948717948718\n",
      "\n",
      "C =  0.85\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8409090909090909 | 0.7115384615384616 | 0.7708333333333333 |    52   |\n",
      "|      2       | 0.9433962264150944 | 0.9615384615384616 | 0.9523809523809524 |    52   |\n",
      "|      3       | 0.7796610169491526 | 0.8846153846153846 | 0.8288288288288288 |    52   |\n",
      "|  macro avg   | 0.8546554447577793 | 0.8525641025641025 | 0.8506810381810381 |   156   |\n",
      "| weighted avg | 0.8546554447577793 | 0.8525641025641025 | 0.8506810381810382 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8525641025641025\n",
      "\n",
      "C =  0.87\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8809523809523809 | 0.7115384615384616 | 0.7872340425531914 |    52   |\n",
      "|      2       | 0.9272727272727272 | 0.9807692307692307 | 0.9532710280373831 |    52   |\n",
      "|      3       | 0.7796610169491526 | 0.8846153846153846 | 0.8288288288288288 |    52   |\n",
      "|  macro avg   | 0.8626287083914203 | 0.8589743589743589 | 0.8564446331398011 |   156   |\n",
      "| weighted avg | 0.8626287083914201 | 0.8589743589743589 | 0.8564446331398011 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8589743589743589\n",
      "\n",
      "C =  0.89\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8636363636363636 | 0.7307692307692307 | 0.7916666666666666 |    52   |\n",
      "|      2       | 0.9107142857142857 | 0.9807692307692307 | 0.9444444444444444 |    52   |\n",
      "|      3       | 0.8035714285714286 | 0.8653846153846154 | 0.8333333333333334 |    52   |\n",
      "|  macro avg   | 0.8593073593073592 | 0.8589743589743589 | 0.8564814814814815 |   156   |\n",
      "| weighted avg | 0.8593073593073592 | 0.8589743589743589 | 0.8564814814814815 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8589743589743589\n",
      "\n",
      "C =  0.91\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8636363636363636 | 0.7307692307692307 | 0.7916666666666666 |    52   |\n",
      "|      2       | 0.9444444444444444 | 0.9807692307692307 | 0.9622641509433962 |    52   |\n",
      "|      3       | 0.7931034482758621 | 0.8846153846153846 | 0.8363636363636363 |    52   |\n",
      "|  macro avg   | 0.8670614187855566 | 0.8653846153846153 | 0.8634314846578998 |   156   |\n",
      "| weighted avg | 0.8670614187855568 | 0.8653846153846154 | 0.8634314846578997 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8653846153846154\n",
      "\n",
      "C =  0.93\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8444444444444444 | 0.7307692307692307 | 0.7835051546391751 |    52   |\n",
      "|      2       | 0.9433962264150944 | 0.9615384615384616 | 0.9523809523809524 |    52   |\n",
      "|      3       | 0.7931034482758621 | 0.8846153846153846 | 0.8363636363636363 |    52   |\n",
      "|  macro avg   | 0.860314706378467  | 0.8589743589743589 | 0.8574165811279214 |   156   |\n",
      "| weighted avg | 0.860314706378467  | 0.8589743589743589 | 0.8574165811279212 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8589743589743589\n",
      "\n",
      "C =  0.95\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8837209302325582 | 0.7307692307692307 |        0.8         |    52   |\n",
      "|      2       | 0.9444444444444444 | 0.9807692307692307 | 0.9622641509433962 |    52   |\n",
      "|      3       | 0.7796610169491526 | 0.8846153846153846 | 0.8288288288288288 |    52   |\n",
      "|  macro avg   | 0.8692754638753851 | 0.8653846153846153 | 0.863697659924075  |   156   |\n",
      "| weighted avg | 0.8692754638753851 | 0.8653846153846154 | 0.8636976599240751 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8653846153846154\n",
      "\n",
      "C =  0.97\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8604651162790697 | 0.7115384615384616 | 0.7789473684210527 |    52   |\n",
      "|      2       | 0.9444444444444444 | 0.9807692307692307 | 0.9622641509433962 |    52   |\n",
      "|      3       | 0.7796610169491526 | 0.8846153846153846 | 0.8288288288288288 |    52   |\n",
      "|  macro avg   | 0.861523525890889  | 0.8589743589743589 | 0.856680116064426  |   156   |\n",
      "| weighted avg | 0.861523525890889  | 0.8589743589743589 | 0.8566801160644258 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8589743589743589\n",
      "\n",
      "C =  0.99\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8409090909090909 | 0.7115384615384616 | 0.7708333333333333 |    52   |\n",
      "|      2       | 0.9272727272727272 | 0.9807692307692307 | 0.9532710280373831 |    52   |\n",
      "|      3       | 0.7719298245614035 | 0.8461538461538461 | 0.8073394495412844 |    52   |\n",
      "|  macro avg   | 0.8467038809144073 | 0.8461538461538461 | 0.8438146036373336 |   156   |\n",
      "| weighted avg | 0.8467038809144072 | 0.8461538461538461 | 0.8438146036373336 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "C=0.01\n",
    "\n",
    "\n",
    "while C <= 1:\n",
    "  print(\"\\nC = \",\"{:.2f}\".format(C))\n",
    "  SVM_cross_validation(xFC,yFC,5,\"rbf\", False, C)\n",
    "  C += 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWeo4cfmvclA"
   },
   "source": [
    "El óptimo valor para el hiperpárametro de C en SVM es de 0.83."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ao46ewMIR0b_"
   },
   "source": [
    "4. Para uno de los modelos de clasificación, aplique un método de selección de características. Indique cuantas características son suficientes para obtener buenos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "id": "TvfF3uyG3k0t",
    "outputId": "87348ddd-e784-4b26-c9c9-2be7cb18ea44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Filter feature selection, k = 1\n",
      "ACC:  0.6666666666666666 Recall:  [0.46153846 0.82692308 0.71153846] Precision:  [0.5106383  0.87755102 0.61666667]\n",
      "--------------- Filter feature selection, k = 2\n",
      "ACC:  0.6794871794871795 Recall:  [0.51923077 0.92307692 0.59615385] Precision:  [0.52941176 0.92307692 0.58490566]\n",
      "--------------- Filter feature selection, k = 3\n",
      "ACC:  0.7564102564102564 Recall:  [0.63461538 0.90384615 0.73076923] Precision:  [0.64705882 0.92156863 0.7037037 ]\n",
      "--------------- Filter feature selection, k = 4\n",
      "ACC:  0.6858974358974359 Recall:  [0.53846154 0.88461538 0.63461538] Precision:  [0.53846154 0.92       0.61111111]\n",
      "--------------- Filter feature selection, k = 5\n",
      "ACC:  0.6987179487179487 Recall:  [0.59615385 0.88461538 0.61538462] Precision:  [0.55357143 0.92       0.64      ]\n",
      "--------------- Filter feature selection, k = 6\n",
      "ACC:  0.7243589743589743 Recall:  [0.57692308 0.90384615 0.69230769] Precision:  [0.6122449  0.92156863 0.64285714]\n",
      "--------------- Filter feature selection, k = 7\n",
      "ACC:  0.7435897435897436 Recall:  [0.61538462 0.92307692 0.69230769] Precision:  [0.62745098 0.90566038 0.69230769]\n",
      "--------------- Filter feature selection, k = 8\n",
      "ACC:  0.7115384615384616 Recall:  [0.61538462 0.90384615 0.61538462] Precision:  [0.58181818 0.90384615 0.65306122]\n",
      "--------------- Filter feature selection, k = 9\n",
      "ACC:  0.7371794871794872 Recall:  [0.59615385 0.92307692 0.69230769] Precision:  [0.63265306 0.92307692 0.65454545]\n",
      "--------------- Filter feature selection, k = 10\n",
      "ACC:  0.7115384615384616 Recall:  [0.57692308 0.88461538 0.67307692] Precision:  [0.58823529 0.90196078 0.64814815]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the filter approach for feature selection\n",
    "ks = np.arange(1, 11, 1)\n",
    "accs = []\n",
    "clf = SVC(kernel='rbf')\n",
    "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for k in ks:\n",
    "    print('--------------- Filter feature selection, k =', k)\n",
    "\n",
    "    cv_y_test = []\n",
    "    cv_y_pred = []\n",
    "\n",
    "    for train_index, test_index in kf.split(xFC, yFC):\n",
    "\n",
    "       # Training phase\n",
    "        x_train = xFC[train_index, :]\n",
    "        y_train = yFC[train_index]\n",
    "\n",
    "        ffs = SelectKBest(mutual_info_classif, k=k)\n",
    "        ffs.fit(x_train, y_train)\n",
    "        x_train = ffs.transform(x_train)\n",
    "\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        # Test phase\n",
    "        x_test = ffs.transform(xFC[test_index, :])\n",
    "        y_test = yFC[test_index]\n",
    "        y_pred = clf.predict(x_test)\n",
    "\n",
    "        cv_y_test.append(y_test)\n",
    "        cv_y_pred.append(y_pred)\n",
    "\n",
    "    acc = accuracy_score(np.concatenate(cv_y_test), np.concatenate(cv_y_pred))\n",
    "    rec = recall_score(np.concatenate(cv_y_test), np.concatenate(cv_y_pred), average = None)\n",
    "    pre = precision_score(np.concatenate(cv_y_test), np.concatenate(cv_y_pred), average = None)\n",
    "\n",
    "    print('ACC: ', acc, 'Recall: ', rec, 'Precision: ', pre)\n",
    "    accs.append(acc)\n",
    "\n",
    "plt.plot(ks, accs)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Univariate filter for feature selection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CP6uTKHHBVXb"
   },
   "source": [
    "La mejor cantidad de características para este conjunto de datos es de 8 con una exactitud de 0.6094, lo cuál no es muy bueno. Esto significa que para que el modelo sea mejor, se necesita mayor número de características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gz57EJ1Q6Js6"
   },
   "source": [
    "**Clasificación de no tarea cognitiva vs tarea cognitiva**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "Mbtf9Tei6cF6",
    "outputId": "a7ca9e73-4431-4502-dc38-4988e2c9fa9c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-60ee7ccf-9245-4c69-a186-d396e440cf40\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2332</th>\n",
       "      <th>2333</th>\n",
       "      <th>2334</th>\n",
       "      <th>2335</th>\n",
       "      <th>2336</th>\n",
       "      <th>2337</th>\n",
       "      <th>2338</th>\n",
       "      <th>2339</th>\n",
       "      <th>2340</th>\n",
       "      <th>2341</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.316079</td>\n",
       "      <td>-0.569181</td>\n",
       "      <td>-0.840397</td>\n",
       "      <td>-2.263029</td>\n",
       "      <td>-0.477150</td>\n",
       "      <td>-0.473358</td>\n",
       "      <td>-1.639392</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.089592</td>\n",
       "      <td>-1.521619</td>\n",
       "      <td>-0.756561</td>\n",
       "      <td>-1.132632</td>\n",
       "      <td>-1.944529</td>\n",
       "      <td>-1.126415</td>\n",
       "      <td>-1.040056</td>\n",
       "      <td>-1.276589</td>\n",
       "      <td>-1.252492</td>\n",
       "      <td>-1.276102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.092858</td>\n",
       "      <td>-0.509809</td>\n",
       "      <td>-0.208803</td>\n",
       "      <td>0.182265</td>\n",
       "      <td>-1.280907</td>\n",
       "      <td>-0.332009</td>\n",
       "      <td>0.088508</td>\n",
       "      <td>-0.322166</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.129138</td>\n",
       "      <td>-1.549519</td>\n",
       "      <td>-1.534214</td>\n",
       "      <td>-0.629425</td>\n",
       "      <td>-1.352853</td>\n",
       "      <td>-0.975112</td>\n",
       "      <td>-1.168972</td>\n",
       "      <td>-2.116018</td>\n",
       "      <td>-1.773718</td>\n",
       "      <td>-1.474069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.924355</td>\n",
       "      <td>-1.020561</td>\n",
       "      <td>-0.608800</td>\n",
       "      <td>-1.923035</td>\n",
       "      <td>-1.002875</td>\n",
       "      <td>-0.927044</td>\n",
       "      <td>-0.946278</td>\n",
       "      <td>-0.433741</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.051609</td>\n",
       "      <td>-1.223329</td>\n",
       "      <td>-1.384643</td>\n",
       "      <td>-0.561653</td>\n",
       "      <td>-0.666955</td>\n",
       "      <td>-1.012405</td>\n",
       "      <td>-0.713106</td>\n",
       "      <td>-1.353017</td>\n",
       "      <td>-1.530745</td>\n",
       "      <td>-0.481837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.269049</td>\n",
       "      <td>-0.495929</td>\n",
       "      <td>-0.515496</td>\n",
       "      <td>-0.309277</td>\n",
       "      <td>-0.425367</td>\n",
       "      <td>-0.968869</td>\n",
       "      <td>-0.364516</td>\n",
       "      <td>-1.179716</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.825389</td>\n",
       "      <td>-0.510917</td>\n",
       "      <td>-0.676058</td>\n",
       "      <td>-0.091499</td>\n",
       "      <td>-0.740510</td>\n",
       "      <td>-0.497735</td>\n",
       "      <td>-0.659177</td>\n",
       "      <td>-1.753575</td>\n",
       "      <td>-0.644050</td>\n",
       "      <td>-0.541565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.174988</td>\n",
       "      <td>-0.915864</td>\n",
       "      <td>0.160994</td>\n",
       "      <td>-2.238067</td>\n",
       "      <td>-0.740315</td>\n",
       "      <td>-0.548436</td>\n",
       "      <td>0.227631</td>\n",
       "      <td>-0.112852</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.375743</td>\n",
       "      <td>-1.633402</td>\n",
       "      <td>-1.146866</td>\n",
       "      <td>-0.800723</td>\n",
       "      <td>-0.698990</td>\n",
       "      <td>-0.311886</td>\n",
       "      <td>-1.488918</td>\n",
       "      <td>-1.371906</td>\n",
       "      <td>-1.615953</td>\n",
       "      <td>-0.688520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2342 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60ee7ccf-9245-4c69-a186-d396e440cf40')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-60ee7ccf-9245-4c69-a186-d396e440cf40 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-60ee7ccf-9245-4c69-a186-d396e440cf40');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   0     1         2         3         4         5         6         7     \\\n",
       "0     1     1 -1.316079 -0.569181 -0.840397 -2.263029 -0.477150 -0.473358   \n",
       "1     1     1 -0.092858 -0.509809 -0.208803  0.182265 -1.280907 -0.332009   \n",
       "2     1     1 -0.924355 -1.020561 -0.608800 -1.923035 -1.002875 -0.927044   \n",
       "3     1     1 -0.269049 -0.495929 -0.515496 -0.309277 -0.425367 -0.968869   \n",
       "4     1     1  0.174988 -0.915864  0.160994 -2.238067 -0.740315 -0.548436   \n",
       "\n",
       "       8         9     ...      2332      2333      2334      2335      2336  \\\n",
       "0 -1.639392 -0.018691  ... -1.089592 -1.521619 -0.756561 -1.132632 -1.944529   \n",
       "1  0.088508 -0.322166  ... -1.129138 -1.549519 -1.534214 -0.629425 -1.352853   \n",
       "2 -0.946278 -0.433741  ... -1.051609 -1.223329 -1.384643 -0.561653 -0.666955   \n",
       "3 -0.364516 -1.179716  ... -0.825389 -0.510917 -0.676058 -0.091499 -0.740510   \n",
       "4  0.227631 -0.112852  ... -0.375743 -1.633402 -1.146866 -0.800723 -0.698990   \n",
       "\n",
       "       2337      2338      2339      2340      2341  \n",
       "0 -1.126415 -1.040056 -1.276589 -1.252492 -1.276102  \n",
       "1 -0.975112 -1.168972 -2.116018 -1.773718 -1.474069  \n",
       "2 -1.012405 -0.713106 -1.353017 -1.530745 -0.481837  \n",
       "3 -0.497735 -0.659177 -1.753575 -0.644050 -0.541565  \n",
       "4 -0.311886 -1.488918 -1.371906 -1.615953 -0.688520  \n",
       "\n",
       "[5 rows x 2342 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frank_cog= pd.read_csv(\"/Features_Frank_Cognitivo.txt\" , header=None, delimiter= \"\\t\")\n",
    "frank_cog = frank_cog.dropna(axis=1)\n",
    "frank_cog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "UizRUQId6khc"
   },
   "outputs": [],
   "source": [
    "transformacion = lambda x: 1 if 1 <= x <= 12 else 2\n",
    "frank_cog[0] = frank_cog[0].map(transformacion)\n",
    "xFC1 = frank_cog.iloc[:, 2:].values\n",
    "yFC1 = frank_cog.iloc[:, 0].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etslvJVS6yFv"
   },
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "lx20UgBz6xK0",
    "outputId": "ba463c61-f2a7-464a-d2ef-388021c271ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.88      0.86        32\n",
      "           2       0.78      0.74      0.76        19\n",
      "\n",
      "    accuracy                           0.82        51\n",
      "   macro avg       0.81      0.81      0.81        51\n",
      "weighted avg       0.82      0.82      0.82        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.97      0.86        31\n",
      "           2       0.92      0.55      0.69        20\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.84      0.76      0.77        51\n",
      "weighted avg       0.83      0.80      0.79        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.90      0.82        31\n",
      "           2       0.77      0.53      0.62        19\n",
      "\n",
      "    accuracy                           0.76        50\n",
      "   macro avg       0.76      0.71      0.72        50\n",
      "weighted avg       0.76      0.76      0.75        50\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.97      0.88        31\n",
      "           2       0.92      0.63      0.75        19\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.87      0.80      0.82        50\n",
      "weighted avg       0.85      0.84      0.83        50\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.90      0.89        31\n",
      "           2       0.83      0.79      0.81        19\n",
      "\n",
      "    accuracy                           0.86        50\n",
      "   macro avg       0.85      0.85      0.85        50\n",
      "weighted avg       0.86      0.86      0.86        50\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8089887640449438 | 0.9230769230769231 | 0.8622754491017964 |   156   |\n",
      "|      2       | 0.8378378378378378 | 0.6458333333333334 | 0.7294117647058824 |    96   |\n",
      "|  macro avg   | 0.8234133009413909 | 0.7844551282051282 | 0.7958436069038395 |   252   |\n",
      "| weighted avg | 0.8199788873946178 | 0.8174603174603174 | 0.8116607121890673 |   252   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8174603174603174\n"
     ]
    }
   ],
   "source": [
    "SVM_cross_validation(xFC1,yFC1,5,\"rbf\",True, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4pdOOu-60BQ"
   },
   "source": [
    "KNN\n",
    "\n",
    "k=13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7P8ftxE7GSU",
    "outputId": "364d13c4-e6ed-4601-fb28-5b90b962a70b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.78      0.79        32\n",
      "           2       0.65      0.68      0.67        19\n",
      "\n",
      "    accuracy                           0.75        51\n",
      "   macro avg       0.73      0.73      0.73        51\n",
      "weighted avg       0.75      0.75      0.75        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.81      0.75        31\n",
      "           2       0.60      0.45      0.51        20\n",
      "\n",
      "    accuracy                           0.67        51\n",
      "   macro avg       0.65      0.63      0.63        51\n",
      "weighted avg       0.66      0.67      0.66        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.74      0.72        31\n",
      "           2       0.53      0.47      0.50        19\n",
      "\n",
      "    accuracy                           0.64        50\n",
      "   macro avg       0.61      0.61      0.61        50\n",
      "weighted avg       0.63      0.64      0.64        50\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.81      0.86        31\n",
      "           2       0.74      0.89      0.81        19\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.83      0.85      0.84        50\n",
      "weighted avg       0.85      0.84      0.84        50\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.84      0.87        31\n",
      "           2       0.76      0.84      0.80        19\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.83      0.84      0.83        50\n",
      "weighted avg       0.85      0.84      0.84        50\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7948717948717948 | 0.7948717948717948 | 0.7948717948717948 |   156   |\n",
      "|      2       | 0.6666666666666666 | 0.6666666666666666 | 0.6666666666666666 |    96   |\n",
      "|  macro avg   | 0.7307692307692307 | 0.7307692307692307 | 0.7307692307692307 |   252   |\n",
      "| weighted avg | 0.746031746031746  | 0.746031746031746  | 0.746031746031746  |   252   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.746031746031746\n"
     ]
    }
   ],
   "source": [
    "KNN_cross_validation(xFC1,yFC1,5,13,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtD5_Pvr7A1Q"
   },
   "source": [
    "MLP 5 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQTzPR1I7BQR",
    "outputId": "ca21bac7-ff49-4256-f217-01438779d732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        32\n",
      "           2       0.37      1.00      0.54        19\n",
      "\n",
      "    accuracy                           0.37        51\n",
      "   macro avg       0.19      0.50      0.27        51\n",
      "weighted avg       0.14      0.37      0.20        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      1.00      0.76        31\n",
      "           2       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.61        51\n",
      "   macro avg       0.30      0.50      0.38        51\n",
      "weighted avg       0.37      0.61      0.46        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.65      0.70        31\n",
      "           2       0.54      0.68      0.60        19\n",
      "\n",
      "    accuracy                           0.66        50\n",
      "   macro avg       0.66      0.66      0.65        50\n",
      "weighted avg       0.68      0.66      0.66        50\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      1.00      0.79        31\n",
      "           2       1.00      0.16      0.27        19\n",
      "\n",
      "    accuracy                           0.68        50\n",
      "   macro avg       0.83      0.58      0.53        50\n",
      "weighted avg       0.79      0.68      0.60        50\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      1.00      0.77        31\n",
      "           2       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.62        50\n",
      "   macro avg       0.31      0.50      0.38        50\n",
      "weighted avg       0.38      0.62      0.47        50\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+---------------------+--------------------+---------------------+---------+\n",
      "|    Clase     |      Precisión      |       Recall       |      Puntaje F1     | Soporte |\n",
      "+--------------+---------------------+--------------------+---------------------+---------+\n",
      "|      1       |  0.6494252873563219 | 0.7243589743589743 |  0.6848484848484848 |   156   |\n",
      "|      2       | 0.44871794871794873 | 0.3645833333333333 | 0.40229885057471265 |    96   |\n",
      "|  macro avg   |  0.5490716180371353 | 0.5444711538461539 |  0.5435736677115988 |   252   |\n",
      "| weighted avg |  0.5729653488274178 | 0.5873015873015873 |  0.5772105289346668 |   252   |\n",
      "|   Accuracy   |                     |                    |  0.5873015873015873 |         |\n",
      "+--------------+---------------------+--------------------+---------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "perceptron(xFC1,yFC1,(5,5,5,5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmuxsYTd7bTq"
   },
   "source": [
    "2. Seleccione dos modelos de clasificación no vistos en clase, y evalúelos con sus conjuntos de datos. Calcule tanto la exactitud, la precisión por clase y el recall por clase para cada uno de los modelos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AAt3NDzW7cBP"
   },
   "source": [
    "Decission Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "u3pOUDC17cKo",
    "outputId": "57e234fd-95b4-4bc1-94ed-64d84d43426c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.72      0.71        32\n",
      "           2       0.50      0.47      0.49        19\n",
      "\n",
      "    accuracy                           0.63        51\n",
      "   macro avg       0.60      0.60      0.60        51\n",
      "weighted avg       0.62      0.63      0.63        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.74      0.77        31\n",
      "           2       0.64      0.70      0.67        20\n",
      "\n",
      "    accuracy                           0.73        51\n",
      "   macro avg       0.71      0.72      0.72        51\n",
      "weighted avg       0.73      0.73      0.73        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.65      0.67        31\n",
      "           2       0.48      0.53      0.50        19\n",
      "\n",
      "    accuracy                           0.60        50\n",
      "   macro avg       0.58      0.59      0.58        50\n",
      "weighted avg       0.61      0.60      0.60        50\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.81      0.82        31\n",
      "           2       0.70      0.74      0.72        19\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.77      0.77      0.77        50\n",
      "weighted avg       0.78      0.78      0.78        50\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.84      0.81        31\n",
      "           2       0.71      0.63      0.67        19\n",
      "\n",
      "    accuracy                           0.76        50\n",
      "   macro avg       0.75      0.74      0.74        50\n",
      "weighted avg       0.76      0.76      0.76        50\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7597402597402597 |        0.75        | 0.7548387096774193 |   156   |\n",
      "|      2       | 0.6020408163265306 | 0.6145833333333334 | 0.6082474226804124 |    96   |\n",
      "|  macro avg   | 0.6808905380333952 | 0.6822916666666667 | 0.6815430661789159 |   252   |\n",
      "| weighted avg | 0.6996642812969343 | 0.6984126984126984 | 0.6989944098690358 |   252   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.6984126984126984\n"
     ]
    }
   ],
   "source": [
    "dtc_cross_validation(xFC1,yFC1,5, True, 'gini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBa9iymT7tqZ"
   },
   "source": [
    "XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "8IaWEKWs7sp3",
    "outputId": "d8acd7ca-0fe3-4a67-9cbc-88237c3fcf0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.97      0.86        32\n",
      "           2       0.91      0.53      0.67        19\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.84      0.75      0.76        51\n",
      "weighted avg       0.82      0.80      0.79        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.94      0.89        31\n",
      "           2       0.88      0.75      0.81        20\n",
      "\n",
      "    accuracy                           0.86        51\n",
      "   macro avg       0.87      0.84      0.85        51\n",
      "weighted avg       0.86      0.86      0.86        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.90      0.81        31\n",
      "           2       0.75      0.47      0.58        19\n",
      "\n",
      "    accuracy                           0.74        50\n",
      "   macro avg       0.74      0.69      0.70        50\n",
      "weighted avg       0.74      0.74      0.72        50\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.81      0.79        31\n",
      "           2       0.67      0.63      0.65        19\n",
      "\n",
      "    accuracy                           0.74        50\n",
      "   macro avg       0.72      0.72      0.72        50\n",
      "weighted avg       0.74      0.74      0.74        50\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.84      0.80        31\n",
      "           2       0.69      0.58      0.63        19\n",
      "\n",
      "    accuracy                           0.74        50\n",
      "   macro avg       0.73      0.71      0.71        50\n",
      "weighted avg       0.74      0.74      0.73        50\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7808988764044944 | 0.8910256410256411 | 0.8323353293413175 |   156   |\n",
      "|      2       | 0.7702702702702703 |      0.59375       | 0.6705882352941177 |    96   |\n",
      "|  macro avg   | 0.7755845733373823 | 0.7423878205128205 | 0.7514617823177177 |   252   |\n",
      "| weighted avg | 0.7768498835914567 | 0.7777777777777778 | 0.770717388751908  |   252   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "XGB_cross_validation(xFC1,yFC1,5, True, 'gbtree')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SY1sTZjZC-On"
   },
   "source": [
    "El mejo clasificador para este conjunto de datos es SVM base radial con una exactitud de 0.79."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3uzwm0E73FJ"
   },
   "source": [
    "Hiperparámetro XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "kfyfFamb73gp",
    "outputId": "311ba714-733e-4111-b900-d319c26c44a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Para booster gbtree:\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8242424242424242 | 0.8717948717948718 | 0.8473520249221185 |   156   |\n",
      "|      2       | 0.7701149425287356 | 0.6979166666666666 | 0.7322404371584699 |    96   |\n",
      "|  macro avg   | 0.7971786833855798 | 0.7848557692307692 | 0.7897962310402942 |   252   |\n",
      "| weighted avg | 0.803622431208638  | 0.8055555555555556 | 0.8034999914883475 |   252   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8055555555555556\n",
      "\n",
      "Para booster gblinear:\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8048780487804879 | 0.8461538461538461 | 0.8250000000000001 |   156   |\n",
      "|      2       | 0.7272727272727273 | 0.6666666666666666 | 0.6956521739130435 |    96   |\n",
      "|  macro avg   | 0.7660753880266076 | 0.7564102564102564 | 0.7603260869565218 |   252   |\n",
      "| weighted avg | 0.7753141167775314 | 0.7777777777777778 | 0.7757246376811594 |   252   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7777777777777778\n",
      "\n",
      "Para booster dart:\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7953216374269005 | 0.8717948717948718 | 0.8318042813455657 |   156   |\n",
      "|      2       | 0.7530864197530864 | 0.6354166666666666 | 0.6892655367231637 |    96   |\n",
      "|  macro avg   | 0.7742040285899935 | 0.7536057692307692 | 0.7605349090343647 |   252   |\n",
      "| weighted avg | 0.779232030694019  | 0.7817460317460317 | 0.7775038072036984 |   252   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7817460317460317\n"
     ]
    }
   ],
   "source": [
    "boo = ['gbtree', 'gblinear', 'dart']\n",
    "\n",
    "for i in boo:\n",
    "  print(f\"\\nPara booster {i}:\")\n",
    "  XGB_cross_validation(xFC1,yFC1, 5, False, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAArSfWVDK4n"
   },
   "source": [
    "El mejor hiperparámetro de booster para el XGBoost classifier es 'gbtree' con una exactitud de 0.825."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vD_VBOh8Ia2"
   },
   "source": [
    "4. Para uno de los modelos de clasificación, aplique un método de selección de características. Indique cuantas características son suficientes para obtener buenos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "id": "ZQbEwN8o8Inh",
    "outputId": "2474ee49-5985-4b37-8e9b-443069b008c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Filter feature selection, k = 1\n",
      "ACC:  0.7023809523809523 Recall:  [0.88461538 0.40625   ] Precision:  [0.70769231 0.68421053]\n",
      "--------------- Filter feature selection, k = 2\n",
      "ACC:  0.746031746031746 Recall:  [0.85897436 0.5625    ] Precision:  [0.76136364 0.71052632]\n",
      "--------------- Filter feature selection, k = 3\n",
      "ACC:  0.7420634920634921 Recall:  [0.87179487 0.53125   ] Precision:  [0.75138122 0.71830986]\n",
      "--------------- Filter feature selection, k = 4\n",
      "ACC:  0.753968253968254 Recall:  [0.87179487 0.5625    ] Precision:  [0.76404494 0.72972973]\n",
      "--------------- Filter feature selection, k = 5\n",
      "ACC:  0.7619047619047619 Recall:  [0.87179487 0.58333333] Precision:  [0.77272727 0.73684211]\n",
      "--------------- Filter feature selection, k = 6\n",
      "ACC:  0.7579365079365079 Recall:  [0.86538462 0.58333333] Precision:  [0.77142857 0.72727273]\n",
      "--------------- Filter feature selection, k = 7\n",
      "ACC:  0.7658730158730159 Recall:  [0.88461538 0.57291667] Precision:  [0.77094972 0.75342466]\n",
      "--------------- Filter feature selection, k = 8\n",
      "ACC:  0.75 Recall:  [0.86538462 0.5625    ] Precision:  [0.76271186 0.72      ]\n",
      "--------------- Filter feature selection, k = 9\n",
      "ACC:  0.753968253968254 Recall:  [0.87820513 0.55208333] Precision:  [0.76111111 0.73611111]\n",
      "--------------- Filter feature selection, k = 10\n",
      "ACC:  0.7380952380952381 Recall:  [0.87820513 0.51041667] Precision:  [0.74456522 0.72058824]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the filter approach for feature selection\n",
    "ks = np.arange(1, 11, 1)\n",
    "accs = []\n",
    "clf = SVC(kernel='rbf')\n",
    "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for k in ks:\n",
    "    print('--------------- Filter feature selection, k =', k)\n",
    "\n",
    "    cv_y_test = []\n",
    "    cv_y_pred = []\n",
    "\n",
    "    for train_index, test_index in kf.split(xFC1, yFC1):\n",
    "\n",
    "       # Training phase\n",
    "        x_train = xFC1[train_index, :]\n",
    "        y_train = yFC1[train_index]\n",
    "\n",
    "        ffs = SelectKBest(mutual_info_classif, k=k)\n",
    "        ffs.fit(x_train, y_train)\n",
    "        x_train = ffs.transform(x_train)\n",
    "\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        # Test phase\n",
    "        x_test = ffs.transform(xFC1[test_index, :])\n",
    "        y_test = yFC1[test_index]\n",
    "        y_pred = clf.predict(x_test)\n",
    "\n",
    "        cv_y_test.append(y_test)\n",
    "        cv_y_pred.append(y_pred)\n",
    "\n",
    "    acc = accuracy_score(np.concatenate(cv_y_test), np.concatenate(cv_y_pred))\n",
    "    rec = recall_score(np.concatenate(cv_y_test), np.concatenate(cv_y_pred), average = None)\n",
    "    pre = precision_score(np.concatenate(cv_y_test), np.concatenate(cv_y_pred), average = None)\n",
    "\n",
    "    print('ACC: ', acc, 'Recall: ', rec, 'Precision: ', pre)\n",
    "    accs.append(acc)\n",
    "\n",
    "plt.plot(ks, accs)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Univariate filter for feature selection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1uw8QBKDcUQ"
   },
   "source": [
    "El número óptimo de características para este conjunto de datos es 7 ya que las dos tienen una exactitud de 0.76587, con unas métricas por clase arriba de 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhCw6-8O9LWG"
   },
   "source": [
    "### Cognitivo Laura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHVeSM1W9LWM"
   },
   "source": [
    "**Clasificación de tareas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "mlqBQIwI9LWM",
    "outputId": "2d5c21d1-cec5-48c9-db82-922a93e3c3e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-50984664-8679-44e0-a581-1630a587e5b2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2332</th>\n",
       "      <th>2333</th>\n",
       "      <th>2334</th>\n",
       "      <th>2335</th>\n",
       "      <th>2336</th>\n",
       "      <th>2337</th>\n",
       "      <th>2338</th>\n",
       "      <th>2339</th>\n",
       "      <th>2340</th>\n",
       "      <th>2341</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017339</td>\n",
       "      <td>-0.636327</td>\n",
       "      <td>-2.293761</td>\n",
       "      <td>-1.049895</td>\n",
       "      <td>-0.815500</td>\n",
       "      <td>-0.607317</td>\n",
       "      <td>0.276530</td>\n",
       "      <td>-1.970846</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.833860</td>\n",
       "      <td>-1.579618</td>\n",
       "      <td>-1.023245</td>\n",
       "      <td>-0.813402</td>\n",
       "      <td>-0.841095</td>\n",
       "      <td>-0.833210</td>\n",
       "      <td>-0.891639</td>\n",
       "      <td>-1.369041</td>\n",
       "      <td>-1.703913</td>\n",
       "      <td>-0.270019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.464403</td>\n",
       "      <td>-0.088847</td>\n",
       "      <td>-1.380865</td>\n",
       "      <td>-1.597218</td>\n",
       "      <td>-1.485126</td>\n",
       "      <td>-2.568367</td>\n",
       "      <td>-0.543693</td>\n",
       "      <td>-0.922254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.945614</td>\n",
       "      <td>-1.556861</td>\n",
       "      <td>-1.537365</td>\n",
       "      <td>-1.195360</td>\n",
       "      <td>-0.920358</td>\n",
       "      <td>-1.276328</td>\n",
       "      <td>-0.559226</td>\n",
       "      <td>-1.294663</td>\n",
       "      <td>-1.690584</td>\n",
       "      <td>-1.553823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387756</td>\n",
       "      <td>0.025880</td>\n",
       "      <td>0.112102</td>\n",
       "      <td>-0.957592</td>\n",
       "      <td>-0.906744</td>\n",
       "      <td>-1.344665</td>\n",
       "      <td>-0.102744</td>\n",
       "      <td>0.714924</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.235127</td>\n",
       "      <td>-1.107091</td>\n",
       "      <td>-1.287671</td>\n",
       "      <td>-1.123152</td>\n",
       "      <td>-1.291325</td>\n",
       "      <td>-1.523272</td>\n",
       "      <td>-1.326378</td>\n",
       "      <td>-1.247965</td>\n",
       "      <td>-0.712618</td>\n",
       "      <td>-0.967449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.631094</td>\n",
       "      <td>-0.471242</td>\n",
       "      <td>-0.084936</td>\n",
       "      <td>-0.789807</td>\n",
       "      <td>-1.429423</td>\n",
       "      <td>-1.741191</td>\n",
       "      <td>-0.529927</td>\n",
       "      <td>-0.436456</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.588948</td>\n",
       "      <td>-1.787488</td>\n",
       "      <td>-0.811567</td>\n",
       "      <td>-0.904608</td>\n",
       "      <td>-0.565347</td>\n",
       "      <td>-1.011173</td>\n",
       "      <td>-1.171311</td>\n",
       "      <td>-1.814192</td>\n",
       "      <td>-0.892988</td>\n",
       "      <td>-1.070001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.524811</td>\n",
       "      <td>-0.941667</td>\n",
       "      <td>-2.081175</td>\n",
       "      <td>-1.482091</td>\n",
       "      <td>-1.679116</td>\n",
       "      <td>-2.010238</td>\n",
       "      <td>-1.417845</td>\n",
       "      <td>-1.085229</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.781886</td>\n",
       "      <td>-1.537562</td>\n",
       "      <td>-0.668185</td>\n",
       "      <td>-0.815963</td>\n",
       "      <td>-0.636921</td>\n",
       "      <td>-0.381253</td>\n",
       "      <td>-0.886230</td>\n",
       "      <td>-1.230972</td>\n",
       "      <td>-0.395736</td>\n",
       "      <td>-0.844716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2342 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50984664-8679-44e0-a581-1630a587e5b2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-50984664-8679-44e0-a581-1630a587e5b2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-50984664-8679-44e0-a581-1630a587e5b2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   0     1         2         3         4         5         6         7     \\\n",
       "0     1     1  0.017339 -0.636327 -2.293761 -1.049895 -0.815500 -0.607317   \n",
       "1     1     1 -0.464403 -0.088847 -1.380865 -1.597218 -1.485126 -2.568367   \n",
       "2     1     1  0.387756  0.025880  0.112102 -0.957592 -0.906744 -1.344665   \n",
       "3     1     1 -0.631094 -0.471242 -0.084936 -0.789807 -1.429423 -1.741191   \n",
       "4     1     1 -0.524811 -0.941667 -2.081175 -1.482091 -1.679116 -2.010238   \n",
       "\n",
       "       8         9     ...      2332      2333      2334      2335      2336  \\\n",
       "0  0.276530 -1.970846  ... -0.833860 -1.579618 -1.023245 -0.813402 -0.841095   \n",
       "1 -0.543693 -0.922254  ... -0.945614 -1.556861 -1.537365 -1.195360 -0.920358   \n",
       "2 -0.102744  0.714924  ... -1.235127 -1.107091 -1.287671 -1.123152 -1.291325   \n",
       "3 -0.529927 -0.436456  ... -0.588948 -1.787488 -0.811567 -0.904608 -0.565347   \n",
       "4 -1.417845 -1.085229  ... -0.781886 -1.537562 -0.668185 -0.815963 -0.636921   \n",
       "\n",
       "       2337      2338      2339      2340      2341  \n",
       "0 -0.833210 -0.891639 -1.369041 -1.703913 -0.270019  \n",
       "1 -1.276328 -0.559226 -1.294663 -1.690584 -1.553823  \n",
       "2 -1.523272 -1.326378 -1.247965 -0.712618 -0.967449  \n",
       "3 -1.011173 -1.171311 -1.814192 -0.892988 -1.070001  \n",
       "4 -0.381253 -0.886230 -1.230972 -0.395736 -0.844716  \n",
       "\n",
       "[5 rows x 2342 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laura_cog= pd.read_csv(\"/content/drive/Shareddrives/Proyecto_AprendizajeAI/Features_Laura_Cognitivo.txt\" , header=None, delimiter= \"\\t\")\n",
    "laura_cog = laura_cog.dropna(axis=1)\n",
    "laura_cog = laura_cog[laura_cog[1] != 0]\n",
    "laura_cog = laura_cog[laura_cog[0] != 13]\n",
    "laura_cog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "AZZ7_aq39LWN"
   },
   "outputs": [],
   "source": [
    "transformacion = lambda x: 1 if 1 <= x <= 4 else 2 if 5 <= x <= 8 else 3 if 9 <= x <= 12 else 4\n",
    "laura_cog[0] = laura_cog[0].map(transformacion)\n",
    "xLC = laura_cog.iloc[:, 2:].values\n",
    "yLC = laura_cog.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4Cn8tg79LWN"
   },
   "source": [
    "1. Evalúe el rendimiento de los modelos de clasificación SVM, K-NN, y MLP (de al menos 2 capas). Calcule tanto la exactitud, la precisión por clase y el recall por clase para cada uno de los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Jht88yd9LWN"
   },
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "n_31ehgv9LWN",
    "outputId": "ed53e725-9780-4b02-e3dd-c5b13bfb1491"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.73      0.80        11\n",
      "           2       0.83      1.00      0.91        10\n",
      "           3       0.91      0.91      0.91        11\n",
      "\n",
      "    accuracy                           0.88        32\n",
      "   macro avg       0.88      0.88      0.87        32\n",
      "weighted avg       0.88      0.88      0.87        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.82      0.90        11\n",
      "           2       1.00      1.00      1.00        10\n",
      "           3       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.94        31\n",
      "   macro avg       0.94      0.94      0.94        31\n",
      "weighted avg       0.95      0.94      0.94        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       1.00      0.91      0.95        11\n",
      "           3       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.94        31\n",
      "   macro avg       0.94      0.94      0.93        31\n",
      "weighted avg       0.94      0.94      0.94        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.60      0.71        10\n",
      "           2       1.00      0.91      0.95        11\n",
      "           3       0.64      0.90      0.75        10\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.83      0.80      0.80        31\n",
      "weighted avg       0.84      0.81      0.81        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.50      0.67        10\n",
      "           2       0.82      0.90      0.86        10\n",
      "           3       0.67      0.91      0.77        11\n",
      "\n",
      "    accuracy                           0.77        31\n",
      "   macro avg       0.83      0.77      0.76        31\n",
      "weighted avg       0.82      0.77      0.76        31\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       |       0.925        | 0.7115384615384616 | 0.8043478260869567 |    52   |\n",
      "|      2       | 0.9245283018867925 | 0.9423076923076923 | 0.9333333333333333 |    52   |\n",
      "|      3       | 0.7777777777777778 | 0.9423076923076923 | 0.8521739130434781 |    52   |\n",
      "|  macro avg   | 0.8757686932215235 | 0.8653846153846153 | 0.8632850241545894 |   156   |\n",
      "| weighted avg | 0.8757686932215234 | 0.8653846153846154 | 0.8632850241545893 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8653846153846154\n"
     ]
    }
   ],
   "source": [
    "SVM_cross_validation(xLC,yLC,5,\"rbf\",True, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzpFXhwR9LWN"
   },
   "source": [
    "KNN\n",
    "\n",
    "k=13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ldLH7ps9LWN",
    "outputId": "8e5520a9-3be9-4af1-f192-e07948310535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.27      0.43        11\n",
      "           2       0.82      0.90      0.86        10\n",
      "           3       0.61      1.00      0.76        11\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.81      0.72      0.68        32\n",
      "weighted avg       0.81      0.72      0.68        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.91      0.95        11\n",
      "           2       1.00      0.90      0.95        10\n",
      "           3       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.94        31\n",
      "   macro avg       0.94      0.94      0.94        31\n",
      "weighted avg       0.95      0.94      0.94        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.60      0.71        10\n",
      "           2       1.00      1.00      1.00        11\n",
      "           3       0.69      0.90      0.78        10\n",
      "\n",
      "    accuracy                           0.84        31\n",
      "   macro avg       0.85      0.83      0.83        31\n",
      "weighted avg       0.85      0.84      0.83        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.70      0.82        10\n",
      "           2       0.92      1.00      0.96        11\n",
      "           3       0.75      0.90      0.82        10\n",
      "\n",
      "    accuracy                           0.87        31\n",
      "   macro avg       0.89      0.87      0.87        31\n",
      "weighted avg       0.89      0.87      0.87        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.70      0.78        10\n",
      "           2       0.82      0.90      0.86        10\n",
      "           3       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.84        31\n",
      "   macro avg       0.84      0.84      0.83        31\n",
      "weighted avg       0.84      0.84      0.84        31\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.9428571428571428 | 0.6346153846153846 | 0.7586206896551724 |    52   |\n",
      "|      2       | 0.9074074074074074 | 0.9423076923076923 | 0.9245283018867925 |    52   |\n",
      "|      3       | 0.7313432835820896 | 0.9423076923076923 | 0.8235294117647058 |    52   |\n",
      "|  macro avg   | 0.8605359446155466 | 0.8397435897435898 | 0.8355594677688902 |   156   |\n",
      "| weighted avg | 0.8605359446155466 | 0.8397435897435898 | 0.8355594677688901 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8397435897435898\n"
     ]
    }
   ],
   "source": [
    "KNN_cross_validation(xLC,yLC,5,13,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-4BbIxy9LWN"
   },
   "source": [
    "MLP 5 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "pe1puW8g9LWN",
    "outputId": "3cee9ceb-82ac-4f02-aa73-2bc7d361287f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.82      0.86        11\n",
      "           2       0.45      1.00      0.62        10\n",
      "           3       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.59        32\n",
      "   macro avg       0.45      0.61      0.49        32\n",
      "weighted avg       0.45      0.59      0.49        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.73      0.84        11\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.43      0.90      0.58        10\n",
      "\n",
      "    accuracy                           0.55        31\n",
      "   macro avg       0.48      0.54      0.47        31\n",
      "weighted avg       0.49      0.55      0.49        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.10      0.18        10\n",
      "           2       1.00      1.00      1.00        11\n",
      "           3       0.53      1.00      0.69        10\n",
      "\n",
      "    accuracy                           0.71        31\n",
      "   macro avg       0.84      0.70      0.62        31\n",
      "weighted avg       0.85      0.71      0.64        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.60      0.71        10\n",
      "           2       0.42      0.91      0.57        11\n",
      "           3       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.52        31\n",
      "   macro avg       0.42      0.50      0.43        31\n",
      "weighted avg       0.42      0.52      0.43        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.90      0.72        10\n",
      "           2       0.83      1.00      0.91        10\n",
      "           3       1.00      0.36      0.53        11\n",
      "\n",
      "    accuracy                           0.74        31\n",
      "   macro avg       0.81      0.75      0.72        31\n",
      "weighted avg       0.82      0.74      0.71        31\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8048780487804879 | 0.6346153846153846 | 0.7096774193548387 |    52   |\n",
      "|      2       | 0.5774647887323944 | 0.7884615384615384 | 0.6666666666666667 |    52   |\n",
      "|      3       | 0.5227272727272727 | 0.4423076923076923 | 0.4791666666666667 |    52   |\n",
      "|  macro avg   | 0.6350233700800516 | 0.6217948717948717 | 0.6185035842293908 |   156   |\n",
      "| weighted avg | 0.6350233700800516 | 0.6217948717948718 | 0.6185035842293908 |   156   |\n",
      "|   Accuracy   |                    |                    | 0.6217948717948718 |         |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "perceptron(xLC,yLC,(5,5,5,5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFkFZXT59LWO"
   },
   "source": [
    "2. Seleccione dos modelos de clasificación no vistos en clase, y evalúelos con sus conjuntos de datos. Calcule tanto la exactitud, la precisión por clase y el recall por clase para cada uno de los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxlXfJED9LWO"
   },
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ODct4Su9LWO",
    "outputId": "e4b6cd86-a8ff-4f26-fe3f-255e45190f8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.73      0.76        11\n",
      "           2       0.86      0.60      0.71        10\n",
      "           3       0.60      0.82      0.69        11\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.75      0.72      0.72        32\n",
      "weighted avg       0.75      0.72      0.72        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.55      0.67        11\n",
      "           2       1.00      1.00      1.00        10\n",
      "           3       0.64      0.90      0.75        10\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.83      0.82      0.81        31\n",
      "weighted avg       0.83      0.81      0.80        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.60      0.57        10\n",
      "           2       0.88      0.64      0.74        11\n",
      "           3       0.75      0.90      0.82        10\n",
      "\n",
      "    accuracy                           0.71        31\n",
      "   macro avg       0.72      0.71      0.71        31\n",
      "weighted avg       0.73      0.71      0.71        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.60      0.60        10\n",
      "           2       0.82      0.82      0.82        11\n",
      "           3       0.80      0.80      0.80        10\n",
      "\n",
      "    accuracy                           0.74        31\n",
      "   macro avg       0.74      0.74      0.74        31\n",
      "weighted avg       0.74      0.74      0.74        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.40      0.42        10\n",
      "           2       0.80      0.80      0.80        10\n",
      "           3       0.67      0.73      0.70        11\n",
      "\n",
      "    accuracy                           0.65        31\n",
      "   macro avg       0.64      0.64      0.64        31\n",
      "weighted avg       0.64      0.65      0.64        31\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.6382978723404256 | 0.5769230769230769 | 0.6060606060606061 |    52   |\n",
      "|      2       | 0.8695652173913043 | 0.7692307692307693 | 0.8163265306122449 |    52   |\n",
      "|      3       | 0.6825396825396826 | 0.8269230769230769 | 0.7478260869565218 |    52   |\n",
      "|  macro avg   | 0.7301342574238042 | 0.7243589743589745 | 0.7234044078764575 |   156   |\n",
      "| weighted avg | 0.7301342574238041 | 0.7243589743589743 | 0.7234044078764575 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7243589743589743\n"
     ]
    }
   ],
   "source": [
    "dtc_cross_validation(xLC,yLC,5, True, 'gini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCqCZ0XX9LWO"
   },
   "source": [
    "XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "KPI831799LWO",
    "outputId": "8d49dfc0-b5f5-42e3-b954-733a821564c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.82      0.86        11\n",
      "           2       0.75      0.90      0.82        10\n",
      "           3       0.90      0.82      0.86        11\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.85      0.85      0.84        32\n",
      "weighted avg       0.85      0.84      0.84        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.64      0.78        11\n",
      "           2       0.91      1.00      0.95        10\n",
      "           3       0.77      1.00      0.87        10\n",
      "\n",
      "    accuracy                           0.87        31\n",
      "   macro avg       0.89      0.88      0.87        31\n",
      "weighted avg       0.90      0.87      0.86        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.90      0.86        10\n",
      "           2       1.00      1.00      1.00        11\n",
      "           3       0.89      0.80      0.84        10\n",
      "\n",
      "    accuracy                           0.90        31\n",
      "   macro avg       0.90      0.90      0.90        31\n",
      "weighted avg       0.91      0.90      0.90        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.70      0.74        10\n",
      "           2       1.00      0.91      0.95        11\n",
      "           3       0.75      0.90      0.82        10\n",
      "\n",
      "    accuracy                           0.84        31\n",
      "   macro avg       0.84      0.84      0.84        31\n",
      "weighted avg       0.85      0.84      0.84        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.90      0.90      0.90        10\n",
      "           3       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           0.94        31\n",
      "   macro avg       0.93      0.93      0.93        31\n",
      "weighted avg       0.94      0.94      0.94        31\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8723404255319149 | 0.7884615384615384 | 0.8282828282828283 |    52   |\n",
      "|      2       | 0.9074074074074074 | 0.9423076923076923 | 0.9245283018867925 |    52   |\n",
      "|      3       | 0.8545454545454545 | 0.9038461538461539 | 0.8785046728971962 |    52   |\n",
      "|  macro avg   | 0.8780977624949257 | 0.8782051282051282 | 0.8771052676889389 |   156   |\n",
      "| weighted avg | 0.8780977624949257 | 0.8782051282051282 | 0.8771052676889389 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8782051282051282\n"
     ]
    }
   ],
   "source": [
    "XGB_cross_validation(xLC,yLC,5, True, 'gbtree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJsyUy5RDveo"
   },
   "source": [
    "El mejor clasificador para este caso es XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHHWDvla9LWO"
   },
   "source": [
    "3. Indique qué modelos de clasificación de los que evaluó anteriormente tienen hiperparámetros y cuáles son éstos en cada caso. Seleccione uno de estos clasificadores, y determine sus hiperparámetros óptimos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZNqxHjv9LWO"
   },
   "source": [
    "1.   ***SVM***\n",
    "  *   **C**: Es el parámetro que controla la relación el tamaño del margen (valor grande de 𝐶 ocasiona un margen pequeño, y un valor grande de 𝐶 conduce a un margen grande).\n",
    "2.   ***KNN***\n",
    "  *   **k**: Representa el número de vecinos más cercanos que se utilizan para la clasificación. Seleccionar un valor adecuado para k es importante, ya que un valor bajo puede llevar a un modelo demasiado sensible al ruido y un valor alto puede llevar a un modelo demasiado generalizado.\n",
    "3.   ***MLP***\n",
    "  *   **hidden_layer_sizes**: Especifica la arquitectura de la red neuronal, es decir, el número de neuronas en cada capa oculta.\n",
    "4.   ***Decision Tree Classifier***\n",
    "  *   **max_depth**: Determina la profundidad máxima del árbol de decisión.\n",
    "  *   **criterion**: Es el encargado de medir la uniformidad de los nodos, uniformidad quiere decir que las cosas que son similares deben estar juntas y las que son diferentes deben separarse y distinguirse claramente unas de otras. se puede elegir el mse/mae/friedman_mse para regresión y gini/entropy para clasificación.\n",
    "  *   **min_samples_split**: el número mínimo de datos requeridos por un nodo para realizar una división.\n",
    "5.   ***XGBoost Classifier***\n",
    "  *   **n_estimators**: Representa el número de árboles que se utilizarán en el modelo. Cuanto mayor sea este valor, más complejo será el modelo y más tiempo requerirá el entrenamiento. Sin embargo, un número demasiado alto puede llevar a un sobreajuste.\n",
    "  *   **booster**: El tipo de modelo de clasificación usado, por defecto gbtree.\n",
    "  *   **max_depth**: “Profundidad” o número de nodos de bifurcación de los árboles de decisión usados en el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_a1pZ-F59LWO"
   },
   "source": [
    "Hiperparámetro KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "CpUrAeWq9LWO",
    "outputId": "b20b9aeb-4bee-4e6c-c980-301b3b35ec78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Para k = 10 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.9473684210526315 | 0.6923076923076923 | 0.7999999999999999 |    52   |\n",
      "|      2       | 0.8909090909090909 | 0.9423076923076923 | 0.9158878504672897 |    52   |\n",
      "|      3       | 0.7936507936507936 | 0.9615384615384616 | 0.8695652173913043 |    52   |\n",
      "|  macro avg   | 0.877309435204172  | 0.8653846153846154 | 0.8618176892861981 |   156   |\n",
      "| weighted avg | 0.8773094352041719 | 0.8653846153846154 | 0.861817689286198  |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8653846153846154\n",
      "\n",
      "Para k = 11 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.9714285714285714 | 0.6538461538461539 | 0.7816091954022988 |    52   |\n",
      "|      2       | 0.9074074074074074 | 0.9423076923076923 | 0.9245283018867925 |    52   |\n",
      "|      3       | 0.746268656716418  | 0.9615384615384616 | 0.8403361344537815 |    52   |\n",
      "|  macro avg   | 0.8750348785174656 | 0.8525641025641026 | 0.848824543914291  |   156   |\n",
      "| weighted avg | 0.8750348785174656 | 0.8525641025641025 | 0.8488245439142909 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8525641025641025\n",
      "\n",
      "Para k = 12 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.9142857142857143 | 0.6153846153846154 | 0.7356321839080461 |    52   |\n",
      "|      2       | 0.9245283018867925 | 0.9423076923076923 | 0.9333333333333333 |    52   |\n",
      "|      3       | 0.7352941176470589 | 0.9615384615384616 | 0.8333333333333333 |    52   |\n",
      "|  macro avg   | 0.8580360446065218 | 0.8397435897435898 | 0.8340996168582375 |   156   |\n",
      "| weighted avg | 0.8580360446065217 | 0.8397435897435898 | 0.8340996168582375 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8397435897435898\n",
      "\n",
      "Para k = 13 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.9705882352941176 | 0.6346153846153846 | 0.7674418604651162 |    52   |\n",
      "|      2       | 0.8909090909090909 | 0.9423076923076923 | 0.9158878504672897 |    52   |\n",
      "|      3       | 0.7313432835820896 | 0.9423076923076923 | 0.8235294117647058 |    52   |\n",
      "|  macro avg   | 0.864280203261766  | 0.8397435897435898 | 0.8356197075657038 |   156   |\n",
      "| weighted avg | 0.864280203261766  | 0.8397435897435898 | 0.8356197075657039 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8397435897435898\n",
      "\n",
      "Para k = 14 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.9705882352941176 | 0.6346153846153846 | 0.7674418604651162 |    52   |\n",
      "|      2       | 0.8909090909090909 | 0.9423076923076923 | 0.9158878504672897 |    52   |\n",
      "|      3       | 0.7313432835820896 | 0.9423076923076923 | 0.8235294117647058 |    52   |\n",
      "|  macro avg   | 0.864280203261766  | 0.8397435897435898 | 0.8356197075657038 |   156   |\n",
      "| weighted avg | 0.864280203261766  | 0.8397435897435898 | 0.8356197075657039 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8397435897435898\n",
      "\n",
      "Para k = 15 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.9696969696969697 | 0.6153846153846154 | 0.7529411764705882 |    52   |\n",
      "|      2       | 0.9074074074074074 | 0.9423076923076923 | 0.9245283018867925 |    52   |\n",
      "|      3       | 0.7246376811594203 | 0.9615384615384616 | 0.8264462809917356 |    52   |\n",
      "|  macro avg   | 0.8672473527545992 | 0.8397435897435898 | 0.8346385864497053 |   156   |\n",
      "| weighted avg | 0.8672473527545992 | 0.8397435897435898 | 0.8346385864497055 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8397435897435898\n",
      "\n",
      "Para k = 16 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.9714285714285714 | 0.6538461538461539 | 0.7816091954022988 |    52   |\n",
      "|      2       | 0.9074074074074074 | 0.9423076923076923 | 0.9245283018867925 |    52   |\n",
      "|      3       | 0.7313432835820896 | 0.9423076923076923 | 0.8235294117647058 |    52   |\n",
      "|  macro avg   | 0.8700597541393562 | 0.8461538461538461 | 0.8432223030179324 |   156   |\n",
      "| weighted avg | 0.8700597541393561 | 0.8461538461538461 | 0.8432223030179323 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8461538461538461\n",
      "\n",
      "Para k = 17 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.9411764705882353 | 0.6153846153846154 | 0.744186046511628  |    52   |\n",
      "|      2       | 0.9074074074074074 | 0.9423076923076923 | 0.9245283018867925 |    52   |\n",
      "|      3       | 0.7205882352941176 | 0.9423076923076923 | 0.8166666666666668 |    52   |\n",
      "|  macro avg   |  0.85639070442992  | 0.8333333333333334 | 0.8284603383550291 |   156   |\n",
      "| weighted avg | 0.8563907044299202 | 0.8333333333333334 | 0.8284603383550291 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8333333333333334\n",
      "\n",
      "Para k = 18 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.9696969696969697 | 0.6153846153846154 | 0.7529411764705882 |    52   |\n",
      "|      2       | 0.8909090909090909 | 0.9423076923076923 | 0.9158878504672897 |    52   |\n",
      "|      3       | 0.7205882352941176 | 0.9423076923076923 | 0.8166666666666668 |    52   |\n",
      "|  macro avg   | 0.8603980986333927 | 0.8333333333333334 | 0.8284985645348483 |   156   |\n",
      "| weighted avg | 0.8603980986333928 | 0.8333333333333334 | 0.8284985645348483 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8333333333333334\n",
      "\n",
      "Para k = 19 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       |      0.96875       | 0.5961538461538461 | 0.738095238095238  |    52   |\n",
      "|      2       |       0.875        | 0.9423076923076923 | 0.9074074074074073 |    52   |\n",
      "|      3       | 0.7058823529411765 | 0.9230769230769231 | 0.8000000000000002 |    52   |\n",
      "|  macro avg   | 0.8498774509803922 | 0.8205128205128206 | 0.8151675485008818 |   156   |\n",
      "| weighted avg | 0.8498774509803922 | 0.8205128205128205 | 0.8151675485008819 |   156   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8205128205128205\n"
     ]
    }
   ],
   "source": [
    "for k in range(10, 20):\n",
    "  print(f'\\nPara k = {k} los resultados son: ')\n",
    "  KNN_cross_validation(xLC,yLC,5,k,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7tFDkAtD3vv"
   },
   "source": [
    "EL mejor valor de k, que es el hiperparámetro de KNN, es de 17, con una exactitud de 0.747."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8OYtYUt9LWP"
   },
   "source": [
    "4. Para uno de los modelos de clasificación, aplique un método de selección de características. Indique cuantas características son suficientes para obtener buenos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "id": "klurKHoZ9LWP",
    "outputId": "3ef70cb2-dcac-40d3-8c1f-6b8b119843d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Filter feature selection, k = 1\n",
      "ACC:  0.6474358974358975 Recall:  [0.48076923 0.84615385 0.61538462] Precision:  [0.5        0.74576271 0.68085106]\n",
      "--------------- Filter feature selection, k = 2\n",
      "ACC:  0.6538461538461539 Recall:  [0.5        0.80769231 0.65384615] Precision:  [0.54166667 0.77777778 0.62962963]\n",
      "--------------- Filter feature selection, k = 3\n",
      "ACC:  0.6602564102564102 Recall:  [0.55769231 0.80769231 0.61538462] Precision:  [0.50877193 0.77777778 0.71111111]\n",
      "--------------- Filter feature selection, k = 4\n",
      "ACC:  0.6923076923076923 Recall:  [0.55769231 0.84615385 0.67307692] Precision:  [0.55769231 0.81481481 0.7       ]\n",
      "--------------- Filter feature selection, k = 5\n",
      "ACC:  0.6858974358974359 Recall:  [0.55769231 0.80769231 0.69230769] Precision:  [0.53703704 0.82352941 0.70588235]\n",
      "--------------- Filter feature selection, k = 6\n",
      "ACC:  0.7564102564102564 Recall:  [0.55769231 0.90384615 0.80769231] Precision:  [0.69047619 0.85454545 0.71186441]\n",
      "--------------- Filter feature selection, k = 7\n",
      "ACC:  0.7564102564102564 Recall:  [0.61538462 0.84615385 0.80769231] Precision:  [0.65306122 0.8627451  0.75      ]\n",
      "--------------- Filter feature selection, k = 8\n",
      "ACC:  0.7051282051282052 Recall:  [0.53846154 0.88461538 0.69230769] Precision:  [0.57142857 0.80701754 0.72      ]\n",
      "--------------- Filter feature selection, k = 9\n",
      "ACC:  0.75 Recall:  [0.61538462 0.92307692 0.71153846] Precision:  [0.64       0.88888889 0.71153846]\n",
      "--------------- Filter feature selection, k = 10\n",
      "ACC:  0.782051282051282 Recall:  [0.59615385 0.88461538 0.86538462] Precision:  [0.75609756 0.86792453 0.72580645]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the filter approach for feature selection\n",
    "ks = np.arange(1, 11, 1)\n",
    "accs = []\n",
    "clf = SVC(kernel='rbf')\n",
    "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for k in ks:\n",
    "    print('--------------- Filter feature selection, k =', k)\n",
    "\n",
    "    cv_y_test = []\n",
    "    cv_y_pred = []\n",
    "\n",
    "    for train_index, test_index in kf.split(xLC, yLC):\n",
    "\n",
    "       # Training phase\n",
    "        x_train = xLC[train_index, :]\n",
    "        y_train = yLC[train_index]\n",
    "\n",
    "        ffs = SelectKBest(mutual_info_classif, k=k)\n",
    "        ffs.fit(x_train, y_train)\n",
    "        x_train = ffs.transform(x_train)\n",
    "\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        # Test phase\n",
    "        x_test = ffs.transform(xLC[test_index, :])\n",
    "        y_test = yLC[test_index]\n",
    "        y_pred = clf.predict(x_test)\n",
    "\n",
    "        cv_y_test.append(y_test)\n",
    "        cv_y_pred.append(y_pred)\n",
    "\n",
    "    acc = accuracy_score(np.concatenate(cv_y_test), np.concatenate(cv_y_pred))\n",
    "    rec = recall_score(np.concatenate(cv_y_test), np.concatenate(cv_y_pred), average = None)\n",
    "    pre = precision_score(np.concatenate(cv_y_test), np.concatenate(cv_y_pred), average = None)\n",
    "\n",
    "    print('ACC: ', acc, 'Recall: ', rec, 'Precision: ', pre)\n",
    "    accs.append(acc)\n",
    "\n",
    "plt.plot(ks, accs)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Univariate filter for feature selection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3l6xzfBfED5E"
   },
   "source": [
    "La mejor cantidad de características para este conjunto de datos utilizando el método de filtrado es de 9, con una exactitud de 0.5494. Es un modelo que no se puede aceptar porque es muy bajo su exactitud, por lo que se necesitarían mayor número de características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzBf0G3P9LWP"
   },
   "source": [
    "**Clasificación de no tarea cognitiva vs tarea cognitiva**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "-dOl_XXB9LWP",
    "outputId": "6a9ba273-b7bd-45c0-9138-7b6dda2fc033"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b4bd5f1f-2aa9-4d2d-a348-76d610913d37\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2332</th>\n",
       "      <th>2333</th>\n",
       "      <th>2334</th>\n",
       "      <th>2335</th>\n",
       "      <th>2336</th>\n",
       "      <th>2337</th>\n",
       "      <th>2338</th>\n",
       "      <th>2339</th>\n",
       "      <th>2340</th>\n",
       "      <th>2341</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017339</td>\n",
       "      <td>-0.636327</td>\n",
       "      <td>-2.293761</td>\n",
       "      <td>-1.049895</td>\n",
       "      <td>-0.815500</td>\n",
       "      <td>-0.607317</td>\n",
       "      <td>0.276530</td>\n",
       "      <td>-1.970846</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.833860</td>\n",
       "      <td>-1.579618</td>\n",
       "      <td>-1.023245</td>\n",
       "      <td>-0.813402</td>\n",
       "      <td>-0.841095</td>\n",
       "      <td>-0.833210</td>\n",
       "      <td>-0.891639</td>\n",
       "      <td>-1.369041</td>\n",
       "      <td>-1.703913</td>\n",
       "      <td>-0.270019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.464403</td>\n",
       "      <td>-0.088847</td>\n",
       "      <td>-1.380865</td>\n",
       "      <td>-1.597218</td>\n",
       "      <td>-1.485126</td>\n",
       "      <td>-2.568367</td>\n",
       "      <td>-0.543693</td>\n",
       "      <td>-0.922254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.945614</td>\n",
       "      <td>-1.556861</td>\n",
       "      <td>-1.537365</td>\n",
       "      <td>-1.195360</td>\n",
       "      <td>-0.920358</td>\n",
       "      <td>-1.276328</td>\n",
       "      <td>-0.559226</td>\n",
       "      <td>-1.294663</td>\n",
       "      <td>-1.690584</td>\n",
       "      <td>-1.553823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387756</td>\n",
       "      <td>0.025880</td>\n",
       "      <td>0.112102</td>\n",
       "      <td>-0.957592</td>\n",
       "      <td>-0.906744</td>\n",
       "      <td>-1.344665</td>\n",
       "      <td>-0.102744</td>\n",
       "      <td>0.714924</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.235127</td>\n",
       "      <td>-1.107091</td>\n",
       "      <td>-1.287671</td>\n",
       "      <td>-1.123152</td>\n",
       "      <td>-1.291325</td>\n",
       "      <td>-1.523272</td>\n",
       "      <td>-1.326378</td>\n",
       "      <td>-1.247965</td>\n",
       "      <td>-0.712618</td>\n",
       "      <td>-0.967449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.631094</td>\n",
       "      <td>-0.471242</td>\n",
       "      <td>-0.084936</td>\n",
       "      <td>-0.789807</td>\n",
       "      <td>-1.429423</td>\n",
       "      <td>-1.741191</td>\n",
       "      <td>-0.529927</td>\n",
       "      <td>-0.436456</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.588948</td>\n",
       "      <td>-1.787488</td>\n",
       "      <td>-0.811567</td>\n",
       "      <td>-0.904608</td>\n",
       "      <td>-0.565347</td>\n",
       "      <td>-1.011173</td>\n",
       "      <td>-1.171311</td>\n",
       "      <td>-1.814192</td>\n",
       "      <td>-0.892988</td>\n",
       "      <td>-1.070001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.524811</td>\n",
       "      <td>-0.941667</td>\n",
       "      <td>-2.081175</td>\n",
       "      <td>-1.482091</td>\n",
       "      <td>-1.679116</td>\n",
       "      <td>-2.010238</td>\n",
       "      <td>-1.417845</td>\n",
       "      <td>-1.085229</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.781886</td>\n",
       "      <td>-1.537562</td>\n",
       "      <td>-0.668185</td>\n",
       "      <td>-0.815963</td>\n",
       "      <td>-0.636921</td>\n",
       "      <td>-0.381253</td>\n",
       "      <td>-0.886230</td>\n",
       "      <td>-1.230972</td>\n",
       "      <td>-0.395736</td>\n",
       "      <td>-0.844716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2342 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4bd5f1f-2aa9-4d2d-a348-76d610913d37')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b4bd5f1f-2aa9-4d2d-a348-76d610913d37 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b4bd5f1f-2aa9-4d2d-a348-76d610913d37');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   0     1         2         3         4         5         6         7     \\\n",
       "0     1     1  0.017339 -0.636327 -2.293761 -1.049895 -0.815500 -0.607317   \n",
       "1     1     1 -0.464403 -0.088847 -1.380865 -1.597218 -1.485126 -2.568367   \n",
       "2     1     1  0.387756  0.025880  0.112102 -0.957592 -0.906744 -1.344665   \n",
       "3     1     1 -0.631094 -0.471242 -0.084936 -0.789807 -1.429423 -1.741191   \n",
       "4     1     1 -0.524811 -0.941667 -2.081175 -1.482091 -1.679116 -2.010238   \n",
       "\n",
       "       8         9     ...      2332      2333      2334      2335      2336  \\\n",
       "0  0.276530 -1.970846  ... -0.833860 -1.579618 -1.023245 -0.813402 -0.841095   \n",
       "1 -0.543693 -0.922254  ... -0.945614 -1.556861 -1.537365 -1.195360 -0.920358   \n",
       "2 -0.102744  0.714924  ... -1.235127 -1.107091 -1.287671 -1.123152 -1.291325   \n",
       "3 -0.529927 -0.436456  ... -0.588948 -1.787488 -0.811567 -0.904608 -0.565347   \n",
       "4 -1.417845 -1.085229  ... -0.781886 -1.537562 -0.668185 -0.815963 -0.636921   \n",
       "\n",
       "       2337      2338      2339      2340      2341  \n",
       "0 -0.833210 -0.891639 -1.369041 -1.703913 -0.270019  \n",
       "1 -1.276328 -0.559226 -1.294663 -1.690584 -1.553823  \n",
       "2 -1.523272 -1.326378 -1.247965 -0.712618 -0.967449  \n",
       "3 -1.011173 -1.171311 -1.814192 -0.892988 -1.070001  \n",
       "4 -0.381253 -0.886230 -1.230972 -0.395736 -0.844716  \n",
       "\n",
       "[5 rows x 2342 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laura_cog= pd.read_csv(\"/Features_Laura_Cognitivo.txt\" , header=None, delimiter= \"\\t\")\n",
    "laura_cog = laura_cog.dropna(axis=1)\n",
    "laura_cog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "xFdJsdKY9LWP"
   },
   "outputs": [],
   "source": [
    "transformacion = lambda x: 1 if 1 <= x <= 12 else 2\n",
    "laura_cog[0] = laura_cog[0].map(transformacion)\n",
    "xLC1 = laura_cog.iloc[:, 2:].values\n",
    "yLC1 = laura_cog.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBheHL4t9LWP"
   },
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "lYUAFw_K9LWP",
    "outputId": "9785788f-1f20-4ae4-b381-846cf35f96f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.94      0.88        32\n",
      "           2       0.87      0.68      0.76        19\n",
      "\n",
      "    accuracy                           0.84        51\n",
      "   macro avg       0.85      0.81      0.82        51\n",
      "weighted avg       0.85      0.84      0.84        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.94      0.88        31\n",
      "           2       0.88      0.70      0.78        20\n",
      "\n",
      "    accuracy                           0.84        51\n",
      "   macro avg       0.85      0.82      0.83        51\n",
      "weighted avg       0.85      0.84      0.84        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.90      0.86        31\n",
      "           2       0.82      0.70      0.76        20\n",
      "\n",
      "    accuracy                           0.82        51\n",
      "   macro avg       0.82      0.80      0.81        51\n",
      "weighted avg       0.82      0.82      0.82        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.90      0.84        31\n",
      "           2       0.79      0.58      0.67        19\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.78      0.74      0.75        50\n",
      "weighted avg       0.78      0.78      0.77        50\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.94      0.85        31\n",
      "           2       0.85      0.58      0.69        19\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.81      0.76      0.77        50\n",
      "weighted avg       0.81      0.80      0.79        50\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.8089887640449438 | 0.9230769230769231 | 0.8622754491017964 |   156   |\n",
      "|      2       |        0.84        | 0.6494845360824743 | 0.7325581395348837 |    97   |\n",
      "|  macro avg   | 0.8244943820224719 | 0.7862807295796987 | 0.7974167943183401 |   253   |\n",
      "| weighted avg | 0.8208784473953014 | 0.8181818181818182 | 0.8125419351571699 |   253   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "SVM_cross_validation(xLC1,yLC1,5,\"rbf\",True, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsEHruoz9LWP"
   },
   "source": [
    "KNN\n",
    "\n",
    "k=13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z6A1Yu0r9LWQ",
    "outputId": "dc7082f7-d194-4626-ef26-13798224c4b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.94      0.87        32\n",
      "           2       0.86      0.63      0.73        19\n",
      "\n",
      "    accuracy                           0.82        51\n",
      "   macro avg       0.83      0.78      0.80        51\n",
      "weighted avg       0.83      0.82      0.82        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.71      0.71        31\n",
      "           2       0.55      0.55      0.55        20\n",
      "\n",
      "    accuracy                           0.65        51\n",
      "   macro avg       0.63      0.63      0.63        51\n",
      "weighted avg       0.65      0.65      0.65        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.84      0.80        31\n",
      "           2       0.71      0.60      0.65        20\n",
      "\n",
      "    accuracy                           0.75        51\n",
      "   macro avg       0.74      0.72      0.72        51\n",
      "weighted avg       0.74      0.75      0.74        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.81      0.77        31\n",
      "           2       0.62      0.53      0.57        19\n",
      "\n",
      "    accuracy                           0.70        50\n",
      "   macro avg       0.68      0.67      0.67        50\n",
      "weighted avg       0.69      0.70      0.69        50\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.90      0.82        31\n",
      "           2       0.77      0.53      0.62        19\n",
      "\n",
      "    accuracy                           0.76        50\n",
      "   macro avg       0.76      0.71      0.72        50\n",
      "weighted avg       0.76      0.76      0.75        50\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7572254335260116 | 0.8397435897435898 | 0.7963525835866261 |   156   |\n",
      "|      2       |       0.6875       | 0.5670103092783505 | 0.6214689265536724 |    97   |\n",
      "|  macro avg   | 0.7223627167630058 | 0.7033769495109701 | 0.7089107550701492 |   253   |\n",
      "| weighted avg | 0.7304927574310586 | 0.7351778656126482 | 0.7293023277281419 |   253   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7351778656126482\n"
     ]
    }
   ],
   "source": [
    "KNN_cross_validation(xLC1,yLC1,5,13,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ep9H6sOP9LWQ"
   },
   "source": [
    "MLP 5 capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "bKGRXy5S9LWQ",
    "outputId": "af002db0-401f-4fa1-d12b-5ea989a466b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.88      0.74        32\n",
      "           2       0.43      0.16      0.23        19\n",
      "\n",
      "    accuracy                           0.61        51\n",
      "   macro avg       0.53      0.52      0.48        51\n",
      "weighted avg       0.56      0.61      0.55        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      1.00      0.84        31\n",
      "           2       1.00      0.40      0.57        20\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.86      0.70      0.70        51\n",
      "weighted avg       0.83      0.76      0.73        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.65      0.70        31\n",
      "           2       0.56      0.70      0.62        20\n",
      "\n",
      "    accuracy                           0.67        51\n",
      "   macro avg       0.66      0.67      0.66        51\n",
      "weighted avg       0.69      0.67      0.67        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.77      0.79        31\n",
      "           2       0.65      0.68      0.67        19\n",
      "\n",
      "    accuracy                           0.74        50\n",
      "   macro avg       0.73      0.73      0.73        50\n",
      "weighted avg       0.74      0.74      0.74        50\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.55      0.71        31\n",
      "           2       0.58      1.00      0.73        19\n",
      "\n",
      "    accuracy                           0.72        50\n",
      "   macro avg       0.79      0.77      0.72        50\n",
      "weighted avg       0.84      0.72      0.72        50\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       |        0.75        | 0.7692307692307693 | 0.7594936708860761 |   156   |\n",
      "|      2       | 0.6129032258064516 | 0.5876288659793815 |        0.6         |    97   |\n",
      "|  macro avg   | 0.6814516129032258 | 0.6784298176050754 | 0.679746835443038  |   253   |\n",
      "| weighted avg | 0.6974372051510901 | 0.6996047430830039 | 0.6983439235503078 |   253   |\n",
      "|   Accuracy   |                    |                    | 0.6996047430830039 |         |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "perceptron(xLC1,yLC1,(5,5,5,5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33VkrtYr9LWQ"
   },
   "source": [
    "2. Seleccione dos modelos de clasificación no vistos en clase, y evalúelos con sus conjuntos de datos. Calcule tanto la exactitud, la precisión por clase y el recall por clase para cada uno de los modelos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjbJ5Uoq9LWQ"
   },
   "source": [
    "Decission Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "vAhE-HJE9LWQ",
    "outputId": "781c0706-36a6-4e86-8b24-d1885c6576db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.81      0.80        32\n",
      "           2       0.67      0.63      0.65        19\n",
      "\n",
      "    accuracy                           0.75        51\n",
      "   macro avg       0.73      0.72      0.72        51\n",
      "weighted avg       0.74      0.75      0.74        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.68      0.69        31\n",
      "           2       0.52      0.55      0.54        20\n",
      "\n",
      "    accuracy                           0.63        51\n",
      "   macro avg       0.61      0.61      0.61        51\n",
      "weighted avg       0.63      0.63      0.63        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.58      0.62        31\n",
      "           2       0.46      0.55      0.50        20\n",
      "\n",
      "    accuracy                           0.57        51\n",
      "   macro avg       0.56      0.57      0.56        51\n",
      "weighted avg       0.58      0.57      0.57        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.71      0.71        31\n",
      "           2       0.53      0.53      0.53        19\n",
      "\n",
      "    accuracy                           0.64        50\n",
      "   macro avg       0.62      0.62      0.62        50\n",
      "weighted avg       0.64      0.64      0.64        50\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.71      0.71        31\n",
      "           2       0.53      0.53      0.53        19\n",
      "\n",
      "    accuracy                           0.64        50\n",
      "   macro avg       0.62      0.62      0.62        50\n",
      "weighted avg       0.64      0.64      0.64        50\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7171052631578947 | 0.6987179487179487 | 0.7077922077922078 |   156   |\n",
      "|      2       | 0.5346534653465347 | 0.5567010309278351 | 0.5454545454545455 |    97   |\n",
      "|  macro avg   | 0.6258793642522147 | 0.6277094898228919 | 0.6266233766233766 |   253   |\n",
      "| weighted avg | 0.6471533881076895 | 0.6442687747035574 | 0.6455520763821159 |   253   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.6442687747035574\n"
     ]
    }
   ],
   "source": [
    "dtc_cross_validation(xLC1,yLC1,5, True, 'gini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82-lVGER9LWQ"
   },
   "source": [
    "XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "mUBZjoE79LWQ",
    "outputId": "642461e1-4307-4535-9b40-c3f3992e0bca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.81      0.84        32\n",
      "           2       0.71      0.79      0.75        19\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.79      0.80      0.79        51\n",
      "weighted avg       0.81      0.80      0.81        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.81      0.77        31\n",
      "           2       0.65      0.55      0.59        20\n",
      "\n",
      "    accuracy                           0.71        51\n",
      "   macro avg       0.69      0.68      0.68        51\n",
      "weighted avg       0.70      0.71      0.70        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.90      0.81        31\n",
      "           2       0.77      0.50      0.61        20\n",
      "\n",
      "    accuracy                           0.75        51\n",
      "   macro avg       0.75      0.70      0.71        51\n",
      "weighted avg       0.75      0.75      0.73        51\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.87      0.83        31\n",
      "           2       0.75      0.63      0.69        19\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.77      0.75      0.76        50\n",
      "weighted avg       0.78      0.78      0.78        50\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.94      0.88        31\n",
      "           2       0.87      0.68      0.76        19\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.85      0.81      0.82        50\n",
      "weighted avg       0.84      0.84      0.84        50\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7894736842105263 | 0.8653846153846154 | 0.8256880733944955 |   156   |\n",
      "|      2       | 0.7439024390243902 | 0.6288659793814433 | 0.6815642458100558 |    97   |\n",
      "|  macro avg   | 0.7666880616174583 | 0.7471252973830294 | 0.7536261596022756 |   253   |\n",
      "| weighted avg | 0.7720017048308615 | 0.7747035573122529 | 0.7704311118305008 |   253   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7747035573122529\n"
     ]
    }
   ],
   "source": [
    "XGB_cross_validation(xLC1,yLC1,5, True, 'gbtree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_cTUAAgEkMy"
   },
   "source": [
    "El mejor modelo para estos datos, como en todos los casos anteriores es el SVM de base radial con una exactitud de 0.81."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-ANGxtC9LWQ"
   },
   "source": [
    "Hiperparámetro KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "BY1JPwSw9LWQ",
    "outputId": "d94b24eb-3953-4277-b678-8c14bfb21464"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Para k = 10 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       |        0.75        | 0.9038461538461539 | 0.8197674418604652 |   156   |\n",
      "|      2       | 0.7692307692307693 | 0.5154639175257731 | 0.617283950617284  |    97   |\n",
      "|  macro avg   | 0.7596153846153846 | 0.7096550356859634 | 0.7185256962388746 |   253   |\n",
      "| weighted avg | 0.7573730617208878 | 0.7549407114624506 | 0.7421354313838306 |   253   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7549407114624506\n",
      "\n",
      "Para k = 11 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7745664739884393 | 0.8589743589743589 | 0.8145896656534954 |   156   |\n",
      "|      2       |       0.725        | 0.5979381443298969 | 0.655367231638418  |    97   |\n",
      "|  macro avg   | 0.7497832369942197 | 0.7284562516521279 | 0.7349784486459567 |   253   |\n",
      "| weighted avg | 0.755562727044255  | 0.758893280632411  | 0.7535439103196515 |   253   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.758893280632411\n",
      "\n",
      "Para k = 12 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7566137566137566 | 0.9166666666666666 | 0.8289855072463769 |   156   |\n",
      "|      2       |      0.796875      | 0.5257731958762887 | 0.6335403726708075 |    97   |\n",
      "|  macro avg   | 0.7767443783068784 | 0.7212199312714777 | 0.7312629399585922 |   253   |\n",
      "| weighted avg | 0.7720498855009724 | 0.766798418972332  | 0.7540519971521862 |   253   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.766798418972332\n",
      "\n",
      "Para k = 13 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7758620689655172 | 0.8653846153846154 | 0.8181818181818181 |   156   |\n",
      "|      2       | 0.7341772151898734 | 0.5979381443298969 | 0.6590909090909092 |    97   |\n",
      "|  macro avg   | 0.7550196420776953 | 0.7316613798572562 | 0.7386363636363636 |   253   |\n",
      "| weighted avg | 0.759880128980389  | 0.7628458498023716 | 0.7571864893999282 |   253   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7628458498023716\n",
      "\n",
      "Para k = 14 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7295918367346939 | 0.9166666666666666 | 0.8124999999999999 |   156   |\n",
      "|      2       | 0.7719298245614035 | 0.4536082474226804 | 0.5714285714285714 |    97   |\n",
      "|  macro avg   | 0.7507608306480487 | 0.6851374570446735 | 0.6919642857142856 |   253   |\n",
      "| weighted avg | 0.7458241877986893 | 0.7391304347826086 | 0.7200734048560135 |   253   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7391304347826086\n",
      "\n",
      "Para k = 15 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       |        0.75        | 0.8653846153846154 | 0.8035714285714286 |   156   |\n",
      "|      2       | 0.7123287671232876 | 0.5360824742268041 | 0.6117647058823529 |    97   |\n",
      "|  macro avg   | 0.7311643835616438 | 0.7007335448057097 | 0.7076680672268907 |   253   |\n",
      "| weighted avg | 0.7355568790946992 | 0.7391304347826086 | 0.7300328827183047 |   253   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7391304347826086\n",
      "\n",
      "Para k = 16 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7540106951871658 | 0.9038461538461539 | 0.8221574344023324 |   156   |\n",
      "|      2       | 0.7727272727272727 | 0.5257731958762887 | 0.6257668711656441 |    97   |\n",
      "|  macro avg   | 0.7633689839572193 | 0.7148096748612213 | 0.7239621527839882 |   253   |\n",
      "| weighted avg | 0.7611866162203292 | 0.758893280632411  | 0.7468614477068432 |   253   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.758893280632411\n",
      "\n",
      "Para k = 17 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7821229050279329 | 0.8974358974358975 | 0.835820895522388  |   156   |\n",
      "|      2       | 0.7837837837837838 | 0.5979381443298969 | 0.6783625730994152 |    97   |\n",
      "|  macro avg   | 0.7829533444058583 | 0.7476870208828972 | 0.7570917343109016 |   253   |\n",
      "| weighted avg | 0.7827596846299785 | 0.782608695652174  | 0.7754514991784024 |   253   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.782608695652174\n",
      "\n",
      "Para k = 18 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7409326424870466 | 0.9166666666666666 | 0.8194842406876791 |   156   |\n",
      "|      2       | 0.7833333333333333 | 0.4845360824742268 | 0.5987261146496815 |    97   |\n",
      "|  macro avg   | 0.7621329879101899 | 0.7006013745704467 | 0.7091051776686803 |   253   |\n",
      "| weighted avg | 0.7571890338391803 | 0.7509881422924901 | 0.7348457496770634 |   253   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7509881422924901\n",
      "\n",
      "Para k = 19 los resultados son: \n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      1       | 0.7784090909090909 | 0.8782051282051282 | 0.8253012048192772 |   156   |\n",
      "|      2       | 0.7532467532467533 | 0.5979381443298969 | 0.6666666666666666 |    97   |\n",
      "|  macro avg   | 0.765827922077922  | 0.7380716362675126 | 0.7459839357429718 |   253   |\n",
      "| weighted avg | 0.7687618705405267 | 0.7707509881422925 | 0.7644808482943631 |   253   |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.7707509881422925\n"
     ]
    }
   ],
   "source": [
    "for k in range(10, 20):\n",
    "  print(f'\\nPara k = {k} los resultados son: ')\n",
    "  KNN_cross_validation(xLC1,yLC1,5,k,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYISB4vWEyMd"
   },
   "source": [
    "EL mejor valor de k, que es el hiperparámetro de KNN, es de 17, con una exactitud de 0.7826."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16Qrd8LV9LWQ"
   },
   "source": [
    "4. Para uno de los modelos de clasificación, aplique un método de selección de características. Indique cuantas características son suficientes para obtener buenos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "id": "q7aunTYQ9LWR",
    "outputId": "3c73446c-3eb7-4983-952c-193ace036ed1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Filter feature selection, k = 1\n",
      "ACC:  0.6324110671936759 Recall:  [0.85897436 0.26804124] Precision:  [0.65365854 0.54166667]\n",
      "--------------- Filter feature selection, k = 2\n",
      "ACC:  0.6837944664031621 Recall:  [0.83974359 0.43298969] Precision:  [0.70430108 0.62686567]\n",
      "--------------- Filter feature selection, k = 3\n",
      "ACC:  0.7193675889328063 Recall:  [0.83974359 0.5257732 ] Precision:  [0.74011299 0.67105263]\n",
      "--------------- Filter feature selection, k = 4\n",
      "ACC:  0.7391304347826086 Recall:  [0.90384615 0.4742268 ] Precision:  [0.734375   0.75409836]\n",
      "--------------- Filter feature selection, k = 5\n",
      "ACC:  0.6877470355731226 Recall:  [0.83974359 0.44329897] Precision:  [0.70810811 0.63235294]\n",
      "--------------- Filter feature selection, k = 6\n",
      "ACC:  0.7193675889328063 Recall:  [0.84615385 0.51546392] Precision:  [0.73743017 0.67567568]\n",
      "--------------- Filter feature selection, k = 7\n",
      "ACC:  0.758893280632411 Recall:  [0.86538462 0.58762887] Precision:  [0.77142857 0.73076923]\n",
      "--------------- Filter feature selection, k = 8\n",
      "ACC:  0.7470355731225297 Recall:  [0.83333333 0.60824742] Precision:  [0.77380952 0.69411765]\n",
      "--------------- Filter feature selection, k = 9\n",
      "ACC:  0.7391304347826086 Recall:  [0.84615385 0.56701031] Precision:  [0.75862069 0.69620253]\n",
      "--------------- Filter feature selection, k = 10\n",
      "ACC:  0.7233201581027668 Recall:  [0.84615385 0.5257732 ] Precision:  [0.74157303 0.68      ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the filter approach for feature selection\n",
    "ks = np.arange(1, 11, 1)\n",
    "accs = []\n",
    "clf = SVC(kernel='rbf')\n",
    "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for k in ks:\n",
    "    print('--------------- Filter feature selection, k =', k)\n",
    "\n",
    "    cv_y_test = []\n",
    "    cv_y_pred = []\n",
    "\n",
    "    for train_index, test_index in kf.split(xLC1, yLC1):\n",
    "\n",
    "       # Training phase\n",
    "        x_train = xLC1[train_index, :]\n",
    "        y_train = yLC1[train_index]\n",
    "\n",
    "        ffs = SelectKBest(mutual_info_classif, k=k)\n",
    "        ffs.fit(x_train, y_train)\n",
    "        x_train = ffs.transform(x_train)\n",
    "\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        # Test phase\n",
    "        x_test = ffs.transform(xLC1[test_index, :])\n",
    "        y_test = yLC1[test_index]\n",
    "        y_pred = clf.predict(x_test)\n",
    "\n",
    "        cv_y_test.append(y_test)\n",
    "        cv_y_pred.append(y_pred)\n",
    "\n",
    "    acc = accuracy_score(np.concatenate(cv_y_test), np.concatenate(cv_y_pred))\n",
    "    rec = recall_score(np.concatenate(cv_y_test), np.concatenate(cv_y_pred), average = None)\n",
    "    pre = precision_score(np.concatenate(cv_y_test), np.concatenate(cv_y_pred), average = None)\n",
    "\n",
    "    print('ACC: ', acc, 'Recall: ', rec, 'Precision: ', pre)\n",
    "    accs.append(acc)\n",
    "\n",
    "plt.plot(ks, accs)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Univariate filter for feature selection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ItEOK76F6Hz"
   },
   "source": [
    "La óptima cantidad de características para este conjunto de datos utilizando el método de filtrado es k = 10, con una exactitud de 0.791."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTcJYQID3Y-v"
   },
   "source": [
    "## Aprendizaje por transferencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTheatLh3bea"
   },
   "source": [
    "Datos de entrenamiento: Laura\n",
    "\n",
    "Datos de prueba: Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "wUk8SNG64Hg-"
   },
   "outputs": [],
   "source": [
    "lauraP300 = lauraP300.drop([154,153,152], axis=1)\n",
    "xL = lauraP300.iloc[:, 1:].values\n",
    "yL = lauraP300.iloc[:, 0].values\n",
    "\n",
    "\n",
    "xF = frankP300.iloc[:, 1:].values\n",
    "yF = frankP300.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vD_oSyIo3rbb"
   },
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ZgKWSdA43Ydu",
    "outputId": "a9dcab8d-3de5-4cb5-df37-0def44b79d1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------+---------------------+---------------------+---------+\n",
      "|    Clase     |      Precisión      |        Recall       |      Puntaje F1     | Soporte |\n",
      "+--------------+---------------------+---------------------+---------------------+---------+\n",
      "|      1       | 0.34831460674157305 | 0.11191335740072202 | 0.16939890710382513 |   277   |\n",
      "|      2       |  0.8113496932515337 |  0.9480286738351255 |  0.8743801652892562 |   1116  |\n",
      "|  macro avg   |  0.5798321499965534 |  0.5299710156179237 |  0.5218895361965407 |   1393  |\n",
      "| weighted avg |  0.7192745181163872 |  0.7817659727207465 |  0.7341936552265395 |   1393  |\n",
      "+--------------+---------------------+---------------------+---------------------+---------+\n",
      "\n",
      "Precisión del modelo SVM: 0.7817659727207465\n"
     ]
    }
   ],
   "source": [
    "# Datos de entrenamiento: Laura\n",
    "X_train = xL\n",
    "y_train = yL\n",
    "\n",
    "# Datos de prueba: francisco\n",
    "X_test = xF\n",
    "y_test = yF\n",
    "\n",
    "# Creación del modelo SVM radial\n",
    "model = SVC(kernel='rbf')\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prueba del modelo\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Resultados del clasificador\n",
    "\n",
    "report =  classification_report(y_test, y_pred, output_dict=True)\n",
    "accuracy = report['accuracy']\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Clase', 'Precisión', 'Recall', 'Puntaje F1', 'Soporte']\n",
    "\n",
    "# Agrega las filas a la tabla\n",
    "for class_label, metrics in report.items():\n",
    "    if class_label != 'accuracy':\n",
    "        precision = metrics['precision']\n",
    "        recall = metrics['recall']\n",
    "        f1_score = metrics['f1-score']\n",
    "        support = metrics['support']\n",
    "        table.add_row([class_label, precision, recall, f1_score, support])\n",
    "\n",
    "# Imprime el resultado\n",
    "print(table)\n",
    "print(\"\\nPrecisión del modelo SVM:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7-3wFgX3tIo"
   },
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "FFfVEQfP3wE8",
    "outputId": "6b689d4d-bf88-445c-f18d-804601b9a78b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+---------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |        Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+---------------------+--------------------+---------+\n",
      "|      1       |      0.28125       | 0.22743682310469315 | 0.251497005988024  |   277   |\n",
      "|      2       | 0.8169375534644996 |  0.8557347670250897 | 0.8358862144420132 |   1116  |\n",
      "|  macro avg   | 0.5490937767322498 |  0.5415857950648915 | 0.5436916102150186 |   1393  |\n",
      "| weighted avg | 0.7104153335724204 |  0.7307968413496052 | 0.7196796022799493 |   1393  |\n",
      "+--------------+--------------------+---------------------+--------------------+---------+\n",
      "\n",
      "Precisión del modelo MLP: 0.7307968413496052\n"
     ]
    }
   ],
   "source": [
    "X_train = xL\n",
    "y_train = yL\n",
    "\n",
    "X_test = xF\n",
    "y_test = yF\n",
    "\n",
    "# Paso 5: Creación del modelo MLP\n",
    "model = MLPClassifier()\n",
    "\n",
    "# Paso 6: Entrenamiento del modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Paso 7: Prueba del modelo\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Resultados del clasificador\n",
    "\n",
    "report =  classification_report(y_test, y_pred, output_dict=True)\n",
    "accuracy = report['accuracy']\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Clase', 'Precisión', 'Recall', 'Puntaje F1', 'Soporte']\n",
    "\n",
    "# Agrega las filas a la tabla\n",
    "for class_label, metrics in report.items():\n",
    "    if class_label != 'accuracy':\n",
    "        precision = metrics['precision']\n",
    "        recall = metrics['recall']\n",
    "        f1_score = metrics['f1-score']\n",
    "        support = metrics['support']\n",
    "        table.add_row([class_label, precision, recall, f1_score, support])\n",
    "\n",
    "# Imprime el resultado\n",
    "print(table)\n",
    "print(\"\\nPrecisión del modelo MLP:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMP35HZQ3uIE"
   },
   "source": [
    "XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "4PdIZmrx30Bv",
    "outputId": "8d84f597-910d-4b44-e280-cf5cb4c45338"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+---------------------+---------------------+---------+\n",
      "|    Clase     |     Precisión      |        Recall       |      Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+---------------------+---------------------+---------+\n",
      "|      1       | 0.3732394366197183 | 0.19133574007220217 | 0.25298329355608595 |   277   |\n",
      "|      2       | 0.820943245403677  |  0.9202508960573477 |  0.8677651035065482 |   1116  |\n",
      "|  macro avg   | 0.5970913410116977 |  0.5557933180647749 |  0.5603741985313171 |   1393  |\n",
      "| weighted avg | 0.7319167163059336 |  0.7753050969131371 |  0.7455148799916321 |   1393  |\n",
      "+--------------+--------------------+---------------------+---------------------+---------+\n",
      "\n",
      "Precisión del modelo XGBOOST: 0.7753050969131371\n"
     ]
    }
   ],
   "source": [
    "X_train = xL\n",
    "y_train = yL - 1\n",
    "\n",
    "X_test = xF\n",
    "y_test = yF\n",
    "\n",
    "# Paso 5: Creación del modelo MLP\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Paso 6: Entrenamiento del modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Paso 7: Prueba del modelo\n",
    "y_pred = model.predict(X_test) + 1\n",
    "\n",
    "# Resultados del clasificador\n",
    "\n",
    "report =  classification_report(y_test, y_pred, output_dict=True)\n",
    "accuracy = report['accuracy']\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Clase', 'Precisión', 'Recall', 'Puntaje F1', 'Soporte']\n",
    "\n",
    "# Agrega las filas a la tabla\n",
    "for class_label, metrics in report.items():\n",
    "    if class_label != 'accuracy':\n",
    "        precision = metrics['precision']\n",
    "        recall = metrics['recall']\n",
    "        f1_score = metrics['f1-score']\n",
    "        support = metrics['support']\n",
    "        table.add_row([class_label, precision, recall, f1_score, support])\n",
    "\n",
    "# Imprime el resultado\n",
    "print(table)\n",
    "print(\"\\nPrecisión del modelo XGBOOST:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXAbnkPS4c5Z"
   },
   "source": [
    "¿Es posible entrenar un modelo de clasificación con los datos de un sujeto y obtener buenos resultados con los datos de otro sujeto? ¿Por qué?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNdy5JX0DKzF"
   },
   "source": [
    "Sí es posible entrenar un modelo de clasficación con los datos de un sujeto y probarlo con otro y obtener un buen resultado. En este caso el SVM Radial fue el mejor modelo con un accuracy de 0.78 que en la vida real es un muy buen valor para un modelo de clasificación. Además este modelo tiene un precisión y recall por la clase 2 muy buena. Esto es porque la cantidad de los datos que hay, muchos son observaciones de la clase dos y muy pocos de la clase 1. Eso nos dice que tenemos un desbalance en nuestro modelo, pero aun así se alcanza a obtener un buen clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qGF4NNH4f2y"
   },
   "source": [
    "¿Consideras que debes hacer ajustes cuando tengas datos de otro sujeto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyB6WFRBEK-R"
   },
   "source": [
    "Si se tienen datos de otro sujeto se puede volver a entrenar con ambos datos y probar con los del sujeto restante, esto podría mejorar nuestro clasificador porque ya no solo se toma en cuenta los datos de un sujeto para entrenar el modelo, en su lugar se usan 2, lo que aportaría información valiosa al momento de entrenar el modelo."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
